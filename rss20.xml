<?xml version="1.0"?>
<rss version="2.0">

<channel>
	<title>FreeIPA Identity Management planet - technical blogs</title>
	<link>http://planet.freeipa.org/</link>
	<language>en</language>
	<description>FreeIPA Identity Management planet - technical blogs - http://planet.freeipa.org/</description>

<item>
	<title>Fraser Tweedale: Demo: namespaced systemd workloads on OpenShift</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-07-22-openshift-systemd-workload-demo.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-07-22-openshift-systemd-workload-demo.html</link>
	<description>&lt;h1 id=&quot;demo-namespaced-systemd-workloads-on-openshift&quot;&gt;Demo: namespaced systemd workloads on OpenShift&lt;/h1&gt;
&lt;p&gt;I have spent much of the last year diving deep into OpenShift’s container runtime. The goal: work out how to run systemd-based workloads in &lt;em&gt;user namespaces&lt;/em&gt; on OpenShift nodes. The exploration took many twists and turns. But finally, I have achieved the goal.&lt;/p&gt;
&lt;p&gt;In this post I recap the journey so far, and &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#demo&quot;&gt;&lt;strong&gt;demonstrate&lt;/strong&gt;&lt;/a&gt; what I have achieved. Then I will summarise the path(s?) forward from here.&lt;/p&gt;
&lt;h2 id=&quot;the-journey-so-far&quot;&gt;The journey so far &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#the-journey-so-far&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-07-21-freeipa-on-openshift-update.html&quot;&gt;previous post&lt;/a&gt; gives an overview of the FreeIPA on OpenShift project. In particular, it explains our decision to use a “monolithic” systemd-based container. That implementation approach exposed capability gaps in OpenShift and led to a long running series of investigations. I wrote up the results of these investigations across several blog posts, summarised here:&lt;/p&gt;
&lt;h3 id=&quot;openshift-and-user-namespaces&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2020-11-05-openshift-user-namespace.html&quot;&gt;&lt;em&gt;OpenShift and user namespaces&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#openshift-and-user-namespaces&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I observed that OpenShift (4.6 at the time) did not isolate containers in user namespaces. I noted that &lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/127&quot;&gt;KEP-127&lt;/a&gt; proposes user namespace support for Kubernetes (it is &lt;a href=&quot;https://github.com/kubernetes/enhancements/pull/2101&quot;&gt;still being worked on&lt;/a&gt;). CRI-O had also recently &lt;a href=&quot;https://github.com/cri-o/cri-o/pull/3944&quot;&gt;added support&lt;/a&gt; for user namespaces via annotations.&lt;/p&gt;
&lt;h3 id=&quot;user-namespaces-in-openshift-via-cri-o-annotations&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2020-12-01-openshift-crio-userns.html&quot;&gt;&lt;em&gt;User namespaces in OpenShift via CRI-O annotations&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#user-namespaces-in-openshift-via-cri-o-annotations&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I tested CRI-O’s annotation-based user namespace support on OpenShift 4.7 nightlies. I found that the runtime creates a sandbox with a user namespace and the expected UID mappings. I also found that it is necessary to override the &lt;code&gt;net.ipv4.ping_group_range&lt;/code&gt; sysctl. Also, the SCC enforcement machinery does not know about user namespaces and therefore the account that creates the container requires the &lt;code&gt;anyuid&lt;/code&gt; SCC. These deficiencies still exist today.&lt;/p&gt;
&lt;h3 id=&quot;user-namespace-support-in-openshift-4.7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-03-openshift-4.7-user-namespaces.html&quot;&gt;&lt;em&gt;User namespace support in OpenShift 4.7&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#user-namespace-support-in-openshift-4.7&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I continued my investigation after the release of OpenShift 4.7. With the aforementioned caveats, user namespaces work. I also noted an inconsistent treatment of &lt;code&gt;securityContext&lt;/code&gt;: specifying &lt;code&gt;runAsUser&lt;/code&gt; in the &lt;code&gt;PodSpec&lt;/code&gt; maps the container’s UID &lt;code&gt;0&lt;/code&gt; to host UID &lt;code&gt;0&lt;/code&gt;—a dangerous configuration.&lt;/p&gt;
&lt;p&gt;More recently, I noticed that the &lt;code&gt;userns-mode&lt;/code&gt; annotation I was using included &lt;code&gt;map-to-root=true&lt;/code&gt;. I now understand that it is this configuration that causes this mapping behaviour. I no longer consider it particularly serious. Ideally the SCC enforcement should learn about user namespaces, and prevent unprivileged users from creating containers that run as &lt;code&gt;root&lt;/code&gt; (or other system accounts) on the host.&lt;/p&gt;
&lt;h3 id=&quot;multiple-users-in-user-namespaces-on-openshift&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-10-openshift-user-namespace-multi-user.html&quot;&gt;&lt;em&gt;Multiple users in user namespaces on OpenShift&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#multiple-users-in-user-namespaces-on-openshift&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I verified that workloads that run processes under a variety of user accounts work as expected in user namespaces. I did not use a &lt;em&gt;systemd&lt;/em&gt;-based workload to verify this.&lt;/p&gt;
&lt;h3 id=&quot;systemd-containers-on-openshift-with-cgroups-v2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-30-openshift-cgroupv2-systemd.html&quot;&gt;&lt;em&gt;systemd containers on OpenShift with cgroups v2&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#systemd-containers-on-openshift-with-cgroups-v2&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I observed that systemd-based workloads run successfully in OpenShift when executed as UID 0 &lt;em&gt;on the host&lt;/em&gt;. Such containers can only be created by accounts granted privileged SCCs (e.g. &lt;code&gt;anyuid&lt;/code&gt;). When running the container under other UIDs, &lt;em&gt;systemd&lt;/em&gt; can’t run because it does not have write permission on the container’s cgroup directory.&lt;/p&gt;
&lt;h3 id=&quot;using-runc-to-explore-the-oci-runtime-specification&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-05-27-oci-runtime-spec-runc.html&quot;&gt;&lt;em&gt;Using &lt;code&gt;runc&lt;/code&gt; to explore the OCI Runtime Specification&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#using-runc-to-explore-the-oci-runtime-specification&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I investigated how &lt;code&gt;runc&lt;/code&gt; (the OCI runtime used in OpenShift) operates, and how it creates cgroups. I identified some potential ways to change the ownership of the container cgroup to the &lt;em&gt;container’s&lt;/em&gt; UID 0.&lt;/p&gt;
&lt;h3 id=&quot;systemd-cgroups-and-subuid-ranges&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-06-09-systemd-cgroups-subuid.html&quot;&gt;&lt;em&gt;systemd, cgroups and subuid ranges&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#systemd-cgroups-and-subuid-ranges&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I discovered that the systemd &lt;em&gt;transient unit API&lt;/em&gt; (which &lt;code&gt;runc&lt;/code&gt; uses to create container cgroups) allows specifying a different owner for the new cgroup. Unfortunately, the user must be “known”, in the form of a &lt;code&gt;passwd&lt;/code&gt; entity via NSSwitch. A &lt;a href=&quot;https://github.com/systemd/systemd/issues/19781&quot;&gt;proposal to relax this requirement&lt;/a&gt; was provisionally rejected. Other approaches include writing an NSSwitch module to synthesise &lt;code&gt;passwd&lt;/code&gt; entities for subuids, or modifying &lt;code&gt;runc&lt;/code&gt; to &lt;code&gt;chown(2)&lt;/code&gt; the container cgroup after systemd creates it. I decided to experiment with the latter approach.&lt;/p&gt;
&lt;h2 id=&quot;modifying-runc-to-chown-the-container-cgroup&quot;&gt;Modifying &lt;code&gt;runc&lt;/code&gt; to &lt;code&gt;chown&lt;/code&gt; the container cgroup &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#modifying-runc-to-chown-the-container-cgroup&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The main challenge in modifying &lt;code&gt;runc&lt;/code&gt; was getting my head around the unfamiliar codebase. The actual operations are straightforward. There are two main aspects.&lt;/p&gt;
&lt;p&gt;The first aspect is to compute the appropriate owner UID for the cgroup, and tell it to the cgroup manager object. I &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-06-09-systemd-cgroups-subuid.html#determining-the-uid&quot;&gt;described the algorithm&lt;/a&gt; in a previous post. The &lt;code&gt;config.HostRootUID()&lt;/code&gt; method already implements this computation. I was able to reuse it.&lt;/p&gt;
&lt;p&gt;The second aspect is to actually &lt;code&gt;chown(2)&lt;/code&gt; the relevant cgroup files and directories. I previously observed systemd’s behaviour when creating units owned by arbitrary users. systemd &lt;code&gt;chown&lt;/code&gt;s the container’s cgroup directory, and the &lt;code&gt;cgroup.procs&lt;/code&gt;, &lt;code&gt;cgroup.subtree_control&lt;/code&gt; and &lt;code&gt;cgroup.threads&lt;/code&gt; files within that directory. &lt;code&gt;runc&lt;/code&gt; will do the same. The cgroup manager object already knows the path to the container cgroup directory. It changes the owner of the directory and same three files as &lt;em&gt;systemd&lt;/em&gt; to the relevant user.&lt;/p&gt;
&lt;h2 id=&quot;demo&quot;&gt;Demo &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#demo&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Following is a step-by-step demonstration starting with a fresh deployment of OpenShift &lt;code&gt;4.7.20&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get clusterversion
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.7.20    True        False         8m52s   Cluster version is 4.7.20&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;There is a &lt;a href=&quot;https://github.com/cri-o/cri-o/issues/5077&quot;&gt;regression&lt;/a&gt; in OpenShift 4.8.0 that prevents Pod annotations from being propagated to container OCI configurations. As a consequence, &lt;code&gt;runc&lt;/code&gt; does not receive the annotations that trigger the experimental behaviour. I filed a &lt;a href=&quot;https://github.com/cri-o/cri-o/pull/5078&quot;&gt;pull request&lt;/a&gt; that fixes the issue. The patch was accepted and the fix released in OpenShift 4.8.4.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The latent credential is the cluster &lt;code&gt;admin&lt;/code&gt; user. Where relevant, I use the &lt;code&gt;oc --as USER&lt;/code&gt; option to execute commands as other users.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc whoami
system:admin&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;install-modified-runc-package&quot;&gt;Install modified &lt;code&gt;runc&lt;/code&gt; package &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#install-modified-runc-package&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;List the nodes in the cluster:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get node
NAME                                       STATUS   ROLES    AGE   VERSION
ci-ln-jqbnbfk-f76d1-gnkkv-master-0         Ready    master   61m   v1.20.0+01c9f3f
ci-ln-jqbnbfk-f76d1-gnkkv-master-1         Ready    master   61m   v1.20.0+01c9f3f
ci-ln-jqbnbfk-f76d1-gnkkv-master-2         Ready    master   61m   v1.20.0+01c9f3f
ci-ln-jqbnbfk-f76d1-gnkkv-worker-a-vrbnv   Ready    worker   52m   v1.20.0+01c9f3f
ci-ln-jqbnbfk-f76d1-gnkkv-worker-b-dxk6k   Ready    worker   52m   v1.20.0+01c9f3f
ci-ln-jqbnbfk-f76d1-gnkkv-worker-c-db89w   Ready    worker   52m   v1.20.0+01c9f3f&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For each worker node, open a node debug shell and use &lt;code&gt;rpm-ostree override replace&lt;/code&gt; to install the modified &lt;code&gt;runc&lt;/code&gt; (one worker shown):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/ci-ln-jqbnbfk-f76d1-gnkkv-worker-a-vrbnv
Starting pod/ci-ln-jqbnbfk-f76d1-gnkkv-worker-a-vrbnv-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.0.32.2
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# rpm-ostree override replace https://ftweedal.fedorapeople.org/runc-1.0.0-990.rhaos4.8.gitcd80260.el8.x86_64.rpm
Downloading 'https://ftweedal.fedorapeople.org/runc-1.0.0-990.rhaos4.8.gitcd80260.el8.x86_64.rpm'... done!
Checking out tree 9767154... done
No enabled rpm-md repositories.
Importing rpm-md... done
Resolving dependencies... done
Applying 1 override
Processing packages... done
Running pre scripts... done
Running post scripts... done
Running posttrans scripts... done
Writing rpmdb... done
Writing OSTree commit... done
Staging deployment... done
Upgraded:
  runc 1.0.0-96.rhaos4.8.gitcd80260.el8 -&amp;gt; 1.0.0-990.rhaos4.8.gitcd80260.el8
Run &amp;quot;systemctl reboot&amp;quot; to start a reboot&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;Instead of installing the modified &lt;code&gt;runc&lt;/code&gt; on all worker nodes, you could update one node and use &lt;code&gt;.spec.nodeAffinity&lt;/code&gt; in the &lt;code&gt;PodSpec&lt;/code&gt; to force the pod to run on that node.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Don’t worry about the restart right now (it will happen in the next step). Exit the debug shell:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# exit
sh-4.2# exit

Removing debug pod ...&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;enable-user-namespaces-and-cgroups-v2&quot;&gt;Enable user namespaces and cgroups v2 &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#enable-user-namespaces-and-cgroups-v2&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The following &lt;code&gt;MachineConfig&lt;/code&gt; enables cgroups v2 and CRI-O annotation-based user namespace support:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb6&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb6-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; machineconfiguration.openshift.io/v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; MachineConfig&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;machineconfiguration.openshift.io/role&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; worker&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; userns-cgv2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;kernelArguments&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; systemd.unified_cgroup_hierarchy=1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; cgroup_no_v1=&amp;quot;all&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; psi=1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;ignition&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-14&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;3.1.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-16&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-16&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-17&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-17&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; /etc/crio/crio.conf.d/99-crio-userns.conf&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-18&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-18&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-19&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-19&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-20&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-20&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; data:text/plain;charset=utf-8;base64,W2NyaW8ucnVudGltZS5ydW50aW1lcy5ydW5jXQphbGxvd2VkX2Fubm90YXRpb25zPVsiaW8ua3ViZXJuZXRlcy5jcmktby51c2VybnMtbW9kZSJdCg==&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-21&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-21&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; /etc/subuid&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-22&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-22&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-23&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-23&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-24&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-24&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; data:text/plain;charset=utf-8;base64,Y29yZToxMDAwMDA6NjU1MzYKY29udGFpbmVyczoyMDAwMDA6MjY4NDM1NDU2Cg==&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-25&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-25&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; /etc/subgid&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-26&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-26&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-27&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-27&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-28&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-28&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;          &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; data:text/plain;charset=utf-8;base64,Y29yZToxMDAwMDA6NjU1MzYKY29udGFpbmVyczoyMDAwMDA6MjY4NDM1NDU2Cg==&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The file &lt;code&gt;/etc/crio/crio.conf.d/99-crio-userns.conf&lt;/code&gt; enables CRI-O’s annotation-based user namespace support. Its content (base64-encoded in the &lt;code&gt;MachineConfig&lt;/code&gt;) is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb7&quot;&gt;&lt;pre class=&quot;sourceCode ini&quot;&gt;&lt;code class=&quot;sourceCode ini&quot;&gt;&lt;span id=&quot;cb7-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;[crio.runtime.runtimes.runc]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;dt&quot;&gt;allowed_annotations&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;[&amp;quot;io.kubernetes.cri-o.userns-mode&amp;quot;]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;MachineConfig&lt;/code&gt; also overrides &lt;code&gt;/etc/subuid&lt;/code&gt; and &lt;code&gt;/etc/subgid&lt;/code&gt;, defining sub-id ranges for user namespaces. The content is the same for both files:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;core:100000:65536
containers:200000:268435456&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create the &lt;code&gt;MachineConfig&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f machineconfig-userns-cgv2.yaml
machineconfig.machineconfiguration.openshift.io/userns-cgv2 created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wait for the Machine Config Operator to apply the changes and reboot the worker nodes:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc wait mcp/worker --for condition=updated --timeout=-1s
machineconfigpool.machineconfiguration.openshift.io/worker condition met&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It will take several minutes, as worker nodes get rebooted one a time.&lt;/p&gt;
&lt;h3 id=&quot;create-project-and-user&quot;&gt;Create project and user &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#create-project-and-user&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Create a new project called &lt;code&gt;test&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc new-project test
Now using project &amp;quot;test&amp;quot; on server &amp;quot;https://api.ci-ln-jqbnbfk-f76d1.origin-ci-int-gce.dev.openshift.com:6443&amp;quot;.

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app ruby~https://github.com/sclorg/ruby-ex.git

to build a new example application in Python. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output shows the public domain name of this cluster: &lt;code&gt;ci-ln-jqbnbfk-f76d1.origin-ci-int-gce.dev.openshift.com&lt;/code&gt;. We need to know this for creating the route in the next step.&lt;/p&gt;
&lt;p&gt;Create a user called &lt;code&gt;test&lt;/code&gt;. Grant it &lt;code&gt;admin&lt;/code&gt; role on project &lt;code&gt;test&lt;/code&gt;, and the &lt;code&gt;anyuid&lt;/code&gt; Security Context Constraint (SCC) privilege:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create user test
user.user.openshift.io/test created
% oc adm policy add-role-to-user admin test
clusterrole.rbac.authorization.k8s.io/admin added: &amp;quot;test&amp;quot;
% oc adm policy add-scc-to-user anyuid test
securitycontextconstraints.security.openshift.io/anyuid added to: [&amp;quot;test&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;create-service-and-route&quot;&gt;Create service and route &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#create-service-and-route&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Create a service to provide HTTP access to pods matching the &lt;code&gt;app: nginx&lt;/code&gt; selector:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb13&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb13-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Service&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; TCP&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb13-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;80&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f service-nginx.yaml
service/nginx created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following route definition will provide HTTP ingress from outside the cluster:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb15&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb15-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Route&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx.apps.ci-ln-jqbnbfk-f76d1.origin-ci-int-gce.dev.openshift.com&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Service&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb15-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the &lt;code&gt;host&lt;/code&gt; field. Its value is &lt;code&gt;nginx.apps.$CLUSTER_DOMAIN&lt;/code&gt;. Change it to the proper value for your cluster, then create the route:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f route-nginx.yaml
route.route.openshift.io/nginx created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is no pod to route the traffic to… yet.&lt;/p&gt;
&lt;h3 id=&quot;create-pod&quot;&gt;Create pod &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#create-pod&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The pod specification is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb17&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb17-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Pod&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;openshift.io/scc&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; restricted&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;io.kubernetes.cri-o.userns-mode&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;auto:size=65536&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sysctls&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;net.ipv4.ping_group_range&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-14&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;0 65535&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-16&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-16&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-17&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-17&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; quay.io/ftweedal/test-nginx:latest&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-18&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb17-18&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;tty&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Create the pod:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc --as test create -f pod-nginx.yaml
pod/nginx created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a few seconds, the pod is running:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get -o json pod/nginx | jq .status.phase
&amp;quot;Running&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tail the pod’s log. Observe the final lines of systemd boot output and the login prompt:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc logs --tail 10 pod/nginx
[  OK  ] Started The nginx HTTP and reverse proxy server.
[  OK  ] Reached target Multi-User System.
[  OK  ] Reached target Graphical Interface.
         Starting Update UTMP about System Runlevel Changes...
[  OK  ] Finished Update UTMP about System Runlevel Changes.

Fedora 33 (Container Image)
Kernel 4.18.0-305.3.1.el8_4.x86_64 on an x86_64 (console)

nginx login: %&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;Without &lt;code&gt;tty: true&lt;/code&gt; in the &lt;code&gt;Container&lt;/code&gt; spec, the pod won’t produce any output and &lt;code&gt;oc logs&lt;/code&gt; won’t have anything to show.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The log tail also shows that systemd started the &lt;code&gt;nginx&lt;/code&gt; service. We already set up a &lt;code&gt;route&lt;/code&gt; in the previous step. Use &lt;code&gt;curl&lt;/code&gt; to issue an HTTP request and verify that the service is running properly:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% curl --head \
    nginx.apps.ci-ln-jqbnbfk-f76d1.origin-ci-int-gce.dev.openshift.com
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Wed, 21 Jul 2021 06:55:38 GMT
Content-Type: text/html
Content-Length: 5564
Last-Modified: Mon, 27 Jul 2020 22:20:49 GMT
ETag: &amp;quot;5f1f5341-15bc&amp;quot;
Accept-Ranges: bytes
Set-Cookie: 6cf5f3bc2fa4d24f45018c591d3617c3=f114e839b2eef9cdbe00856f18a06336; path=/; HttpOnly
Cache-control: private&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;verify-sandbox&quot;&gt;Verify sandbox &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#verify-sandbox&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now let’s verify that the container is indeed running in a user namespace. Container UIDs must map to unprivileged UIDs on the host. Query the worker node on which the pod is running, and its CRI-O container ID:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get -o json pod/nginx | jq \
    '.spec.nodeName, .status.containerStatuses[0].containerID'
&amp;quot;ci-ln-jqbnbfk-f76d1-gnkkv-worker-c-db89w&amp;quot;
&amp;quot;cri-o://bf2b3d15cbd6944366e29927988ba30bc36d1efee00c28fb4c6d5b2036e462b0&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start a debug shell on the node and query the PID of the container init process:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/ci-ln-jqbnbfk-f76d1-gnkkv-worker-c-db89w
Starting pod/ci-ln-jqbnbfk-f76d1-gnkkv-worker-c-db89w-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.0.32.4
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# crictl inspect bf2b3d | jq .info.pid
7759&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Query the UID map and process tree of the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# cat /proc/7759/uid_map
         0     200000      65536
sh-4.4# pgrep --ns 7759 | xargs ps -o user,pid,cmd --sort pid
USER         PID CMD
200000      7759 /sbin/init
200000      7796 /usr/lib/systemd/systemd-journald
200193      7803 /usr/lib/systemd/systemd-resolved
200000      7806 /usr/lib/systemd/systemd-homed
200000      7807 /usr/lib/systemd/systemd-logind
200081      7809 /usr/bin/dbus-broker-launch --scope system --audit
200000      7812 /sbin/agetty -o -p -- \u --noclear --keep-baud console 115200,38400,9600 xterm
200081      7813 dbus-broker --log 4 --controller 9 --machine-id 2f2fcc4033c5428996568ca34219c72a --max-bytes 5
200000      7815 nginx: master process /usr/sbin/nginx
200999      7816 nginx: worker process
200999      7817 nginx: worker process
200999      7818 nginx: worker process
200999      7819 nginx: worker process&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This confirms that the container has a user namespace. The container’s UID range is &lt;code&gt;0&lt;/code&gt;–&lt;code&gt;65535&lt;/code&gt;, which maps to the host UID range &lt;code&gt;200000&lt;/code&gt;–&lt;code&gt;265535&lt;/code&gt;. The &lt;code&gt;ps&lt;/code&gt; output shows various services running under systemd, running under unprivileged host UIDs in this range.&lt;/p&gt;
&lt;p&gt;So, everything is running as expected. One last thing: let’s look at the cgroup ownership. Query the container’s &lt;code&gt;cgroupsPath&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# crictl inspect bf2b3d | jq .info.runtimeSpec.linux.cgroupsPath
&amp;quot;kubepods-besteffort-podc7f11ee7_e178_4dea_9d8c_c005ad648988.slice:crio:bf2b3d15cbd6944366e29927988ba30bc36d1efee00c28fb4c6d5b2036e462b0&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The value isn’t a filesystem path. &lt;code&gt;runc&lt;/code&gt; interprets it relative to an implementation-defined location. We expect the cgroup directory and the three files mentioned earlier to be owned by the user that maps to UID &lt;code&gt;0&lt;/code&gt; in the container’s user namespace. In my case, that’s &lt;code&gt;200000&lt;/code&gt;. We also expect to see scopes and slices created by systemd &lt;strong&gt;in the container&lt;/strong&gt; to be owned by the same user.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# ls -ali /sys/fs/cgroup\
/kubepods.slice/kubepods-besteffort.slice\
/kubepods-besteffort-podc7f11ee7_e178_4dea_9d8c_c005ad648988.slice\
/crio-bf2b3d15cbd6944366e29927988ba30bc36d1efee00c28fb4c6d5b2036e462b0.scope \
    | grep 200000
14755 drwxr-xr-x.  5 200000 root   0 Jul 21 06:00 .
14757 -rw-r--r--.  1 200000 root   0 Jul 21 06:00 cgroup.procs
14760 -rw-r--r--.  1 200000 root   0 Jul 21 06:00 cgroup.subtree_control
14758 -rw-r--r--.  1 200000 root   0 Jul 21 06:00 cgroup.threads
14806 drwxr-xr-x.  2 200000 200000 0 Jul 21 06:00 init.scope
14835 drwxr-xr-x. 11 200000 200000 0 Jul 21 06:15 system.slice
14922 drwxr-xr-x.  2 200000 200000 0 Jul 21 06:00 user.slice&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the &lt;em&gt;inode&lt;/em&gt; of the container cgroup directory: &lt;code&gt;14755&lt;/code&gt;. We can query the inode and ownership of &lt;code&gt;/sys/fs/cgroup&lt;/code&gt; &lt;em&gt;within the pod&lt;/em&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc exec pod/nginx -- ls -ldi /sys/fs/cgroup
14755 drwxr-xr-x. 5 root nobody 0 Jul 21 06:00 /sys/fs/cgroup&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The inode is the same; this is indeed the same cgroup. But within the container’s user namespace, the owner appears as &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This concludes the verification steps. With my modified version of &lt;code&gt;runc&lt;/code&gt;, systemd-based workloads are indeed working properly in user namespaces.&lt;/p&gt;
&lt;h2 id=&quot;next-steps&quot;&gt;Next steps &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#next-steps&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I submitted a &lt;a href=&quot;https://github.com/opencontainers/runc/pull/3057&quot;&gt;pull request&lt;/a&gt; with these changes. It remains to be seen if the general approach will be accepted, but initial feedback is positive. Some implementation changes are needed. I might have to hide the behaviour behind a feature gate (e.g. to be activated via an annotation). I also need to write tests and documentation.&lt;/p&gt;
&lt;p&gt;I also need to raise a ticket for the SCC issue. The requirement for &lt;code&gt;RunAsAny&lt;/code&gt; (which is granted by the &lt;code&gt;anyuid&lt;/code&gt; SCC) should be relaxed when the sandbox has a user namespace. The SCC enforcement machinery needs to be enhanced to understand user namespaces, so that unprivileged OpenShift user accounts can run workloads in them.&lt;/p&gt;
&lt;p&gt;It would be nice to find a way to avoid the sysctl override to allow the container user to use &lt;code&gt;ping&lt;/code&gt;. This is a much lower priority.&lt;/p&gt;
&lt;p&gt;Alongside these matters, I can begin testing the FreeIPA container in the test environment. Although systemd is now working, I need to see if the FreeIPA’s constituent services will run properly. I anticipate that I will need to tweak the Pod configuration somewhat. But are there more runtime capability gaps waiting to be discovered? I don’t have a particular suspicion about it, but I do need to know for certain, one way or the other. So expect another blog post soon!&lt;/p&gt;</description>
	<pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: FreeIPA on OpenShift: July 2021 update</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-07-21-freeipa-on-openshift-update.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-07-21-freeipa-on-openshift-update.html</link>
	<description>&lt;h1 id=&quot;freeipa-on-openshift-july-2021-update&quot;&gt;FreeIPA on OpenShift: July 2021 update&lt;/h1&gt;
&lt;p&gt;Over the last year I’ve done a lot of investigations into OpenShift, and container runtimes more generally. The driver of this work is the FreeIPA on OpenShift project (known within Red Hat as IDMOCP). I published the results of my investigations in numerous blog posts, but I have not yet written much about &lt;em&gt;why&lt;/em&gt; we are doing this at all.&lt;/p&gt;
&lt;p&gt;So it’s time to fix that. In this short post I discuss why we want FreeIPA on OpenShift, and the major decision that put us on our current implementation path.&lt;/p&gt;
&lt;p&gt;FreeIPA is a centralised identity management system for the enterprise. You enrol users, hosts and services, and configure access policies and other security mechanisms. The system provides authentication and policy enforcement mechanisms. It is similar to Microsoft Active Directory (and indeed can integrate with AD). FreeIPA is a complex system with lots of components including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LDAP server (389 DS / RHDS)&lt;/li&gt;
&lt;li&gt;Kerberos KDC (MIT Kerberos)&lt;/li&gt;
&lt;li&gt;Certificate authority (Dogtag / RHCS)&lt;/li&gt;
&lt;li&gt;HTTP API (Apache httpd and a lot of Python code)&lt;/li&gt;
&lt;li&gt;Host client daemon (SSSD)&lt;/li&gt;
&lt;li&gt;several smaller supporting services&lt;/li&gt;
&lt;li&gt;installation and administration tools&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FreeIPA is available on Fedora and RHEL. You install the RPMs and the installation program configures the system. It is intended to be deployed on a dedicated machine (VM or bare metal).&lt;/p&gt;
&lt;p&gt;We are motivated to support FreeIPA on OpenShift for several reasons, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Easily providing identity services to applications running on OpenShift.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Leveraging OpenShift and Kubernetes orchestration, scalaing and management features to improve robustness and reduce management overhead of FreeIPA deployments.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Offering FreeIPA, hosted on OpenShift, as a managed service.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Understandably, moving such an application to OpenShift is a non-trivial task. At the beginning of this effort, we had to decide the main implementation approach. There were three options:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;Put the whole system in a single “monolithic container”, with systemd as the init process. At the time (and still today) OpenShift only supports running systemd workloads in privileged containers, which is not acceptable. The runtime needs to evolve to support this use case. Work on &lt;em&gt;some&lt;/em&gt; of the missing features (such as user namespaces and cgroups v2) was already underway.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deploy different parts of the FreeIPA system in different containers, running unprivileged. This is a fundamental shift from the current architecture and a huge up-front engineering effort. Also, the current architecture has to be maintained and supported for a long time (&amp;gt;10 years). So this approach brings a substantial ongoing cost in maintaining two architectures of the same application. On a technical level, this approach is feasible today.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use a VM-based workload (Kata / OpenShift Sandboxed Containers). This option probably has the lowest up-front and ongoing engineering costs. But it requires a bare metal cluster or nested virtualisation, which is not available from most cloud providers. By extension, &lt;a href=&quot;https://www.openshift.com/products/dedicated/&quot;&gt;OpenShift Dedicated (OSD)&lt;/a&gt; also does not supported it. Red Hat managed services run on OSD. Offering a managed service is one of the motivators of our effort. So at this time, VM-based workloads are not an option for us.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As a small team, and considering the business reality of the existing offering as part of RHEL, we decided to pursue the “monolithic container” approach. We are depending on the OpenShift runtime evolving to a point where it can support fully isolated systemd-based workloads. And that is why I have invested much of the last 12 months in understanding container runtimes and pushing their limits.&lt;/p&gt;
&lt;p&gt;Our approach is not “cloud native” and indeed many people have expressed alarm or confusion when we tell them what we are doing. Certainly, if we were designing FreeIPA from the ground up in today’s world, it would look very different from the current architecture. But this is the reality: if you want customers to bring their mature, complex applications onto OpenShift, don’t expect them to spend big money and assume big risk to rearchitect the application to fit the new environment.&lt;/p&gt;
&lt;p&gt;What customers actually need is to be able to bring the application across more or less as-is. Then they can realise the benefits (automation, monitoring, scaling, etc) &lt;em&gt;incrementally&lt;/em&gt;, with lower up-front costs and less risk.&lt;/p&gt;
&lt;p&gt;If my claims are correct, then proper systemd workload support in OpenShift will be a Very Big Deal. But even if I’m wrong, it is still critical for our FreeIPA on OpenShift effort. And it is achievable. In my next post I’ll demonstrate my working proof of concept for user-namespaced systemd workloads on OpenShift.&lt;/p&gt;</description>
	<pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: Live-testing changes in OpenShift clusters</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-06-29-openshift-live-changes.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-06-29-openshift-live-changes.html</link>
	<description>&lt;h1 id=&quot;live-testing-changes-in-openshift-clusters&quot;&gt;Live-testing changes in OpenShift clusters&lt;/h1&gt;
&lt;p&gt;I have been hacking on the &lt;a href=&quot;https://github.com/opencontainers/runc&quot;&gt;&lt;code&gt;runc&lt;/code&gt;&lt;/a&gt; container runtime. So how do I test my changes in an OpenShift cluster?&lt;/p&gt;
&lt;p&gt;One option is to compose a &lt;code&gt;machine-os-content&lt;/code&gt; release via &lt;a href=&quot;https://github.com/coreos/coreos-assembler&quot;&gt;&lt;em&gt;coreos-assembler&lt;/em&gt;&lt;/a&gt;. Then you can deploy or upgrade a cluster with that release. Indeed, this approach is &lt;em&gt;necessary&lt;/em&gt; for testing installation and upgrades. It also seems useful for publishing modified versions for other people to test. But it is a heavyweight and time consuming option.&lt;/p&gt;
&lt;p&gt;For development I want a more lightweight approach. In this post I’ll demonstrate how to use the &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; and &lt;code&gt;rpm-ostree override replace&lt;/code&gt; commands to test changes in a live OpenShift cluster.&lt;/p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#background&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;OpenShift runs on CoreOS. CoreOS uses &lt;a href=&quot;https://en.wikipedia.org/wiki/OSTree&quot;&gt;&lt;em&gt;OSTree&lt;/em&gt;&lt;/a&gt; to manage the filesystem. Most of the filesystem is immutable. When upgrading, a new filesystem is prepared before rebooting the system. The old filesystem is preserved, so it is easy to roll back.&lt;/p&gt;
&lt;p&gt;So I can’t just log onto an OpenShift node and replace &lt;code&gt;/usr/bin/runc&lt;/code&gt; with my modified version. Nevertheless, I have seen &lt;a href=&quot;https://github.com/openshift/machine-config-operator/blob/master/docs/HACKING.md#directly-applying-changes-live-to-a-node&quot;&gt;references&lt;/a&gt; to the &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; command. It is supposed to provide a writable overlayfs on &lt;code&gt;/usr&lt;/code&gt;, so that you can test modifications. Changes are lost upon reboot, but that’s fine for testing.&lt;/p&gt;
&lt;p&gt;There’s also the &lt;code&gt;rpm-ostree override replace …&lt;/code&gt; command. This command works on the level of RPM packages. It allows you to install new packages or replace or remove packages. Changes persist across reboots, but it is easy to roll back to the &lt;em&gt;pristine&lt;/em&gt; state of the current CoreOS release.&lt;/p&gt;
&lt;p&gt;The rest of this article explores how to use these two commands to apply changes to the cluster.&lt;/p&gt;
&lt;h2 id=&quot;usroverlay-via-debug-container-doesnt-work&quot;&gt;&lt;code&gt;usroverlay&lt;/code&gt; via debug container (doesn’t work) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#usroverlay-via-debug-container-doesnt-work&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I first attempted to use &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; in a node debug pod.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/worker-a
Starting pod/worker-a-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.0.128.2
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# rpm-ostree usroverlay
Development mode enabled.  A writable overlayfs is now mounted on /usr.
All changes there will be discarded on reboot.
sh-4.4# touch /usr/bin/foo
touch: cannot touch '/usr/bin/foo': Read-only file system&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; command succeeded. But &lt;code&gt;/usr&lt;/code&gt; remained read-only. The debug container has its own mount namespace, which was unaffected. I guess that I need to log into the node directly to use the writable &lt;code&gt;/usr&lt;/code&gt; overlay. Perhaps it is also necessary to execute &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; as an unconfined user (in the SELinux sense). I &lt;strong&gt;restarted the node&lt;/strong&gt; to begin afresh:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# reboot

Removing debug pod ...&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;usroverlay-via-ssh&quot;&gt;&lt;code&gt;usroverlay&lt;/code&gt; via SSH &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#usroverlay-via-ssh&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For the next attempt, I logged into the worker node over SSH. The first step was to add the SSH public key to the &lt;code&gt;core&lt;/code&gt; user’s &lt;code&gt;authorized_keys&lt;/code&gt; file. Roberto Carratalá’s &lt;a href=&quot;https://rcarrata.com/openshift/update-workers-ssh/&quot;&gt;helpful blog post&lt;/a&gt; explains how to do this. I will recap the critical bits.&lt;/p&gt;
&lt;p&gt;SSH keys can be added via &lt;code&gt;MachineConfig&lt;/code&gt; objects, which must also specify the machine role (e.g. &lt;code&gt;worker&lt;/code&gt;). The Machine Config Operator will only add keys to the &lt;code&gt;core&lt;/code&gt; user. Multiple keys can be specified, across multiple &lt;code&gt;MachineConfig&lt;/code&gt; objects—all the keys in matching objects will be included.&lt;/p&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;I don’t have direct network access to the worker node. So how could I log in over SSH? I generated a key &lt;strong&gt;&lt;em&gt;in the node debug shell&lt;/em&gt;&lt;/strong&gt;, and will log in from there!&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Created directory '/root/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:jAmv…NMnY root@worker-a
sh-4.4# cat ~/.ssh/id_rsa.pub
ssh-rsa AAAA…4OU= root@worker-a&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;The following &lt;code&gt;MachineConfig&lt;/code&gt; adds the SSH key for user &lt;code&gt;core&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb4&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb4-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; machineconfiguration.openshift.io/v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; MachineConfig&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; ssh-authorized-keys-worker&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;machineconfiguration.openshift.io/role&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; worker&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;ignition&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;3.2.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;passwd&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;users&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; core&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-14&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sshAuthorizedKeys&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb4-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; ssh-rsa AAAA…40U= root@worker-a&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I created the &lt;code&gt;MachineConfig&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f machineconfig-ssh-worker.yaml
machineconfig.machineconfiguration.openshift.io/ssh-authorized-keys created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the node debug shell, I observed that Machine Config Operator applied the change after a few seconds. It did not restart the worker node. My key was added alongside a key defined in some other &lt;code&gt;MachineConfig&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# cat /var/home/core/.ssh/authorized_keys
ssh-rsa AAAA…jjNV devenv

ssh-rsa AAAA…4OU= root@worker-a&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I could log in over SSH:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# ssh core@$(hostname)
The authenticity of host 'worker-a (10.0.128.2)' can't be established.
ECDSA key fingerprint is SHA256:LUaZOleqVFunmLCp4/E1naIQ+E5BpmVp0gcsXHGacPE.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'worker-a,10.0.128.2' (ECDSA) to the list of known hosts.
Red Hat Enterprise Linux CoreOS 48.84.202106231817-0
  Part of OpenShift 4.8, RHCOS is a Kubernetes native operating system
  managed by the Machine Config Operator (`clusteroperator/machine-config`).

WARNING: Direct SSH access to machines is not recommended; instead,
make configuration changes via `machineconfig` objects:
  https://docs.openshift.com/container-platform/4.8/architecture/architecture-rhcos.html

---
[core@worker-a ~]$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user is unconfined and I can see the normal, read-only (&lt;code&gt;ro&lt;/code&gt;) &lt;code&gt;/usr&lt;/code&gt; mount (but no overlay):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;[core@worker-a ~]$ id -Z
unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
[core@worker-a ~]$ mount |grep &amp;quot;on /usr&amp;quot;
/dev/sda4 on /usr type xfs (ro,relatime,seclabel,attr2,inode64,logbufs=8,logbsize=32k,prjquota)
overlay on /usr type overlay (rw,relatime,seclabel,lowerdir=usr,upperdir=/var/tmp/ostree-unlock-ovl.KZ4V50/upper,workdir=/var/tmp/ostree-unlock-ovl.KZ4V50/work)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I executed &lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; via &lt;code&gt;sudo&lt;/code&gt;. After that, a read-write (&lt;code&gt;rw&lt;/code&gt;) overlay filesystem is visible:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;[core@worker-a ~]$ sudo rpm-ostree usroverlay
Development mode enabled.  A writable overlayfs is now mounted on /usr.
All changes there will be discarded on reboot.
[core@worker-a ~]$ mount |grep &amp;quot;on /usr&amp;quot;
/dev/sda4 on /usr type xfs (ro,relatime,seclabel,attr2,inode64,logbufs=8,logbsize=32k,prjquota)
overlay on /usr type overlay (rw,relatime,seclabel,lowerdir=usr,upperdir=/var/tmp/ostree-unlock-ovl.TCPM50/upper,workdir=/var/tmp/ostree-unlock-ovl.TCPM50/work)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And it is indeed writable. I made a copy of the original &lt;code&gt;runc&lt;/code&gt; binary, then installed my modified version:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;[core@worker-a ~]$ sudo cp /usr/bin/runc /usr/bin/runc.orig
[core@worker-a ~]$ sudo curl -Ss -o /usr/bin/runc \
    https://ftweedal.fedorapeople.org/runc&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;digression-use-a-buildroot&quot;&gt;Digression: use a buildroot &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#digression-use-a-buildroot&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;runc&lt;/code&gt; executable I installed on the previous step didn’t work. I had built it on my workstation, against a too-new version of &lt;em&gt;glibc&lt;/em&gt;. The OpenShift node (which was running RHCOS 4.8, based on RHEL 8.4) was unable to link &lt;code&gt;runc&lt;/code&gt;. Therefore it could not run &lt;em&gt;any&lt;/em&gt; container workloads. I was able to SSH in from another node and reboot, discarding the transient change in the &lt;code&gt;usroverlay&lt;/code&gt; and restoring the node to a functional state.&lt;/p&gt;
&lt;p&gt;All of this is obvious in hindsight. You have to build the program for the environment in which it will be executed. In my case, it was easiest to do this via Brew or Koji. I cloned the dist-git repository (via the &lt;code&gt;fedpkg&lt;/code&gt; or &lt;code&gt;rhpkg&lt;/code&gt; tool), created patches and updated the &lt;code&gt;runc.spec&lt;/code&gt; file. Then I built the SRPM (&lt;code&gt;.src.rpm&lt;/code&gt;) and started a scratch build in Brew. After the build completed I made the resulting &lt;code&gt;.rpm&lt;/code&gt; publicly available, so that it can be fetched from the OpenShift cluster.&lt;/p&gt;
&lt;h2 id=&quot;override-replace-via-node-debug-container&quot;&gt;&lt;code&gt;override replace&lt;/code&gt; via node debug container &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#override-replace-via-node-debug-container&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I now have my modified &lt;code&gt;runc&lt;/code&gt; in an RPM package. So I can use &lt;code&gt;rpm-ostree override replace&lt;/code&gt; to install it. In a debug node on the host:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# rpm-ostree override replace \
  https://ftweedal.fedorapeople.org/runc-1.0.0-98.rhaos4.8.gitcd80260.el8.x86_64.rpm
Downloading 'https://ftweedal.fedorapeople.org/runc-1.0.0-98.rhaos4.8.gitcd80260.el8.x86_64.rpm'... done!
Checking out tree eb6dd3b... done
No enabled rpm-md repositories.
Importing rpm-md... done
Resolving dependencies... done
Applying 1 override
Processing packages... done
Running pre scripts... done
Running post scripts... done
Running posttrans scripts... done
Writing rpmdb... done
Writing OSTree commit... done
Staging deployment... done
Upgraded:
  runc 1.0.0-97.rhaos4.8.gitcd80260.el8 -&amp;gt; 1.0.0-98.rhaos4.8.gitcd80260.el8
Run &amp;quot;systemctl reboot&amp;quot; to start a reboot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;rpm-ostree&lt;/code&gt; downloaded the package and prepared the updated OS. Per the advice, the update is not active yet; I need to reboot:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# rpm -q runc
runc-1.0.0-97.rhaos4.8.gitcd80260.el8.x86_64
sh-4.4# systemctl reboot
sh-4.4# exit
sh-4.2# 
Removing debug pod ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After reboot I started a node debug container and verified that the modified version of &lt;code&gt;runc&lt;/code&gt; is visible:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/worker-a
Starting pod/worker-a-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.0.128.2
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# rpm -q runc
runc-1.0.0-98.rhaos4.8.gitcd80260.el8.x86_64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the fact that the debug container is working proves that the modified version of runc isn’t &lt;em&gt;completely&lt;/em&gt; broken! Testing the new functionality is a topic for a different post, so I’ll leave it at that.&lt;/p&gt;
&lt;h3 id=&quot;listing-and-resetting-overrides&quot;&gt;Listing and resetting overrides &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#listing-and-resetting-overrides&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;rpm-ostree status --booted&lt;/code&gt; lists the current base image and any overrides that have been applied:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# rpm-ostree status --booted
State: idle
BootedDeployment:
* pivot://quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a23adde268dc8937ae293594f58fc4039b574210f320ebdac85a50ef40220dd
              CustomOrigin: Managed by machine-config-operator
                   Version: 48.84.202106231817-0 (2021-06-23T18:21:06Z)
      ReplacedBasePackages: runc 1.0.0-97.rhaos4.8.gitcd80260.el8 -&amp;gt; 1.0.0-98.rhaos4.8.gitcd80260.el8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To reset an override for a specific package, run &lt;code&gt;rpm-ostree override reset $PKG&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# rpm-ostree override reset runc
Staging deployment... done
Freed: 1.1 GB (pkgcache branches: 0)
Downgraded:
  runc 1.0.0-98.rhaos4.8.gitcd80260.el8 -&amp;gt; 1.0.0-97.rhaos4.8.gitcd80260.el8
Run &amp;quot;systemctl reboot&amp;quot; to start a reboot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To reset &lt;em&gt;all&lt;/em&gt; overrides, execute &lt;code&gt;rpm-ostree reset&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# rpm-ostree reset
Staging deployment... done
Freed: 54.8 MB (pkgcache branches: 0)
Downgraded:
  runc 1.0.0-98.rhaos4.8.gitcd80260.el8 -&amp;gt; 1.0.0-97.rhaos4.8.gitcd80260.el8
Run &amp;quot;systemctl reboot&amp;quot; to start a reboot&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#discussion&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I achieved my goal of installed a modified &lt;code&gt;runc&lt;/code&gt; executable on an OpenShift node. There were two approaches:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;rpm-ostree usroverlay&lt;/code&gt; creates a writable overlay on &lt;code&gt;/usr&lt;/code&gt;. The overlay disappears at reboot, which is fine for my testing needs. This technique doesn’t work from a node debug container; you have to log in over SSH, which requires additional steps to add SSH keys.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;rpm-ostree override replace&lt;/code&gt; overrides a particular package RPM. The change takes effect after reboot and is persistent. It is easy to rollback or reset the override. This technique does not require SSH login; it works fine in a node debug container.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because I needed to build my package in a RHEL 8.4 / RHCOS 4.8 buildroot, I used Brew. The build artifacts are RPMs. Therefore &lt;code&gt;rpm-ostree override replace&lt;/code&gt; is the most convenient option for me.&lt;/p&gt;
&lt;p&gt;Both options apply changes &lt;em&gt;per-node&lt;/em&gt;. After confirming with CoreOS developers, there is currently no way to roll out a package override cluster-wide or to a defined group of nodes (e.g. to &lt;code&gt;MachineConfigPool/worker&lt;/code&gt; via a &lt;code&gt;MachineConfig&lt;/code&gt;). So for now, you either have to apply changes/overrides on specific nodes, or build the whole &lt;code&gt;machine-os-content&lt;/code&gt; image and upgrade the cluster. As a container runtime developer, my sweet spot is in a gulf between the existing options. I can tolerate this mild annoyance on the assumption that it discourages messing around in production environments.&lt;/p&gt;
&lt;p&gt;In the meantime, now that I have worked out how to install my modified &lt;code&gt;runc&lt;/code&gt; onto worker nodes, I will get on with testing it!&lt;/p&gt;</description>
	<pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: systemd, cgroups and subuid ranges</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-06-09-systemd-cgroups-subuid.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-06-09-systemd-cgroups-subuid.html</link>
	<description>&lt;h1 id=&quot;systemd-cgroups-and-subuid-ranges&quot;&gt;systemd, cgroups and subuid ranges&lt;/h1&gt;
&lt;p&gt;In my &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-05-27-oci-runtime-spec-runc.html&quot;&gt;previous post&lt;/a&gt; I experimented with &lt;code&gt;runc&lt;/code&gt; as a way of understanding the behaviour of OCI runtimes. I ended up focusing on cgroup creation and the interaction between &lt;code&gt;runc&lt;/code&gt; and &lt;em&gt;systemd&lt;/em&gt;. The experiment revealed a critical deficiency: when using user namespaces the container’s cgroup is not owned by the user executing the container process. As a result, &lt;em&gt;systemd&lt;/em&gt;-based workloads cannot run.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; creates cgroups via systemd’s &lt;em&gt;transient unit API&lt;/em&gt;. Could a container runtime use this API to control the cgroup ownership? Let’s find out.&lt;/p&gt;
&lt;h2 id=&quot;how-runc-talks-to-systemd&quot;&gt;How &lt;code&gt;runc&lt;/code&gt; talks to &lt;em&gt;systemd&lt;/em&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#how-runc-talks-to-systemd&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;em&gt;Open Container Initiative (OCI)&lt;/em&gt; &lt;a href=&quot;https://github.com/opencontainers/runtime-spec&quot;&gt;runtime spec&lt;/a&gt; defines a low-level container runtime interface. OCI runtimes must create the Linux namespaces specified by an OCI config, including the cgroup namespace.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; uses the systemd D-Bus API to ask systemd to create a cgroup scope for the container. Then it creates a cgroup namespace with the new cgroup scope as the root. We can see that &lt;code&gt;runc&lt;/code&gt; invokes the &lt;code&gt;StartTransientUnit&lt;/code&gt; API method with a name for the new unit, and a list of properties (&lt;a href=&quot;https://github.com/opencontainers/runc/blob/v1.0.0-rc95/vendor/github.com/coreos/go-systemd/v22/dbus/methods.go#L198-L200&quot;&gt;source code&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode go&quot;&gt;&lt;code class=&quot;sourceCode go&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;co&quot;&gt;// .../go-systemd/v22/dbus/methods.go&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;func&lt;/span&gt; (c *Conn) StartTransientUnitContext(&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-3&quot;&gt;&lt;/a&gt;  ctx context.Context, name &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt;, mode &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-4&quot;&gt;&lt;/a&gt;  properties []Property, ch &lt;span class=&quot;kw&quot;&gt;chan&lt;/span&gt;&amp;lt;- &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt;) (&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;error&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-5&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; c.startJob(&lt;/span&gt;
&lt;span id=&quot;cb1-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-6&quot;&gt;&lt;/a&gt;    ctx, ch,&lt;/span&gt;
&lt;span id=&quot;cb1-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-7&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;st&quot;&gt;&amp;quot;org.freedesktop.systemd1.Manager.StartTransientUnit&amp;quot;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&quot;cb1-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-8&quot;&gt;&lt;/a&gt;    name, mode, properties, &lt;span class=&quot;bu&quot;&gt;make&lt;/span&gt;([]PropertyCollection, &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&quot;cb1-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-9&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Most of the unit configuration is passed as properties.&lt;/p&gt;
&lt;h2 id=&quot;the-user-property&quot;&gt;The &lt;code&gt;User=&lt;/code&gt; property &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#the-user-property&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/systemd.exec.html#User=&quot;&gt;&lt;code&gt;systemd.exec(5)&lt;/code&gt;&lt;/a&gt; describes the properties that configure a systemd unit (including transient units). Among the properties are &lt;code&gt;User=&lt;/code&gt; and &lt;code&gt;Group=&lt;/code&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Set the UNIX user or group that the processes are executed as, respectively. Takes a single user or group name, or a numeric ID as argument.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sounds promising. Further searching turned up a systemd documentation page entitled &lt;a href=&quot;https://systemd.io/CGROUP_DELEGATION/&quot;&gt;Control Group APIs and Delegation&lt;/a&gt;. That document states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By turning on the &lt;code&gt;Delegate=&lt;/code&gt; property for a scope or service you get a few guarantees: … If your service makes use of the &lt;code&gt;User=&lt;/code&gt; functionality, then the sub-tree will be &lt;code&gt;chown()&lt;/code&gt;ed to the indicated user so that it can correctly create cgroups below it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; already supplies &lt;code&gt;Delegate=true&lt;/code&gt;. The &lt;code&gt;User=&lt;/code&gt; property seems to be exactly what we need.&lt;/p&gt;
&lt;h2 id=&quot;determining-the-uid&quot;&gt;Determining the UID &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#determining-the-uid&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The OCI configuration specifies the &lt;a href=&quot;https://github.com/opencontainers/runtime-spec/blob/master/config.md#posix-platform-user&quot;&gt;&lt;code&gt;user&lt;/code&gt;&lt;/a&gt; that will execute the container process (in the &lt;strong&gt;container’s user namespace&lt;/strong&gt;). It also specifies &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml&quot;&gt;&lt;code&gt;uidMappings&lt;/code&gt;&lt;/a&gt; between the host and container user namespaces. For example:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% jq -c '.process.user, .linux.uidMappings' &amp;lt; config.json
{&amp;quot;uid&amp;quot;:0,&amp;quot;gid&amp;quot;:0}
[{&amp;quot;containerID&amp;quot;:0,&amp;quot;hostID&amp;quot;:100000,&amp;quot;size&amp;quot;:65536}]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; has all the data it needs to compute the appropriate value for the &lt;code&gt;User=&lt;/code&gt; property. The algorithm, expressed as Python is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-1&quot;&gt;&lt;/a&gt;uid &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; config[&lt;span class=&quot;st&quot;&gt;&amp;quot;process&amp;quot;&lt;/span&gt;][&lt;span class=&quot;st&quot;&gt;&amp;quot;user&amp;quot;&lt;/span&gt;][&lt;span class=&quot;st&quot;&gt;&amp;quot;uid&amp;quot;&lt;/span&gt;]&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt; config[&lt;span class=&quot;st&quot;&gt;&amp;quot;linux&amp;quot;&lt;/span&gt;][&lt;span class=&quot;st&quot;&gt;&amp;quot;uidMappings&amp;quot;&lt;/span&gt;]:&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-4&quot;&gt;&lt;/a&gt;    uid_min &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;&amp;quot;containerID&amp;quot;&lt;/span&gt;]&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-5&quot;&gt;&lt;/a&gt;    uid_max &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; map_min &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;&amp;quot;size&amp;quot;&lt;/span&gt;] &lt;span class=&quot;op&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-6&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-7&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; uid_min &lt;span class=&quot;op&quot;&gt;&amp;lt;=&lt;/span&gt; uid &lt;span class=&quot;op&quot;&gt;&amp;lt;=&lt;/span&gt; uid_max:&lt;/span&gt;
&lt;span id=&quot;cb3-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-8&quot;&gt;&lt;/a&gt;        offset &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; uid &lt;span class=&quot;op&quot;&gt;-&lt;/span&gt; uid_min&lt;/span&gt;
&lt;span id=&quot;cb3-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-9&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;&amp;quot;hostID&amp;quot;&lt;/span&gt;] &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; offset&lt;/span&gt;
&lt;span id=&quot;cb3-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-10&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;cf&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;
&lt;span id=&quot;cb3-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-12&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;pp&quot;&gt;RuntimeError&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;user.uid is not mapped&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;testing-with-systemd-run&quot;&gt;Testing with &lt;code&gt;systemd-run&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#testing-with-systemd-run&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;systemd-run(1)&lt;/code&gt; uses the transient unit API to run programs via transient scope or service units. You can use the &lt;code&gt;--property&lt;/code&gt;/&lt;code&gt;-p&lt;/code&gt; option to pass additional properties. I used &lt;code&gt;systemd-run&lt;/code&gt; to observe how systemd handles the &lt;code&gt;Delegate=true&lt;/code&gt; and &lt;code&gt;User=&lt;/code&gt; properties.&lt;/p&gt;
&lt;h3 id=&quot;create-and-inspect-transient-unit&quot;&gt;Create and inspect transient unit &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#create-and-inspect-transient-unit&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;First I will do a basic test, talking to my user account’s service manager:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% id -u
1000

% systemd-run --user sleep 300
Running as unit: run-r8e3c22d2bb64491a85882d8303202dca.service

% systemctl --user status run-r8e3c22d2bb64491a85882d8303202dca.service
● run-r8e3c22d2bb64491a85882d8303202dca.service - /bin/sleep 300
     Loaded: loaded (/run/user/1000/systemd/transient/run-r8e3c22d2bb64491a85882d8303202dca.service; transient)
  Transient: yes
     Active: active (running) since Wed 2021-06-09 11:31:14 AEST; 9s ago
   Main PID: 11412 (sleep)
      Tasks: 1 (limit: 2325)
     Memory: 184.0K
        CPU: 3ms
     CGroup: /user.slice/user-1000.slice/user@1000.service/app.slice/run-r8e3c22d2bb64491a85882d8303202dca.service
             └─11412 /bin/sleep 300

Jun 09 11:31:14 f33-1.ipa.local systemd[863]: Started /bin/sleep 300.

% ls -nld /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-r8e3c22d2bb64491a85882d8303202dca.service
drwxr-xr-x. 2 1000 1000 0 Jun  9 11:31 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-r8e3c22d2bb64491a85882d8303202dca.service&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;systemd-run creates the transient unit&lt;/li&gt;
&lt;li&gt;the unit was started successfully, and is running&lt;/li&gt;
&lt;li&gt;the unit has is own &lt;code&gt;CGroup&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;the cgroup is owned by user &lt;code&gt;1000&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I try different ways of invoking &lt;code&gt;systemd-run&lt;/code&gt;, I will repeat this pattern of unit creation, inspection and cgroup ownership checks.&lt;/p&gt;
&lt;h3 id=&quot;specify-user-user-service-manager&quot;&gt;Specify &lt;code&gt;User=&lt;/code&gt; (user service manager) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#specify-user-user-service-manager&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next I explicity specify &lt;code&gt;User=1000&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% systemd-run --user -p User=1000 sleep 300
Running as unit: run-r651ff7d0d1214037b70def6d5694dcd6.service

% systemctl --no-pager --full --user status run-r651ff7d0d1214037b70def6d5694dcd6.service
× run-r651ff7d0d1214037b70def6d5694dcd6.service - /bin/sleep 300
     Loaded: loaded (/run/user/1000/systemd/transient/run-r651ff7d0d1214037b70def6d5694dcd6.service; transient)
  Transient: yes
     Active: failed (Result: exit-code) since Wed 2021-06-09 11:38:50 AEST; 1min 17s ago
    Process: 11432 ExecStart=/bin/sleep 300 (code=exited, status=216/GROUP)
   Main PID: 11432 (code=exited, status=216/GROUP)
        CPU: 4ms

Jun 09 11:38:50 f33-1.ipa.local systemd[863]: Started /bin/sleep 300.
Jun 09 11:38:50 f33-1.ipa.local systemd[11432]: run-r651ff7d0d1214037b70def6d5694dcd6.service: Failed to determine supplementary groups: Operation not permitted
Jun 09 11:38:50 f33-1.ipa.local systemd[11432]: run-r651ff7d0d1214037b70def6d5694dcd6.service: Failed at step GROUP spawning /bin/sleep: Operation not permitted
Jun 09 11:38:50 f33-1.ipa.local systemd[863]: run-r651ff7d0d1214037b70def6d5694dcd6.service: Main process exited, code=exited, status=216/GROUP
Jun 09 11:38:50 f33-1.ipa.local systemd[863]: run-r651ff7d0d1214037b70def6d5694dcd6.service: Failed with result 'exit-code'.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This unit failed to execute, because the user service manager does not have permission to determine supplementary groups. Without going into too much detail, this is because the user systemd instance lacks the &lt;code&gt;CAP_SETGID&lt;/code&gt; capability required by the &lt;code&gt;setgroups(2)&lt;/code&gt; system call used by &lt;code&gt;initgroups(3)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There doesn’t seem to be a way around this. For the rest of my testing I’ll talk to the system service manager. That’s okay, because &lt;code&gt;runc&lt;/code&gt; on OpenShift also talks to the system service manager.&lt;/p&gt;
&lt;h3 id=&quot;specify-user-system-service-manager&quot;&gt;Specify &lt;code&gt;User=&lt;/code&gt; (system service manager) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#specify-user-system-service-manager&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-run -p User=1000 sleep 300
Running as unit: run-r94725453119e4003af336d7294984085.service

% systemctl status run-r94725453119e4003af336d7294984085.service
● run-r94725453119e4003af336d7294984085.service - /usr/bin/sleep 300
     Loaded: loaded (/run/systemd/transient/run-r94725453119e4003af336d7294984085.service; transient)
  Transient: yes
     Active: active (running) since Wed 2021-06-09 11:50:10 AEST; 11s ago
   Main PID: 11517 (sleep)
      Tasks: 1 (limit: 2325)
     Memory: 184.0K
        CPU: 4ms
     CGroup: /system.slice/run-r94725453119e4003af336d7294984085.service
             └─11517 /usr/bin/sleep 300

Jun 09 11:50:10 f33-1.ipa.local systemd[1]: Started /usr/bin/sleep 300.

% ls -nld /sys/fs/cgroup/system.slice/run-r94725453119e4003af336d7294984085.service
drwxr-xr-x. 2 0 0 0 Jun  9 11:50 /sys/fs/cgroup/system.slice/run-r94725453119e4003af336d7294984085.service

% ps -o uid,pid,cmd --pid 11517
  UID     PID CMD
 1000   11517 /usr/bin/sleep 300&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The process is running as user &lt;code&gt;1000&lt;/code&gt;, but the cgroup is owned by &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;specify-delegatetrue&quot;&gt;Specify &lt;code&gt;Delegate=true&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#specify-delegatetrue&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We need to specify &lt;code&gt;Delegate=true&lt;/code&gt; to tell systemd to delegate the cgroup to the specified &lt;code&gt;User&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-run -p Delegate=true -p User=1000 sleep 300
Running as unit: run-r518dbc963502423c9c67b1c72d3d4c12.service

% systemctl status run-r518dbc963502423c9c67b1c72d3d4c12.service
● run-r518dbc963502423c9c67b1c72d3d4c12.service - /usr/bin/sleep 300
     Loaded: loaded (/run/systemd/transient/run-r518dbc963502423c9c67b1c72d3d4c12.service; transient)
  Transient: yes
     Active: active (running) since Wed 2021-06-09 11:59:34 AEST; 1min 21s ago
   Main PID: 11579 (sleep)
      Tasks: 1 (limit: 2325)
     Memory: 184.0K
        CPU: 3ms
     CGroup: /system.slice/run-r518dbc963502423c9c67b1c72d3d4c12.service
             └─11579 /usr/bin/sleep 300

Jun 09 11:59:34 f33-1.ipa.local systemd[1]: Started /usr/bin/sleep 300.

% ls -nld /sys/fs/cgroup/system.slice/run-r518dbc963502423c9c67b1c72d3d4c12.service
drwxr-xr-x. 2 1000 1000 0 Jun  9 11:59 /sys/fs/cgroup/system.slice/run-r518dbc963502423c9c67b1c72d3d4c12.service&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;systemd &lt;code&gt;chown()&lt;/code&gt;ed the cgroup to the specified &lt;code&gt;User&lt;/code&gt;. Note that very few of the cgroup controls in the cgroup directory are writable by user &lt;code&gt;1000&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ls -nl /sys/fs/cgroup/system.slice/run-r518dbc963502423c9c67b1c72d3d4c12.service \
    |grep 1000 
-rw-r--r--. 1 1000 1000 0 Jun  9 11:59 cgroup.procs
-rw-r--r--. 1 1000 1000 0 Jun  9 11:59 cgroup.subtree_control
-rw-r--r--. 1 1000 1000 0 Jun  9 11:59 cgroup.threads&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the process cannot adjust its root cgroup’s &lt;code&gt;memory.max&lt;/code&gt;, &lt;code&gt;pids.max&lt;/code&gt;, &lt;code&gt;cpu.weight&lt;/code&gt; and so on. It &lt;em&gt;can&lt;/em&gt; create cgroup subtrees, manage resources within them, and move processes and threads among those subtrees and its root cgroup.&lt;/p&gt;
&lt;h3 id=&quot;arbitrary-uids&quot;&gt;Arbitrary UIDs &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#arbitrary-uids&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So far I have specified &lt;code&gt;User=1000&lt;/code&gt;. User &lt;code&gt;1000&lt;/code&gt; is a “known user”. That is, the Name Service Switch (see &lt;code&gt;nss(5)&lt;/code&gt;) returns information about the user (name, home directory, shell, etc):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% getent passwd $(id -u)
ftweedal:x:1000:1000:ftweedal:/home/ftweedal:/bin/zsh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, when executing containers with user namespaces, we usually map the namespace UIDs to unprivileged host UIDs from a &lt;em&gt;subordinate ID&lt;/em&gt; range. Subordinate UIDs and GID ranges are currently defined in &lt;code&gt;/etc/subuid&lt;/code&gt; and &lt;code&gt;/etc/subgid&lt;/code&gt; respectively. The subuid range for user &lt;code&gt;1000&lt;/code&gt; is:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% grep $(id -un) /etc/subuid
ftweedal:100000:65536&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;User &lt;code&gt;1000&lt;/code&gt; has been allocated the range &lt;code&gt;100000&lt;/code&gt;–&lt;code&gt;165535&lt;/code&gt;. So let’s try &lt;code&gt;systemd-run&lt;/code&gt; with &lt;code&gt;User=100000&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-run -p Delegate=true -p User=100000 sleep 300
Running as unit: run-r1498304af7df406c9698da5c683ea79e.service

% systemctl --no-pager --full status run-r1498304af7df406c9698da5c683ea79e.service
× run-r1498304af7df406c9698da5c683ea79e.service - /usr/bin/sleep 300
     Loaded: loaded (/run/systemd/transient/run-r1498304af7df406c9698da5c683ea79e.service; transient)
  Transient: yes
     Active: failed (Result: exit-code) since Wed 2021-06-09 12:32:43 AEST; 14s ago
    Process: 11766 ExecStart=/usr/bin/sleep 300 (code=exited, status=217/USER)
   Main PID: 11766 (code=exited, status=217/USER)
        CPU: 2ms

Jun 09 12:32:43 f33-1.ipa.local systemd[1]: Started /usr/bin/sleep 300.
Jun 09 12:32:43 f33-1.ipa.local systemd[11766]: run-r1498304af7df406c9698da5c683ea79e.service: Failed to determine user credentials: No such process
Jun 09 12:32:43 f33-1.ipa.local systemd[11766]: run-r1498304af7df406c9698da5c683ea79e.service: Failed at step USER spawning /usr/bin/sleep: No such process
Jun 09 12:32:43 f33-1.ipa.local systemd[1]: run-r1498304af7df406c9698da5c683ea79e.service: Main process exited, code=exited, status=217/USER
Jun 09 12:32:43 f33-1.ipa.local systemd[1]: run-r1498304af7df406c9698da5c683ea79e.service: Failed with result 'exit-code'.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It failed. Cutting the noise, the cause is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Failed to determine user credentials: No such process&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The string &lt;code&gt;No such process&lt;/code&gt; is a bit misleading. It is the string associated with the &lt;code&gt;ESRCH&lt;/code&gt; error value (see &lt;code&gt;errno(3)&lt;/code&gt;). Here it indicates that &lt;code&gt;getpwuid(3)&lt;/code&gt; did not find a user record for uid &lt;code&gt;100000&lt;/code&gt;. systemd unconditionally fails in this scenario. And this is a problem for us because without intervention, subordinate UIDs do not have associated user records.&lt;/p&gt;
&lt;h3 id=&quot;arbitrary-uids-with-passwd-entry&quot;&gt;Arbitrary UIDs (with &lt;code&gt;passwd&lt;/code&gt; entry) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#arbitrary-uids-with-passwd-entry&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So let’s make NSS return something for user &lt;code&gt;100000&lt;/code&gt;. There are several ways we could do this, including adding it to &lt;code&gt;/etc/passwd&lt;/code&gt;, or creating an NSS module that generates passwd records for ranges declared in &lt;code&gt;/etc/subuid&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Another way is to use &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/nss-systemd.html&quot;&gt;systemd’s NSS module&lt;/a&gt;, which returns passwd records for containers created by &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/systemd-machined.html&quot;&gt;&lt;code&gt;systemd-machined&lt;/code&gt;&lt;/a&gt;. And that’s what I did. Given the root filesystem for a container in &lt;code&gt;./rootfs&lt;/code&gt;, &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html&quot;&gt;&lt;code&gt;systemd-nspawn&lt;/code&gt;&lt;/a&gt; creates the container. The &lt;code&gt;--private-users=100000&lt;/code&gt; option tells it to create a user namespace mapping to the host UID &lt;code&gt;100000&lt;/code&gt; with default size 65536:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-nspawn --directory rootfs --private-users=100000 /bin/sh
Spawning container rootfs on /home/ftweedal/go/src/github.com/opencontainers/runc/rootfs.
Press ^] three times within 1s to kill container.
Selected user namespace base 100000 and range 65536.
sh-5.0#&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the host we can see the “machine” via &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/machinectl.html&quot;&gt;&lt;code&gt;machinectl(1)&lt;/code&gt;&lt;/a&gt;. We also observe that NSS now returns results for UIDs in the mapped host range.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% getent passwd 100000 165535  
vu-rootfs-0:x:100000:65534:UID 0 of Container rootfs:/:/usr/sbin/nologin

% getent passwd 100000 165534
vu-rootfs-0:x:100000:65534:UID 0 of Container rootfs:/:/usr/sbin/nologin
vu-rootfs-65534:x:165534:65534:UID 65534 of Container rootfs:/:/usr/sbin/nologin&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;passwd&lt;/code&gt; records are constructed on demand by &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/nss-systemd.html&quot;&gt;&lt;code&gt;nss-systemd(8)&lt;/code&gt;&lt;/a&gt; using data registered by &lt;code&gt;systemd-machined&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now let’s try &lt;code&gt;systemd-run&lt;/code&gt; again:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-run -p Delegate=true -p User=100000 sleep 300
Running as unit: run-r076a82c36fcd4934b13bba47fcc8462e.service

% systemctl status run-r076a82c36fcd4934b13bba47fcc8462e.service
● run-r076a82c36fcd4934b13bba47fcc8462e.service - /usr/bin/sleep 300
     Loaded: loaded (/run/systemd/transient/run-r076a82c36fcd4934b13bba47fcc8462e.service; transient)
  Transient: yes
     Active: active (running) since Wed 2021-06-09 14:14:34 AEST; 11s ago
   Main PID: 12045 (sleep)
      Tasks: 1 (limit: 2325)
     Memory: 180.0K
        CPU: 4ms
     CGroup: /system.slice/run-r076a82c36fcd4934b13bba47fcc8462e.service
             └─12045 /usr/bin/sleep 300

Jun 09 14:14:34 f33-1.ipa.local systemd[1]: Started /usr/bin/sleep 300.

% ls -nld /sys/fs/cgroup/system.slice/run-r076a82c36fcd4934b13bba47fcc8462e.service 
drwxr-xr-x. 2 100000 65534 0 Jun  9 14:14 /sys/fs/cgroup/system.slice/run-r076a82c36fcd4934b13bba47fcc8462e.service

% ps -o uid,gid,pid,cmd --pid 12045
  UID   GID     PID CMD
  100000 65534  12045 /usr/bin/sleep 300

% id -un 65534
nobody&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the cgroup is owned by &lt;code&gt;100000&lt;/code&gt;. But the group ID (&lt;code&gt;gid&lt;/code&gt;) under which the process runs, and the group owner of the cgroup, is &lt;code&gt;65534&lt;/code&gt;. This is the host’s &lt;code&gt;nobody&lt;/code&gt; account.&lt;/p&gt;
&lt;h3 id=&quot;specify-group&quot;&gt;Specify &lt;code&gt;Group=&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#specify-group&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In a user-namespaced container, ordinarily you would want both the user &lt;em&gt;and&lt;/em&gt; the group of the container process to be mapped into the user namespace. Likewise, you would expect the cgroup to be owned by a known (in the namespace) user. Setting the &lt;code&gt;Group=&lt;/code&gt; property should achieve this.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo systemd-run -p Delegate=true -p User=100000 -p Group=100000 sleep 300      
Running as unit: run-re610d14cc0584a37a3d4099268df75d8.service

% systemctl status run-re610d14cc0584a37a3d4099268df75d8.service
● run-re610d14cc0584a37a3d4099268df75d8.service - /usr/bin/sleep 300
     Loaded: loaded (/run/systemd/transient/run-re610d14cc0584a37a3d4099268df75d8.service; transient)
  Transient: yes
     Active: active (running) since Wed 2021-06-09 14:24:58 AEST; 7s ago
   Main PID: 12131 (sleep)
      Tasks: 1 (limit: 2325)
     Memory: 184.0K
        CPU: 5ms
     CGroup: /system.slice/run-re610d14cc0584a37a3d4099268df75d8.service
             └─12131 /usr/bin/sleep 300

Jun 09 14:24:58 f33-1.ipa.local systemd[1]: Started /usr/bin/sleep 300.

% ls -nld /sys/fs/cgroup/system.slice/run-re610d14cc0584a37a3d4099268df75d8.service
drwxr-xr-x. 2 100000 100000 0 Jun  9 14:24 /sys/fs/cgroup/system.slice/run-re610d14cc0584a37a3d4099268df75d8.service

% ps -o uid,gid,pid,cmd --pid 12131
  UID   GID     PID CMD
100000 100000 12131 /usr/bin/sleep 300&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, systemd is exhibiting the behaviour we desire.&lt;/p&gt;
&lt;h2 id=&quot;discussion-and-next-steps&quot;&gt;Discussion and next steps &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#discussion-and-next-steps&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In summary, the findings from this investigation are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;systemd changes the cgroup ownership of transient units according to the &lt;code&gt;User=&lt;/code&gt; and &lt;code&gt;Group=&lt;/code&gt; properties, if and only if &lt;code&gt;Delegate=true&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;systemd currently requires &lt;code&gt;User=&lt;/code&gt; and &lt;code&gt;Group=&lt;/code&gt; to refer to known (via NSS) users and groups.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unprivileged user systemd service manager instances lack the privileges to set supplementary groups for the container process. This is not a problem for the OpenShift use case, because it uses the system service manager.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As to the second point, I am curious why systemd behaves this way. It does makes sense to query NSS to find out the shell, home directory, and login name for setting up the execution environment. But if there is no &lt;code&gt;passwd&lt;/code&gt; record, why not synthesise one with conservative defaults? Running processes as anonymous UIDs has a valid use case—increasingly so, as adoption of user namespaces increases. I &lt;a href=&quot;https://github.com/systemd/systemd/issues/19781&quot;&gt;filed an RFE (systemd#19781)&lt;/a&gt; against systemd to suggest relaxing this restriction, and inquire whether this is a Bad Idea for some reason I don’t yet understand.&lt;/p&gt;
&lt;p&gt;There are some alternative approaches that don’t require changing systemd:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;systemd-machined&lt;/code&gt; to register a machine. It provides the &lt;code&gt;org.freedesktop.machine1.Manager.RegisterMachine&lt;/code&gt; D-Bus method for this purpose. But &lt;code&gt;systemd-machined&lt;/code&gt; is not used (or even present) on OpenShift cluster nodes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Implement, ship and configure an NSS module that synthesises &lt;code&gt;passwd&lt;/code&gt; records for user subordinate ID ranges. The &lt;em&gt;shadow&lt;/em&gt; project has &lt;a href=&quot;https://github.com/shadow-maint/shadow/pull/321&quot;&gt;defined an NSS interface&lt;/a&gt; for subid ranges. &lt;em&gt;libsubid&lt;/em&gt;, part of &lt;em&gt;shadow&lt;/em&gt;, will provide abstract subid range lookups (forward and reverse). So a &lt;em&gt;libsubid&lt;/em&gt;-based solution to this should be possible. Unfortunately, &lt;em&gt;libsubid&lt;/em&gt; is not yet widely available as a shared library.&lt;/p&gt;
&lt;p&gt;As an example, synthetic user records could have a username like &lt;code&gt;subuid-{username}-{uid}&lt;/code&gt;. The home directory and shell would be &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;/sbin/nologin&lt;/code&gt;, like the records synthesised by &lt;code&gt;nss-systemd&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the container runtime (&lt;code&gt;runc&lt;/code&gt;) to &lt;code&gt;chown&lt;/code&gt; the cgroup &lt;em&gt;after systemd creates it&lt;/em&gt;. In fact, this is what &lt;code&gt;systemd-nspawn&lt;/code&gt; does. This approach is nice because the only component to change is &lt;code&gt;runc&lt;/code&gt;—which had to change anyway, to add the logic to determine the cgroup owner UID. To the best of my knowledge, on OpenShift &lt;code&gt;runc&lt;/code&gt; gets executed as &lt;code&gt;root&lt;/code&gt; (on the node), so it should have the permissions required to do this. Unless SELinux prevents it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of these three options, modifying &lt;code&gt;runc&lt;/code&gt; to &lt;code&gt;chown&lt;/code&gt; the cgroup directory seems the most promising. While I wait for feedback on &lt;a href=&quot;https://github.com/systemd/systemd/issues/19781&quot;&gt;systemd#19781&lt;/a&gt;, I will start hacking on &lt;code&gt;runc&lt;/code&gt; and testing my modifications.&lt;/p&gt;</description>
	<pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: Using runc to explore the OCI Runtime Specification</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-05-27-oci-runtime-spec-runc.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-05-27-oci-runtime-spec-runc.html</link>
	<description>&lt;h1 id=&quot;using-runc-to-explore-the-oci-runtime-specification&quot;&gt;Using &lt;code&gt;runc&lt;/code&gt; to explore the OCI Runtime Specification&lt;/h1&gt;
&lt;p&gt;In recent posts I explored how to use user namespaces and cgroups v2 on OpenShift. My main objective is to run &lt;em&gt;systemd&lt;/em&gt;-based workloads in user namespaces that map to unprivileged users on the host. This is a prerequisite to running &lt;a href=&quot;https://www.freeipa.org/page/Main_Page&quot;&gt;FreeIPA&lt;/a&gt; &lt;em&gt;securely&lt;/em&gt; in OpenShift, and supporting multitenancy.&lt;/p&gt;
&lt;p&gt;Independently, user namespaces and cgroups v2 already work well in OpenShift. But for &lt;em&gt;systemd&lt;/em&gt; support there is a critical gap: the pod’s cgroup directory (mounted as &lt;code&gt;/sys/fs/cgroup/&lt;/code&gt; in the container) is owned by &lt;code&gt;root&lt;/code&gt;—the &lt;em&gt;host’s&lt;/em&gt; UID 0, which is unmapped in the pod’s user namespace. As a consequence, the container’s main process (&lt;code&gt;/sbin/init&lt;/code&gt;, which is &lt;em&gt;systemd&lt;/em&gt;) cannot manage cgroups, and terminates.&lt;/p&gt;
&lt;p&gt;To understand how to close this gap, I needed to become familiar with the low-level container runtime behaviour. This post discusses the relationship between various container runtime components and demonstrates how to use &lt;code&gt;runc&lt;/code&gt; directly to create and run containers. I also outline some possible approaches to solving the cgroup ownership issue.&lt;/p&gt;
&lt;h2 id=&quot;podman-kubernetes-cri-cri-o-runc-oh-my&quot;&gt;Podman, Kubernetes, CRI, CRI-O, runc, oh my! &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#podman-kubernetes-cri-cri-o-runc-oh-my&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;What actually happens when you “run a container”. Abstractly, a container runtime sets up a &lt;em&gt;sandbox&lt;/em&gt; and runs a process in it. The sandbox consists of a set of namespaces (PID, UTS, mount, cgroup, user, network, etc), and a restricted view of a filesystem (via &lt;code&gt;chroot(2)&lt;/code&gt; or similar mechanism).&lt;/p&gt;
&lt;p&gt;There are several different container runtimes in widespread use. In fact, there are several different &lt;em&gt;layers&lt;/em&gt; of container runtime with different purposes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;End-user focused container runtimes include &lt;a href=&quot;https://podman.io/&quot;&gt;&lt;em&gt;Podman&lt;/em&gt;&lt;/a&gt; and &lt;em&gt;Docker&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kubernetes defines the &lt;a href=&quot;https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md&quot;&gt;Container Runtime Interface (CRI)&lt;/a&gt;, which it uses to run containers. Compliant implementations include &lt;em&gt;containerd&lt;/em&gt; and &lt;a href=&quot;https://github.com/cri-o/cri-o&quot;&gt;&lt;em&gt;CRI-O&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;Open Container Initiative (OCI)&lt;/em&gt; &lt;a href=&quot;https://github.com/opencontainers/runtime-spec&quot;&gt;runtime spec&lt;/a&gt; defines a low-level container runtime interface. Implementations include &lt;a href=&quot;https://github.com/opencontainers/runc&quot;&gt;&lt;code&gt;runc&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/containers/crun&quot;&gt;&lt;em&gt;crun&lt;/em&gt;&lt;/a&gt;. OCI runtimes are designed to be used by higher-level container runtimes. They are not friendly for humans to use directly.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Running a container usually involves a higher-level runtime &lt;em&gt;and&lt;/em&gt; a low-level runtime. For example, Podman uses an OCI runtime; crun by default on Fedora but &lt;code&gt;runc&lt;/code&gt; works fine too. OpenShift (which is built on Kubernetes) uses CRI-O, which in turn uses &lt;code&gt;runc&lt;/code&gt; (CRI-O itself can use any OCI runtime).&lt;/p&gt;
&lt;h3 id=&quot;division-of-responsibilities&quot;&gt;Division of responsibilities &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#division-of-responsibilities&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So, what are responsibilities of the higher-level runtime compared to the OCI (or other low-level) runtime? In general the high-level runtime is responsible for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Image management (pulling layers, preparing overlay filesystem)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Determining the mounts, environment, namespaces, resource limits and security policies for the container&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Network setup for the container&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Metrics, accounting, etc.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The steps performed by the low-level runtime include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create and and enter required namespaces&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;chroot(2)&lt;/code&gt; or &lt;code&gt;pivot_root(2)&lt;/code&gt; to the specified root filesystem path&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create requested mounts&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create cgroups and apply resource limits&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjust capabilities and apply seccomp policy&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Execute the container’s main process&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;I mentioned several features specific to Linux in the list above. The OCI Runtime Specification also specifies Windows, Solaris and VM-based workloads. This post assumes a Linux workload, so many details are Linux-specific.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The above list is just a rough guide and not absolute. Depending on use case the high-level runtime might perform some of the low-level steps. For example, if container networking is required, Podman might create the network namespace, setting up devices and routing. Then, instead of asking the OCI runtime to create a network namespace, it tells the runtime to enter the existing namespace.&lt;/p&gt;
&lt;h2 id=&quot;running-containers-via-runc&quot;&gt;Running containers via &lt;code&gt;runc&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#running-containers-via-runc&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Because our effort is targeting OpenShift, the rest of this post mainly deals with &lt;code&gt;runc&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;The functions demonstrated in this post were performed using &lt;code&gt;runc&lt;/code&gt; version 1.0.0-rc95+dev, which I built from source (commit &lt;code&gt;19d75e1c&lt;/code&gt;). The Fedora 33 and 34 repositories offer &lt;code&gt;runc&lt;/code&gt; version 1.0.0-rc93, which &lt;strong&gt;does not work&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&quot;clone-and-build&quot;&gt;Clone and build &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#clone-and-build&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Install the Go compiler and &lt;em&gt;libseccomp&lt;/em&gt; development headers:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% sudo dnf -y --quiet install libseccomp-devel

Installed:
  golang-1.16.3-1.fc34.x86_64
  golang-bin-1.16.3-1.fc34.x86_64
  golang-src-1.16.3-1.fc34.noarch
  libseccomp-devel-2.5.0-4.fc34.x86_64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clone the &lt;code&gt;runc&lt;/code&gt; source code and build the program:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% mkdir -p ~/go/src/github.com/opencontainers
% cd ~/go/src/github.com/opencontainers
% git clone --quiet https://github.com/opencontainers/runc
% cd runc
% make --quiet
% ./runc --version
runc version 1.0.0-rc95+dev
commit: v1.0.0-rc95-31-g19d75e1c
spec: 1.0.2-dev
go: go1.16.3
libseccomp: 2.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;prepare-root-filesystem&quot;&gt;Prepare root filesystem &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#prepare-root-filesystem&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I want to create a filesystem from my &lt;em&gt;systemd&lt;/em&gt; based &lt;a href=&quot;https://quay.io/repository/ftweedal/test-nginx&quot;&gt;&lt;code&gt;test-nginx&lt;/code&gt;&lt;/a&gt; container image. To avoid configuring overlay filesystems myself, I used Podman to create a container, then exported the whole container filesystem, via &lt;code&gt;tar(1)&lt;/code&gt;, to a local directory:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% podman create --quiet quay.io/ftweedal/test-nginx
e97930b3…
% mkdir rootfs
% podman export e97930b3 | tar -xC rootfs
% ls rootfs
bin  dev home lib64      media opt  root sbin sys usr
boot etc lib  lost+found mnt   proc run  srv  tmp var&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;create-config.json&quot;&gt;Create &lt;code&gt;config.json&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#create-config.json&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;OCI runtimes read the container configuration from &lt;code&gt;config.json&lt;/code&gt; in the &lt;em&gt;bundle&lt;/em&gt; directory. (&lt;code&gt;runc&lt;/code&gt; uses the current directory as the default bundle directory). The &lt;code&gt;runc spec&lt;/code&gt; command generates a sample &lt;code&gt;config.json&lt;/code&gt; which can serve as a starting point:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ./runc spec --rootless
% file config.json
config.json: JSON data
% jq -c .process.args &amp;lt; config.json
[&amp;quot;sh&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that &lt;code&gt;runc&lt;/code&gt; created the sample config. The command to execute is &lt;code&gt;sh(1)&lt;/code&gt;. Let’s change that to &lt;code&gt;/sbin/init&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% mv config.json config.json.orig
% jq '.process.args=[&amp;quot;/sbin/init&amp;quot;]' config.json.orig \
    &amp;gt; config.json&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;notes&quot;&gt;
&lt;p&gt;&lt;code&gt;jq(1)&lt;/code&gt; cannot operate on JSON files in situ, so you first have to copy or move the input file. The &lt;a href=&quot;https://linux.die.net/man/1/sponge&quot;&gt;&lt;code&gt;sponge(1)&lt;/code&gt;&lt;/a&gt; command, provided by the &lt;em&gt;moreutils&lt;/em&gt; package, offers an alternative approach.&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&quot;run-container&quot;&gt;Run container &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#run-container&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now we can try and run the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ./runc --systemd-cgroup run test
Mount failed for selinuxfs on /sys/fs/selinux:  No such file or directory
Another IMA custom policy has already been loaded, ignoring: Permission denied
Failed to mount tmpfs at /run: Operation not permitted
[!!!!!!] Failed to mount API filesystems.
Freezing execution.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That didn’t work. systemd failed to mount a &lt;code&gt;tmpfs&lt;/code&gt; (temporary, memory-based filesystem) at &lt;code&gt;/tmp&lt;/code&gt;, and halted. The container itself was still running (but frozen). I was able to kill it from another terminal:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ./runc list --quiet
test
% ./runc kill test KILL
% ./runc list --quiet&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turned out that in addition to the process to run, the config requires several changes to successfully run a &lt;em&gt;systemd&lt;/em&gt;-based container. I will not repeat the whole process here, but I achieved a working config through a combination of trial-and-error, and comparison against OCI configurations produced by Podman. The following &lt;a href=&quot;https://stedolan.github.io/jq/manual/&quot;&gt;&lt;code&gt;jq(1)&lt;/code&gt;&lt;/a&gt; program performs the required modifications:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb8&quot;&gt;&lt;pre class=&quot;sourceCode numberSource json numberLines&quot;&gt;&lt;code class=&quot;sourceCode json&quot;&gt;&lt;span id=&quot;cb8-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;.process.args&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;/sbin/init&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.process.env&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;container=oci&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;containerID&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;hostID&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;size&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;65536&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$idmap&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.linux.uidMappings&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$idmap&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.linux.gidMappings&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$idmap&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.linux.cgroupsPath&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;&amp;quot;user.slice:runc:test&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.linux.namespaces&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;network&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.process.capabilities&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-9&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_CHOWN&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_FOWNER&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_SETUID&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_SETGID&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-10&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_SETPCAP&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;CAP_NET_BIND_SERVICE&amp;quot;&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;tmpfs&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;,&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-12&quot;&gt;&lt;/a&gt;   &lt;span class=&quot;dt&quot;&gt;&amp;quot;source&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;tmpfs&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;,&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-13&quot;&gt;&lt;/a&gt;   &lt;span class=&quot;dt&quot;&gt;&amp;quot;options&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;rw&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;rprivate&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;nosuid&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;nodev&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;tmpcopyup&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-14&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$tmpfs&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.mounts&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;destination&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;/var/log&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$tmpfs&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-16&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-16&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.mounts&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;destination&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;/tmp&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$tmpfs&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-17&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-17&quot;&gt;&lt;/a&gt;&lt;span class=&quot;er&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.mounts&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;|=&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;&amp;quot;destination&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;/run&amp;quot;&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;$tmpfs&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;er&quot;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This program performs the following actions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Set the container process to &lt;code&gt;/sbin/init&lt;/code&gt; (which is &lt;em&gt;systemd&lt;/em&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Set the &lt;code&gt;$container&lt;/code&gt; environment variable, as &lt;a href=&quot;https://systemd.io/CONTAINER_INTERFACE/#environment-variables&quot;&gt;required by systemd&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add UID and GID mappings for IDs &lt;code&gt;1&lt;/code&gt;–&lt;code&gt;65536&lt;/code&gt; in the container’s user namespace. The host range (started at &lt;code&gt;100000&lt;/code&gt;) is taken from my user account’s assigned ranges in &lt;code&gt;/etc/subuid&lt;/code&gt; and &lt;code&gt;/etc/subgid&lt;/code&gt;. &lt;strong&gt;You may need a different number.&lt;/strong&gt; The mapping for the container’s UID &lt;code&gt;0&lt;/code&gt; to my user account already exists in the config.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Set the container’s cgroup path. A non-absolute path is interpreted relative to a runtime-determined location.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tell the runtime to create a network namespace. Without this, the container will have no network stack and &lt;em&gt;nginx&lt;/em&gt; won’t run.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Set the &lt;a href=&quot;https://linux.die.net/man/7/capabilities&quot;&gt;capabilities&lt;/a&gt; required by the container. &lt;em&gt;systemd&lt;/em&gt; requires all of these capabilities, although &lt;code&gt;CAP_NET_BIND_SERVICE&lt;/code&gt; is only required for network name resolution (&lt;em&gt;systemd-resolved&lt;/em&gt;). And &lt;em&gt;nginx&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tell the runtime to mount &lt;code&gt;tmpfs&lt;/code&gt; filesystems at &lt;code&gt;/run&lt;/code&gt;, &lt;code&gt;/tmp&lt;/code&gt; and &lt;code&gt;/var/log&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I ran the program to modify the config, then started the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% jq --from-file filter.jq config.json.orig &amp;gt; config.json
% ./runc --systemd-cgroup run test
systemd v246.10-1.fc33 running in system mode. (+PAM …
Detected virtualization container-other.
Detected architecture x86-64.

Welcome to Fedora 33 (Container Image)!

…

[  OK  ] Started The nginx HTTP and reverse proxy server.
[  OK  ] Reached target Multi-User System.
[  OK  ] Reached target Graphical Interface.
         Starting Update UTMP about System Runlevel Changes.
[  OK  ] Finished Update UTMP about System Runlevel Changes.

Fedora 33 (Container Image)
Kernel 5.11.17-300.fc34.x86_64 on an x86_64 (console)

runc login:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OK! &lt;em&gt;systemd&lt;/em&gt; initialised the system properly and started &lt;em&gt;nginx&lt;/em&gt;. We can confirm &lt;em&gt;nginx&lt;/em&gt; is running properly by running &lt;code&gt;curl&lt;/code&gt; in the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ./runc exec test curl --silent --head localhost:80
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Thu, 27 May 2021 02:29:58 GMT
Content-Type: text/html
Content-Length: 5564
Last-Modified: Mon, 27 Jul 2020 22:20:49 GMT
Connection: keep-alive
ETag: &amp;quot;5f1f5341-15bc&amp;quot;
Accept-Ranges: bytes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point we cannot access &lt;em&gt;nginx&lt;/em&gt; from outside the container. That’s fine; I don’t need to work out how to do that. Not today, anyhow.&lt;/p&gt;
&lt;h2 id=&quot;how-runc-creates-cgroups&quot;&gt;How &lt;code&gt;runc&lt;/code&gt; creates cgroups &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#how-runc-creates-cgroups&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;runc&lt;/code&gt; manages container cgroups via the host’s &lt;em&gt;systemd&lt;/em&gt; service. Specifically, it communicates with &lt;em&gt;systemd&lt;/em&gt; over DBus to create a &lt;a href=&quot;https://www.freedesktop.org/wiki/Software/systemd/ControlGroupInterface/&quot;&gt;transient scope&lt;/a&gt; for the container. Then it binds the container cgroup namespace to this new scope.&lt;/p&gt;
&lt;p&gt;Observe that the inode of &lt;code&gt;/sys/fs/cgroup/&lt;/code&gt; in the container is the same as the scope created for the container by &lt;em&gt;systemd&lt;/em&gt; on the host:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% ./runc exec test ls -aldi /sys/fs/cgroup
64977 drwxr-xr-x. 5 root root 0 May 27 02:26 /sys/fs/cgroup

% ls -aldi /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/user.slice/runc-test.scope 
64977 drwxr-xr-x. 5 ftweedal ftweedal 0 May 27 12:26 /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/user.slice/runc-test.scope&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The mapping of &lt;code&gt;root&lt;/code&gt; in the container’s user namespace to &lt;code&gt;ftweedal&lt;/code&gt; is confirmed by the UID map of the container process:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% id --user ftweedal
1000
% ./runc list -f json | jq '.[]|select(.id=&amp;quot;test&amp;quot;).pid'
186718
% cat /proc/186718/uid_map
         0       1000          1
         1     100000      65536&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;next-steps&quot;&gt;Next steps &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#next-steps&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;systemd&lt;/em&gt; is running properly in the container, but &lt;code&gt;root&lt;/code&gt; in the container is mapped to my main user account. The container is not as isolated as I would like it to be. A partial sandbox escape could lead to the containerised process(es) messing with local files, or other processes owned by my user (including other containers).&lt;/p&gt;
&lt;p&gt;User-namespaced containers in OpenShift (via CRI-O annotations) are allocated non-overlapping host ID ranges. All the host IDs are essentially anonymous. I confirmed this in &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-10-openshift-user-namespace-multi-user.html&quot;&gt;a previous blog post&lt;/a&gt;. That is good! But the container’s cgroup is owned by the &lt;em&gt;host’s&lt;/em&gt; UID 0, which is unmapped in the container. &lt;em&gt;systemd&lt;/em&gt;-based workloads cannot run because the container cannot write to its cgroupfs.&lt;/p&gt;
&lt;p&gt;Therefore, the next steps in my investigation are:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;Alter the ID mappings to use a single mapping of only “anonymous” users. This is a simple change to the OCI config. The host IDs still have to come from the user’s allocated sub-ID range.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Find (or implement) a way to change the ownership of the container’s cgroup scope to the &lt;strong&gt;container’s&lt;/strong&gt; UID 0.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When using the &lt;em&gt;systemd&lt;/em&gt; cgroup manager, &lt;code&gt;runc&lt;/code&gt; uses the &lt;a href=&quot;https://www.freedesktop.org/wiki/Software/systemd/ControlGroupInterface/&quot;&gt;&lt;em&gt;transient unit API&lt;/em&gt;&lt;/a&gt; to ask &lt;em&gt;systemd&lt;/em&gt; to create a new scope for the container. I am still learning about this API. Perhaps there is a way to specify a different ownership for the new scope or service. If so, we should be able to avoid changes to higher-level container runtimes like CRI-O. That would be the best outcome.&lt;/p&gt;
&lt;p&gt;Otherwise, I will investigate whether we could use the OCI &lt;code&gt;createRuntime&lt;/code&gt; hook to &lt;code&gt;chown(2)&lt;/code&gt; the container’s cgroup scope. Unfortunately, the semantics of &lt;code&gt;createRuntime&lt;/code&gt; is currently underspecified. The specification is ambiguous about whether the containers cgroup scope exists when this hook is executed. If this approach is valid, we will have to update CRI-O to add the relevant hook command to the OCI config.&lt;/p&gt;
&lt;p&gt;Another possible approach is for the high-level runtime to perform the ownership change itself. This would be done after it invokes the OCI runtime’s &lt;code&gt;create&lt;/code&gt; command, but before it invokes &lt;code&gt;start&lt;/code&gt;. (See also the OCI &lt;a href=&quot;https://github.com/opencontainers/runtime-spec/blob/master/runtime.md#lifecycle&quot;&gt;container lifecycle description&lt;/a&gt;). However, on OpenShift CRI-O runs as user &lt;code&gt;containers&lt;/code&gt; and the container’s cgroup scope is owned by &lt;code&gt;root&lt;/code&gt;. So I have doubts about the viability of this approach, as well as the OCI hook approach.&lt;/p&gt;
&lt;p&gt;Whatever the outcome, there will certainly be more blog posts as I continue this long-running investigation. I still have much to learn as I struggle towards the goal of systemd-based workloads running securely on OpenShift.&lt;/p&gt;</description>
	<pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Rob Crittenden: Simple 389-ds plugin logging in ipa</title>
	<guid>http://rcritten.wordpress.com/?p=239</guid>
	<link></link>
	<description>IPA created a number of 389-ds plugins to do various things like enforce failed login counters, handle password sync, etc. 389-ds provides quite a robust debug logging and tracing system but if you just want to see your plugin messages without tweaking the 389-ds error log level and spamming the log with things you don&amp;#8217;t &amp;#8230; &lt;a href=&quot;https://rcritten.wordpress.com/2021/04/22/simple-389-ds-plugin-logging-in-ipa/&quot; class=&quot;more-link&quot;&gt;Continue reading &lt;span class=&quot;screen-reader-text&quot;&gt;Simple 389-ds plugin logging in ipa&lt;/span&gt; &lt;span class=&quot;meta-nav&quot;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;</description>
	<pubDate>Thu, 22 Apr 2021 18:11:05 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: systemd containers on OpenShift with cgroups v2</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-03-30-openshift-cgroupv2-systemd.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-03-30-openshift-cgroupv2-systemd.html</link>
	<description>&lt;h1 id=&quot;systemd-containers-on-openshift-with-cgroups-v2&quot;&gt;systemd containers on OpenShift with cgroups v2&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;systemd&lt;/em&gt; in a container is a practical reality of migrating nontrivial applications to container infrastructure. It is not the “cloud native” way, but many applications written in The Before Times cannot be broken up and rearchitected without a huge cost. And so, there is a demand to run containers that run systemd, which in turn manages application services.&lt;/p&gt;
&lt;p&gt;FreeIPA is one example. Its traditional environment is a dedicated Linux server (ignoring replicas). There are &lt;em&gt;many&lt;/em&gt; services which both interact among themselves, and process requests from external clients and other FreeIPA servers. The engineering effort to redesign FreeIPA as a suite of several containerised services is expected to be very high. Therefore our small team focused on bringing FreeIPA to OpenShift therefore decided to pursue the “monolithic container” approach.&lt;/p&gt;
&lt;p&gt;Support for systemd containers in OpenShift, &lt;em&gt;without hacks&lt;/em&gt;, is a prerequisite for this approach to viable. In this post I experiment with systemd containers in OpenShift and share my results.&lt;/p&gt;
&lt;h2 id=&quot;test-application-http-server&quot;&gt;Test application: HTTP server &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#test-application-http-server&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To test systemd containers on OpenShift, I created a Fedora-based container running the &lt;em&gt;nginx&lt;/em&gt; HTTP server. I enable the &lt;code&gt;nginx&lt;/code&gt; systemd and set the default command to &lt;code&gt;/sbin/init&lt;/code&gt;, which is systemd. The server doesn’t host any interesting content, but if it responds to requests we know that systemd is working.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Containerfile&lt;/code&gt; definition is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode dockerfile&quot;&gt;&lt;code class=&quot;sourceCode dockerfile&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;FROM&lt;/span&gt; fedora:33-x86_64&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;RUN&lt;/span&gt; dnf -y install nginx &amp;amp;&amp;amp; dnf clean all &amp;amp;&amp;amp; systemctl enable nginx&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;EXPOSE&lt;/span&gt; 80&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;CMD&lt;/span&gt; [ &lt;span class=&quot;st&quot;&gt;&amp;quot;/sbin/init&amp;quot;&lt;/span&gt; ]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I built the container on my workstation and tagged it &lt;code&gt;test-nginx&lt;/code&gt;. To check that the container works, I ran it locally and performed an HTTP request via &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% podman run --detach --publish 8080:80 test-nginx
2d8059e555c821d9ffcccd84bee88996207794957696c54e8d29787e8c33fab3

% curl --head localhost:8080
HTTP/1.1 200 OK
Server: nginx/1.18.0
Date: Thu, 25 Mar 2021 00:22:23 GMT
Content-Type: text/html
Content-Length: 5564
Last-Modified: Mon, 27 Jul 2020 22:20:49 GMT
Connection: keep-alive
ETag: &amp;quot;5f1f5341-15bc&amp;quot;
Accept-Ranges: bytes

% podman kill 2d8059e5
2d8059e555c821d9ffcccd84bee88996207794957696c54e8d29787e8c33fab3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The container works properly in &lt;code&gt;podman&lt;/code&gt;. I proceed to testing it on OpenShift.&lt;/p&gt;
&lt;h2 id=&quot;running-privileged-user&quot;&gt;Running (&lt;strong&gt;privileged&lt;/strong&gt; user) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#running-privileged-user&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I performed my testing on an OpenShift 4.8 nightly cluster. The exact build is &lt;code&gt;4.8.0-0.nightly-2021-03-26-010831&lt;/code&gt;. As far as I’m aware, with respect to systemd and cgroups there are no major differences between OpenShift 4.7 (which is Generally Available) and the build I’m using. So results should be similar on OpenShift 4.7.&lt;/p&gt;
&lt;p&gt;The Pod definition for my test service is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Pod&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; quay.io/ftweedal/test-nginx:latest&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I create the Pod, operating with the cluster &lt;code&gt;admin&lt;/code&gt; credential. After a few seconds, the pod is running:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f pod-nginx.yaml 
pod/nginx created

% oc get -o json pod/nginx | jq .status.phase
&amp;quot;Running&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;verifying-that-the-service-is-working&quot;&gt;Verifying that the service is working &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#verifying-that-the-service-is-working&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;pod/nginx&lt;/code&gt; is running, but it is not exposed to other pods in the cluster, or to the outside world. To test that the server is working, I will expose it on the hostname &lt;code&gt;nginx.apps.ft-48dev-5.idmocp.lab.eng.rdu2.redhat.com&lt;/code&gt;. First, observe that performing an HTTP request from my workstation fails because the service is not available:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% curl --head nginx.apps.ft-48dev-5.idmocp.lab.eng.rdu2.redhat.com
HTTP/1.0 503 Service Unavailable
pragma: no-cache
cache-control: private, max-age=0, no-cache, no-store
content-type: text/html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I create Service and Route objects to expose the nginx server. The Service definition is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb6&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb6-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Service&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; TCP&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb6-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;80&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And the Route definition is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb7&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb7-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Route&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx.apps.ft-48dev-5.idmocp.lab.eng.rdu2.redhat.com&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Service&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb7-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I create the objects:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create -f service-nginx.yaml 
service/nginx created

% oc create -f route-nginx.yaml
route.route.openshift.io/nginx created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a few seconds I performed the HTTP request again, and it succeeded:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% curl --head nginx.apps.ft-48dev-5.idmocp.lab.eng.rdu2.redhat.com
HTTP/1.1 200 OK
server: nginx/1.18.0
date: Tue, 30 Mar 2021 08:16:23 GMT
content-type: text/html
content-length: 5564
last-modified: Mon, 27 Jul 2020 22:20:49 GMT
etag: &amp;quot;5f1f5341-15bc&amp;quot;
accept-ranges: bytes
set-cookie: 6cf5f3bc2fa4d24f45018c591d3617c3=6f2f093d36d535f1dde195e08a311bda; path=/; HttpOnly
cache-control: private&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This confirms that the systemd container is running properly on OpenShift 4.8.&lt;/p&gt;
&lt;h3 id=&quot;low-level-details&quot;&gt;Low-level details &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#low-level-details&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now I will inspect some low-level details of the container. I’ll do that in a debug shell on the worker node. So first, I query the pod’s worker node name and container ID:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get -o json pod/nginx \
    | jq '.spec.nodeName,
          .status.containerStatuses[0].containerID'
&amp;quot;ft-48dev-5-f24l6-worker-0-q7lff&amp;quot;
&amp;quot;cri-o://d9d106cb65e4c965737ef66f15bd5b9e0988c386675e3404e24fd36e58284638&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I enter a debug shell on the worker node:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/ft-48dev-5-f24l6-worker-0-q7lff
Starting pod/ft-48dev-5-f24l6-worker-0-q7lff-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.8.1.64
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I use &lt;code&gt;crictl&lt;/code&gt; to query the namespaces of the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# crictl inspect d9d106 \
        | jq .info.runtimeSpec.linux.namespaces[].type
&amp;quot;pid&amp;quot;
&amp;quot;network&amp;quot;
&amp;quot;ipc&amp;quot;
&amp;quot;uts&amp;quot;
&amp;quot;mount&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Observe that there are &lt;code&gt;pid&lt;/code&gt; and &lt;code&gt;mount&lt;/code&gt; namespaces (among others), but no &lt;code&gt;cgroup&lt;/code&gt; namespace. The worker node and container are using cgroups v1.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;container_manage_cgroup&lt;/code&gt; SELinux boolean is &lt;code&gt;off&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# getsebool container_manage_cgroup
container_manage_cgroup --&amp;gt; off&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s see what processes are running in the container. We can query the PID of the initial container process via &lt;code&gt;crictl inspect&lt;/code&gt;. Then I use &lt;code&gt;pgrep(1)&lt;/code&gt; with the &lt;code&gt;--ns&lt;/code&gt; option, which lists processes executing in the same namespace(s) as the specified PID:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# crictl inspect d9d106 | jq .info.pid
14591

sh-4.4# pgrep --ns 14591 | xargs ps -o user,pid,cmd --sort pid
USER         PID CMD
root       14591 /sbin/init
root       14625 /usr/lib/systemd/systemd-journald
systemd+   14636 /usr/lib/systemd/systemd-resolved
root       14642 /usr/lib/systemd/systemd-homed
root       14643 /usr/lib/systemd/systemd-logind
root       14646 /sbin/agetty -o -p -- \u --noclear --keep-baud console 115200,38400,9600 xterm
dbus       14647 /usr/bin/dbus-broker-launch --scope system --audit
dbus       14651 dbus-broker --log 4 --controller 9 --machine-id 2f2fcc4033c5428996568ca34219c72a --max-bytes 536870912 --max-fds 4096 --max-matches 16384 --audit
root       14654 nginx: master process /usr/sbin/nginx
polkitd    14655 nginx: worker process
polkitd    14656 nginx: worker process
polkitd    14657 nginx: worker process
polkitd    14658 nginx: worker process
polkitd    14659 nginx: worker process
polkitd    14660 nginx: worker process
polkitd    14661 nginx: worker process
polkitd    14662 nginx: worker process&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;PID&lt;/code&gt; column shows the PIDs from the point of view of the host’s PID namespace. The first process (PID 1 &lt;em&gt;inside&lt;/em&gt; the container) is systemd (&lt;code&gt;/sbin/init&lt;/code&gt;). systemd has started other system services, and also nginx.&lt;/p&gt;
&lt;p&gt;systemd is running as &lt;code&gt;root&lt;/code&gt; &lt;strong&gt;on the host&lt;/strong&gt;. The other processes run under various system accounts. The container does not have its own user namespace. This pod was created by a privileged account, which allows it to run as &lt;code&gt;root&lt;/code&gt; on the host.&lt;/p&gt;
&lt;h2 id=&quot;running-unprivileged-user&quot;&gt;Running (&lt;strong&gt;unprivileged&lt;/strong&gt; user) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#running-unprivileged-user&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I created an unprivileged user called &lt;code&gt;test&lt;/code&gt;, and granted it admin privileges (so it can create pods).&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc create user test
user.user.openshift.io/test created 

% oc adm policy add-role-to-user admin test
clusterrole.rbac.authorization.k8s.io/admin added: &amp;quot;test&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I did not grant to the &lt;code&gt;test&lt;/code&gt; account any &lt;em&gt;Security Context Constraints (SCCs)&lt;/em&gt; that would allow it to run privileged containers or use host user accounts (including &lt;code&gt;root&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now I create the same &lt;code&gt;nginx&lt;/code&gt; pod, as this user &lt;code&gt;test&lt;/code&gt;. The pod fails to execute:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc --as test create -f pod-nginx.yaml
pod/nginx created

% oc get pod/nginx
NAME    READY   STATUS             RESTARTS   AGE
nginx   0/1     CrashLoopBackOff   1          23s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s inspect the logs to see what went wrong:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc logs pod/nginx
%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is no output. This baffled me, at first. Eventually I learned that Kubernetes, by default, does not allocate pseudo-terminal devices to containers. You can overcome this on a per-container basis by including &lt;code&gt;tty: true&lt;/code&gt; in the Container object definition:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb18&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb18-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Pod&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; nginx&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; quay.io/ftweedal/test-nginx:latest&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb18-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;tty&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the pseudo-terminal enabled, &lt;code&gt;oc logs&lt;/code&gt; now shows the error output:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc logs pod/nginx
systemd v246.10-1.fc33 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +ZSTD +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=unified)
Detected virtualization container-other.
Detected architecture x86-64.

Welcome to Fedora 33 (Container Image)!

Set hostname to &amp;lt;nginx&amp;gt;.
Failed to write /run/systemd/container, ignoring: Permission denied
Failed to create /kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod3bbed45f_634a_4f60_bb07_5f080c483f0f.slice/crio-90dead4cf549b844c4fb704765edfbba9e9e188b30299f484906f15d22b29fbd.scope/init.scope control group: Permission denied
Failed to allocate manager object: Permission denied
[!!!!!!] Failed to allocate manager object.
Exiting PID 1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user executing systemd does not have permissions to write the cgroup filesystem. Although cgroups are heirarchical, cgroups v1 does not support delegating management of part of the heirarchy to unprivileged users. But cgroups v2 does support this.&lt;/p&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;Set the &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/systemd.html#%24SYSTEMD_LOG_LEVEL&quot;&gt;&lt;code&gt;SYSTEMD_LOG_LEVEL&lt;/code&gt;&lt;/a&gt; environment variable to &lt;code&gt;info&lt;/code&gt; or &lt;code&gt;debug&lt;/code&gt; to get more detail in the systemd log output.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&quot;enabling-cgroups-v2&quot;&gt;Enabling cgroups v2 &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#enabling-cgroups-v2&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We can enable cgroups v2 (only) on worker nodes via the following MachineConfig object:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb20&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb20-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; machineconfiguration.openshift.io/v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; MachineConfig&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; enable-cgroupv2-workers&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;machineconfiguration.openshift.io/role&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; worker&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;kernelArguments&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; systemd.unified_cgroup_hierarchy=1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; cgroup_no_v1=&amp;quot;all&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb20-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb20-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; psi=1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After creating the MachineConfig, the &lt;em&gt;Machine Config Operator&lt;/em&gt; applies the configuration change and restarts each worker node, one by one. This occurs over several minutes.&lt;/p&gt;
&lt;h2 id=&quot;running-unprivileged-cgroups-v2&quot;&gt;Running (&lt;strong&gt;unprivileged&lt;/strong&gt;; &lt;strong&gt;cgroups v2&lt;/strong&gt;) &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#running-unprivileged-cgroups-v2&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After some time, all worker nodes have the updated kernel configuration to enable cgroups v2 and disable cgroups v1. I again created the pod as the unprivileged &lt;code&gt;test&lt;/code&gt; user. And again, pod execution failed. But this time the error is different:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc --as test create -f pod-nginx.yaml
pod/nginx created

% oc get pod
NAME    READY   STATUS   RESTARTS   AGE
nginx   0/1     Error    1          12s

% oc logs pod/nginx
systemd v246.10-1.fc33 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +ZSTD +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=unified)
Detected virtualization container-other.
Detected architecture x86-64.

Welcome to Fedora 33 (Container Image)!

Set hostname to &amp;lt;nginx&amp;gt;.
Failed to write /run/systemd/container, ignoring: Permission denied
Failed to create /init.scope control group: Permission denied
Failed to allocate manager object: Permission denied
[!!!!!!] Failed to allocate manager object.
Exiting PID 1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The error suggests that the container now has its own cgroup namespace. I can confirm it by creating a &lt;em&gt;pod&lt;/em&gt; debug container…&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug pod/nginx
Starting pod/nginx-debug ...
Pod IP: 10.130.2.10
If you don't see a command prompt, try pressing enter.
sh-5.0$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…finding out the node and container ID…&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get -o json pod/nginx-debug \
    | jq '.spec.nodeName,
          .status.containerStatuses[0].containerID'
&amp;quot;ft-48dev-5-f24l6-worker-0-qv7kq&amp;quot;
&amp;quot;cri-o://e870d022d1c53adf94e36877312fcfef5ef0431ad9cf1fbe9c9d2ace02bee858&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…and analysing the container sandbox in a &lt;em&gt;node&lt;/em&gt; debug shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh-4.4# crictl inspect e870d02 \
        | jq .info.runtimeSpec.linux.namespaces[].type
&amp;quot;pid&amp;quot;
&amp;quot;network&amp;quot;
&amp;quot;ipc&amp;quot;
&amp;quot;uts&amp;quot;
&amp;quot;mount&amp;quot;
&amp;quot;cgroup&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output confirms that the pod has a cgroup namespace. Despite this, the unprivileged user running systemd in the container does not have permission to manage the namespace. The &lt;code&gt;oc logs&lt;/code&gt; output demonstrates this.&lt;/p&gt;
&lt;h3 id=&quot;container_manage_cgroups-selinux-boolean&quot;&gt;&lt;code&gt;container_manage_cgroups&lt;/code&gt; SELinux boolean &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#container_manage_cgroups-selinux-boolean&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I have one more thing to try. The &lt;code&gt;container_manage_cgroups&lt;/code&gt; SELinux boolean was disabled on the worker nodes (per default configuration). Perhaps it is still needed, even when using cgroups v2. I enabled it on the worker node (directly from the debug shell, for now):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# setsebool container_manage_cgroup on&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I again created the nginx pod as the &lt;code&gt;test&lt;/code&gt; user. It failed with the same error as the previous attempt, when &lt;code&gt;container_manage_cgroup&lt;/code&gt; was &lt;em&gt;off&lt;/em&gt;. So that was not the issue, or at least not the immediate issue.&lt;/p&gt;
&lt;h2 id=&quot;next-steps&quot;&gt;Next steps &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#next-steps&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point, I have successfully enabled cgroups v2 on worker nodes. Container sandboxes have their own cgroup namespace. But inside the container, systemd fails with permission errors when it attempts some cgroup management.&lt;/p&gt;
&lt;p&gt;The next step is to test the systemd container in OpenShift with cgroups v2 enabled &lt;em&gt;and&lt;/em&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-03-openshift-4.7-user-namespaces.html&quot;&gt;user namespaces enabled&lt;/a&gt;. Both of these features are necessary for securely running a complex, systemd-based application in OpenShift. My hope is that enabling them &lt;em&gt;together&lt;/em&gt; is the last step to getting systemd-based containers working properly in OpenShift. I will investigate and report the results in an upcoming post.&lt;/p&gt;</description>
	<pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Luc de Louw: Using KDC Proxy to authenticate users</title>
	<guid>https://blog.delouw.ch/?p=2852</guid>
	<link>https://blog.delouw.ch/2021/03/29/using-kdc-proxy-to-authenticate-users/</link>
	<description>&lt;p&gt;How to authenticate users with Kerberos when port 88 is not available in a DMZ? Use an HTTPS server as a proxy. IPA comes with an integrated KDC Proxy and it&amp;#8217;s simple to make use of it. A typical use case is a cross-domain trust with AD, where the Linux clients are not allowed to directly talk to AD because of firewall and/or security policy restrictions. Another use-case is where clients in a DMZ are not allowed to directly communicate &lt;a class=&quot;read-more&quot; href=&quot;https://blog.delouw.ch/2021/03/29/using-kdc-proxy-to-authenticate-users/&quot;&gt;....Read More&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The post &lt;a rel=&quot;nofollow&quot; href=&quot;https://blog.delouw.ch/2021/03/29/using-kdc-proxy-to-authenticate-users/&quot;&gt;Using KDC Proxy to authenticate users&lt;/a&gt; appeared first on &lt;a rel=&quot;nofollow&quot; href=&quot;https://blog.delouw.ch&quot;&gt;Luc de Louw&amp;#039;s Blog&lt;/a&gt;.&lt;/p&gt;</description>
	<pubDate>Mon, 29 Mar 2021 14:52:26 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: Multiple users in user namespaces on OpenShift</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-03-10-openshift-user-namespace-multi-user.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-03-10-openshift-user-namespace-multi-user.html</link>
	<description>&lt;h1 id=&quot;multiple-users-in-user-namespaces-on-openshift&quot;&gt;Multiple users in user namespaces on OpenShift&lt;/h1&gt;
&lt;p&gt;In the &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2021-03-03-openshift-4.7-user-namespaces.html&quot;&gt;previous post&lt;/a&gt; I confirmed that user namespaced pods are working in OpenShift 4.7. There are some rough edges, and the feature must be explicitly enabled in the cluster. But it fundamentally works.&lt;/p&gt;
&lt;p&gt;One area I identified for a follow-up investigation is the behaviour of containers that execute multiple processes as different users. The correct and “expected” behaviour is important for &lt;em&gt;systemd&lt;/em&gt;-based containers (among other scenarios). I did not anticipate any problems, but this is something we need to verify as part of the effort to bring FreeIPA to OpenShift. This post records my steps to verify that multi-user containers work as needed in user namespaces on OpenShift.&lt;/p&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#setup&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&quot;cluster-configuration&quot;&gt;Cluster configuration &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cluster-configuration&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I configured the cluster as recorded in my earlier post, &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2020-12-01-openshift-crio-userns.html&quot;&gt;&lt;em&gt;User namespaces in OpenShift via CRI-O annotations&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;test-program&quot;&gt;Test program &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#test-program&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I wrote a small Python program to serve as the container entrypoint. This program will run as &lt;code&gt;root&lt;/code&gt; (in the namespace). For each of several hardcoded system accounts, it invokes &lt;code&gt;fork(2)&lt;/code&gt; to duplicate the process. The child process executes &lt;code&gt;setuid(2)&lt;/code&gt; to switch user account, then &lt;code&gt;execlp(3)&lt;/code&gt; to replace itself with the &lt;code&gt;sleep(1)&lt;/code&gt; program. The duration to sleep depends on the UID of the system account that executes it.&lt;/p&gt;
&lt;p&gt;Outside the container, we will be able to observe whether the program (and its child processes) are running, and which user accounts they are running under.&lt;/p&gt;
&lt;p&gt;The source of the test program:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; os, pwd, time&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-3&quot;&gt;&lt;/a&gt;users &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; [&lt;span class=&quot;st&quot;&gt;'root'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'daemon'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'operator'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'nobody'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'mail'&lt;/span&gt;]&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-4&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; user &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt; users:&lt;/span&gt;
&lt;span id=&quot;cb1-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-6&quot;&gt;&lt;/a&gt;    ent &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; pwd.getpwnam(user)&lt;/span&gt;
&lt;span id=&quot;cb1-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-7&quot;&gt;&lt;/a&gt;    uid &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; ent.pw_uid&lt;/span&gt;
&lt;span id=&quot;cb1-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-8&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; os.fork() &lt;span class=&quot;op&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;
&lt;span id=&quot;cb1-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-9&quot;&gt;&lt;/a&gt;        os.setuid(uid)&lt;/span&gt;
&lt;span id=&quot;cb1-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-10&quot;&gt;&lt;/a&gt;        os.execlp(&lt;span class=&quot;st&quot;&gt;'sleep'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'sleep'&lt;/span&gt;, &lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3000&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; uid))&lt;/span&gt;
&lt;span id=&quot;cb1-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-11&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-12&quot;&gt;&lt;/a&gt;time.sleep(&lt;span class=&quot;dv&quot;&gt;3600&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;container&quot;&gt;Container &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#container&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;Containerfile&lt;/code&gt; is simple. Based on &lt;code&gt;fedora:33-x86_64&lt;/code&gt;, it copies the Python program into the container and defines the entry point:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode dockerfile&quot;&gt;&lt;code class=&quot;sourceCode dockerfile&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;FROM&lt;/span&gt; fedora:33-x86_64&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;COPY&lt;/span&gt; test_multiuser.py .&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;ENTRYPOINT&lt;/span&gt; [&lt;span class=&quot;st&quot;&gt;&amp;quot;python3&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;test_multiuser.py&amp;quot;&lt;/span&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I built the container and pushed it to &lt;a href=&quot;https://quay.io/repository/ftweedal/test-multiuser&quot;&gt;&lt;code&gt;quay.io/ftweedal/test-multiuser:latest&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;pod-specification&quot;&gt;Pod specification &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#pod-specification&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The pod YAML is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Pod&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; multiuser-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;openshift.io/scc&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; restricted&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;io.kubernetes.cri-o.userns-mode&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;auto:size=65536;map-to-root=true&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; multiuser-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; quay.io/ftweedal/test-multiuser:latest&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-14&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsUser&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsGroup&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-16&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-16&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-17&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-17&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sysctls&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-18&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-18&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;net.ipv4.ping_group_range&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-19&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-19&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;0 65535&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;io.kubernetes.cri-o.userns-mode&lt;/code&gt; annotation tells CRI-O to run the pod in a user namespace. The &lt;code&gt;runAsUser&lt;/code&gt; and &lt;code&gt;runAsGroup&lt;/code&gt; fields tell CRI-O to execute the entry point process as &lt;code&gt;root&lt;/code&gt; (inside the namespace).&lt;/p&gt;
&lt;h2 id=&quot;verification&quot;&gt;Verification &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#verification&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I created the pod:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc --as test create -f multiuser-test.yaml
pod/multiuser-test created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a short time, I queried the status, node and container ID of the pod:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc get -o json pod multiuser-test \
    | jq '.status.phase,
          .spec.nodeName,
          .status.containerStatuses[0].containerID'
&amp;quot;Running&amp;quot;
&amp;quot;ft-47dev-1-4kplg-worker-0-qjfcj&amp;quot;
&amp;quot;cri-o://ee693645f41aa5b54b890862778f173ebaf465f741231426c9e80237aa60660b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I opened a debug shell on the worker node and queried the container PID (process ID):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/ft-47dev-1-4kplg-worker-0-qjfcj
Starting pod/ft-47dev-1-4kplg-worker-0-qjfcj-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.8.0.165
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# crictl inspect ee69364 | jq .info.pid
2445729&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I viewed the user map of the process:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# cat /proc/2445729/uid_map
         0     265536      65536&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This confirms that the container is in a user namespace. The UID range &lt;code&gt;0&lt;/code&gt;–&lt;code&gt;65535&lt;/code&gt; in the container is mapped to &lt;code&gt;265536&lt;/code&gt;–&lt;code&gt;331071&lt;/code&gt; on the host. That is in line with what I expect.&lt;/p&gt;
&lt;p&gt;Now let’s see what else is running in that namespace. We can use &lt;code&gt;pgrep(1)&lt;/code&gt; with the &lt;code&gt;--ns PID&lt;/code&gt; option, which selects all processes in the same namespace(s) as &lt;code&gt;PID&lt;/code&gt;. Then &lt;code&gt;ps(1)&lt;/code&gt; can tell us which users are executing those processes.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# pgrep --ns 2445729 \
        | xargs ps -o user,pid,cmd --sort pid
USER         PID CMD
265536   2445729 sleep 3000
265538   2445766 sleep 3002
265547   2445767 sleep 3011
331070   2445768 sleep 68534
265544   2445769 sleep 3008
265536   2445770 python3 stuff.py&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The entry point spawned the expected 5 child processes. Each is running as a different user. This is the &lt;em&gt;host&lt;/em&gt; view of the processes. Subtracting the base of the &lt;code&gt;uid_map&lt;/code&gt; from each UID, we observe that the UIDs &lt;em&gt;in the namespace&lt;/em&gt; are: &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt;, &lt;code&gt;11&lt;/code&gt;, &lt;code&gt;65534&lt;/code&gt; and &lt;code&gt;8&lt;/code&gt;. These are the UIDs of the five accounts declared in the test program.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#conclusion&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Containers that use multiple users work as expected when using user namespaces in OpenShift.&lt;/p&gt;
&lt;p&gt;The so far unstated assumption is that the mapped UID range includes all the UIDs actually used by the containerised application. Different applications use different UIDs, and different operating systems define different UIDs. So take care that the UID map hinted by the CRI-O annotation suits the container and application.&lt;/p&gt;
&lt;p&gt;Note that mapped UID ranges in Linux need not be contiguous (either outside or inside the container). That is, a process may have multiple lines in its &lt;code&gt;/proc/&amp;lt;PID&amp;gt;/uid_map&lt;/code&gt;, mapping multiple, non-overlapping and not-necessarily-adjacent ranges. But I am talking about the Linux user namespace feature here. I have not yet checked whether CRI-O + OpenShift admits this more complex scenario. But it is fundamentally possible.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;nobody&lt;/code&gt; user in Fedora has UID &lt;code&gt;65534&lt;/code&gt;. Therefore a “simple mapping” must have a size not less than &lt;em&gt;65535&lt;/em&gt; to use the &lt;code&gt;nobody&lt;/code&gt; account in a user namespaced pod. OK, let’s round that up to &lt;em&gt;65536 = 2&lt;sup&gt;16&lt;/sup&gt;&lt;/em&gt;. With a total UID space of &lt;em&gt;2&lt;sup&gt;16+16&lt;/sup&gt;&lt;/em&gt;, you are limited to less than &lt;em&gt;65536&lt;/em&gt; separate mappings. It sounds like a lot, but this limit could be a problem in large, complex environments. But most applications will use only a handful of UIDs. Non-contiguous UID mapping could dramatically increase the number of ranges available, by not mapping UIDs that applications do not use. But there is substantial complexity in defining and managing non-contiguous UID mappings.&lt;/p&gt;</description>
	<pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: User namespace support in OpenShift 4.7</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2021-03-03-openshift-4.7-user-namespaces.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2021-03-03-openshift-4.7-user-namespaces.html</link>
	<description>&lt;h1 id=&quot;user-namespace-support-in-openshift-4.7&quot;&gt;User namespace support in OpenShift 4.7&lt;/h1&gt;
&lt;p&gt;In a &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/2020-12-01-openshift-crio-userns.html&quot;&gt;previous post&lt;/a&gt; I investigated how to use the annotation-based &lt;a href=&quot;https://github.com/cri-o/cri-o/pull/3944&quot;&gt;user namespace support&lt;/a&gt; in CRI-O 1.20. At the end of that post, I was stuck. Now that &lt;a href=&quot;https://www.openshift.com/blog/red-hat-openshift-4.7-is-now-available&quot;&gt;OpenShift 4.7 has been released&lt;/a&gt;, where do things stand?&lt;/p&gt;
&lt;h2 id=&quot;user-namespaces-are-working&quot;&gt;User namespaces are working &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#user-namespaces-are-working&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Using the same setup, and a similar pod specification, I am able to run the pod in a user namespace. The process executes as &lt;code&gt;root&lt;/code&gt; inside the namespace, and an unprivileged account outside the namespace.&lt;/p&gt;
&lt;p&gt;I won’t repeat all the setup here, but one important difference is that I granted to &lt;code&gt;anyuid&lt;/code&gt; SCC to the account that creates the pod (named &lt;code&gt;test&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc adm policy add-scc-to-user anyuid test
securitycontextconstraints.security.openshift.io/anyuid added to: [&amp;quot;test&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pod definition is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;pp&quot;&gt;% cat userns-test.yaml&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; v1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; Pod&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; userns-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;openshift.io/scc&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; restricted&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;io.kubernetes.cri-o.userns-mode&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;auto:size=65536;map-to-root=true&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; userns-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; freeipa/freeipa-server:fedora-31&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;sleep&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;3601&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-14&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsUser&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-16&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-16&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsGroup&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-17&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-17&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-18&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-18&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sysctls&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-19&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-19&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;net.ipv4.ping_group_range&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-20&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-20&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;0 65535&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the &lt;code&gt;io.kubernetes.cri-o.userns-mode&lt;/code&gt; annotation. That activates the user namespace feature. The &lt;code&gt;runAsUser&lt;/code&gt; and &lt;code&gt;runAsGroup&lt;/code&gt; fields in &lt;code&gt;securityContext&lt;/code&gt; are also important.&lt;/p&gt;
&lt;p&gt;I create the pod. After a few moments I observe that it is running, and query the node and container ID:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;$ oc --as test create -f userns-test.yaml
pod/userns-test created

% oc get -o json pod userns-test \
    | jq .status.phase
&amp;quot;Running&amp;quot;

% oc get -o json pod userns-test \
    | jq .spec.nodeName
&amp;quot;ft-47dev-1-4kplg-worker-0-qjfcj&amp;quot;

% oc get -o json pod userns-test \
    | jq &amp;quot;.status.containerStatuses[0].containerID&amp;quot;
&amp;quot;cri-o://92bf6c3b61337f18f4c963450b5db76cbcd4aa73e2659759ba2725f4d0f8aac7&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a debug shell on the worker node, I use &lt;code&gt;crictl&lt;/code&gt; to find out the pid of the pod’s (first) process:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc debug node/ft-47dev-1-4kplg-worker-0-qjfcj
Starting pod/ft-47dev-1-4kplg-worker-0-qjfcj-debug ...
To use host binaries, run `chroot /host`
Pod IP: 10.8.0.165
If you don't see a command prompt, try pressing enter.
sh-4.2# chroot /host
sh-4.4# crictl inspect 92bf6c3b | jq .info.pid
937107&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;Earlier versions of &lt;code&gt;crictl&lt;/code&gt; have the PID in the top-level object (&lt;code&gt;jq&lt;/code&gt; selector &lt;code&gt;.pid&lt;/code&gt;). The selector is now &lt;code&gt;.info.pid&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now we can query the UID map of the container process:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# cat /proc/937107/uid_map
         0     200000      65536&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows that the process is running as uid 0 (&lt;code&gt;root&lt;/code&gt;) in the namespace, and uid 200000 outside the namespace. The mapped range is contiguous and has size 65536, which agrees with the annotation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;io.kubernetes.cri-o.userns-mode: &amp;quot;auto:size=65536;map-to-root=true&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is great!&lt;/p&gt;
&lt;h2 id=&quot;they-still-require-a-privileged-service-account&quot;&gt;They still require a privileged service account &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#they-still-require-a-privileged-service-account&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my earlier investigation I found that that users require the &lt;code&gt;anyuid&lt;/code&gt; SCC (or equivalent) to create user-namespaced pods running as specific UIDs (e.g. &lt;code&gt;root&lt;/code&gt;) inside the pod. This is still the case. Rescinding &lt;code&gt;anyuid&lt;/code&gt; from user &lt;code&gt;test&lt;/code&gt; and (re)creating the pod results in an error:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;% oc adm policy remove-scc-from-user anyuid test
securitycontextconstraints.security.openshift.io/anyuid removed from: [&amp;quot;test&amp;quot;]

% oc --as test create -f userns-test.yaml
Error from server (Forbidden): error when creating
&amp;quot;userns-test.yaml&amp;quot;: pods &amp;quot;userns-test&amp;quot; is forbidden: unable to
validate against any security context constraint:
[spec.containers[0].securityContext.runAsUser: Invalid value: 0:
must be in the ranges: [1000630000, 1000639999]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end of my previous post, I wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The security context constraint (SCC) is prohibiting the use of uid &lt;code&gt;0&lt;/code&gt; for the container process. Switching to a permissive SCC might allow me to proceed, but it would also mean using a more privileged OpenShift user account. Then that privileged account could then create containers running as &lt;code&gt;root&lt;/code&gt; &lt;em&gt;in the system user namespace&lt;/em&gt;. We want user namespaces in OpenShift so that we can &lt;em&gt;avoid&lt;/em&gt; this exact scenario. So resorting to a permissive SCC (e.g. &lt;code&gt;anyuid&lt;/code&gt;) feels like the wrong way to go.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After giving this more thought, my opinion has shifted. This is still an important gap in overall security, and it should be addressed. But even though it currently requires a privileged account to create user-namespaced pods, that fact that you even &lt;em&gt;can&lt;/em&gt; is a huge win.&lt;/p&gt;
&lt;p&gt;In other words, the user namespace support in its current form is still a giant leap forward. Previously, many kinds of applications cannot run securely in OpenShift. The service account privileges caveat may be unacceptable to some, but I hope that would be addressed in time.&lt;/p&gt;
&lt;h2 id=&quot;inconsistent-treatment-of-securitycontext&quot;&gt;Inconsistent treatment of &lt;code&gt;securityContext&lt;/code&gt; &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#inconsistent-treatment-of-securitycontext&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The PodSpec I used above (with success) is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb8&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb8-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; userns-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; freeipa/freeipa-server:fedora-31&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;sleep&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;3601&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsUser&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsGroup&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sysctls&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;net.ipv4.ping_group_range&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb8-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb8-11&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;0 65535&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note there are two &lt;code&gt;securityContext&lt;/code&gt; fields. The first, in the Container spec, is a &lt;a href=&quot;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#securitycontext-v1-core&quot;&gt;SecurityContext&lt;/a&gt; object. The second, in the PodSpec, is a &lt;a href=&quot;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core&quot;&gt;PodSecurityContext&lt;/a&gt; object.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;runAsUser&lt;/code&gt; and &lt;code&gt;runAsGroup&lt;/code&gt; fields can be specified in either of these objects (or both, with SecurityContext taking precedence). I can move these fields to the PodSecurityContext, as below.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb9&quot;&gt;&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span id=&quot;cb9-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; userns-test&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; freeipa/freeipa-server:fedora-31&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;sleep&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;3601&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsUser&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;runAsGroup&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;sysctls&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-9&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;net.ipv4.ping_group_range&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb9-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;at&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;at&quot;&gt; &lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;0 65535&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;According to the documentation, this object should have the same meaning as the previous one. But there is a critical behavioural difference! I create and examine the pod as before:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;$ oc --as test create -f userns-test.yaml
pod/userns-test created

% oc get -o json pod userns-test \
    | jq .status.phase
&amp;quot;Running&amp;quot;

% oc get -o json pod userns-test \
    | jq .spec.nodeName
&amp;quot;ft-47dev-1-4kplg-worker-0-qjfcj&amp;quot;

% oc get -o json pod userns-test \
    | jq &amp;quot;.status.containerStatuses[0].containerID&amp;quot;
&amp;quot;cri-o://c90760e88ee8493bfdb9af661c18afef139b79541160850ceac125b0c62e1de3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And in the node debug shell, I query the &lt;code&gt;uid_map&lt;/code&gt; for the container:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;&lt;code&gt;sh-4.4# crictl inspect c90760e | jq .info.pid
1022187
sh-4.4# cat /proc/1022187/uid_map
         1     200001      65535
         0          0          1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This subtle change to the object definition caused OpenShift to run the process as &lt;code&gt;root&lt;/code&gt; in the container &lt;strong&gt;and on the host!&lt;/strong&gt; Given that the Kubernetes documentation implies that the two configurations are equivalent, this is a dangerous situation. I will file a ticket to bring this to the attention of the developers.&lt;/p&gt;
&lt;h2 id=&quot;continuing-investigation&quot;&gt;Continuing investigation &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#continuing-investigation&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;There are two particular lines of investigation I need to pursue from here. The first is to confirm that &lt;code&gt;setuid(2)&lt;/code&gt; and related functionality work properly in the namespaced container. This is important for containers that run multiple processes as different users. I do not anticipate any particular issues here. But I still need to verify it.&lt;/p&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;p&gt;This is not the &lt;em&gt;cloud native&lt;/em&gt; way. But this is the approach we are taking, for now. “Monolithic container” is a reasonable way to bring complex, traditional software systems into the cloud. As long as it can be done securely.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The other line of investigation is to find out how user-namespaced containers interact with volume mounts. If multiple containers, perhaps running on different nodes, read and write the same volume, what are the UIDs on that volume? Do we need stable, cluster-wide subuid/subgid mappings? If so, how can that be achieved? I expect I will much more to say about this in upcoming posts.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#conclusion&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;CRI-O annotation-based user namespaces work in OpenShift 4.7. But there are some caveats, and at least one scary “gotcha”. Nevertheless, for simple workloads the feature does work well. It is big leap forward for running more kinds of workloads without compromising the security of your cluster.&lt;/p&gt;
&lt;p&gt;In time, I hope the account privilege (SCC) caveat and &lt;code&gt;securityContext&lt;/code&gt; issues can be resolved. I will file tickets and continue to discuss these topics with the OpenShift developers. And my investigations about more complex workloads and multi-node considerations shall continue.&lt;/p&gt;</description>
	<pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Luc de Louw: Using DNSSEC with (Free) IPA</title>
	<guid>https://blog.delouw.ch/?p=2785</guid>
	<link>https://blog.delouw.ch/2021/01/11/using-dnssec-with-free-ipa/</link>
	<description>&lt;p&gt;The DNS infrastructure contains a growing number of critical information such as services records pointing to authentication services, TLSA records, SSH fingerprints and the like. DNSSEC signs this information, the client can trust the information DNS sends. It protects against forged information through cache poisoning. This article shows how to achieve a DNSSEC protected DNS environment with the help of FreeIPA This article was taking some time to write as I wanted to see how it behaves in the long &lt;a class=&quot;read-more&quot; href=&quot;https://blog.delouw.ch/2021/01/11/using-dnssec-with-free-ipa/&quot;&gt;....Read More&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The post &lt;a rel=&quot;nofollow&quot; href=&quot;https://blog.delouw.ch/2021/01/11/using-dnssec-with-free-ipa/&quot;&gt;Using DNSSEC with (Free) IPA&lt;/a&gt; appeared first on &lt;a rel=&quot;nofollow&quot; href=&quot;https://blog.delouw.ch&quot;&gt;Luc de Louw&amp;#039;s Blog&lt;/a&gt;.&lt;/p&gt;</description>
	<pubDate>Mon, 11 Jan 2021 07:38:06 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: Simple Java to C bindings via JNA</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2020-12-16-java-jna.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2020-12-16-java-jna.html</link>
	<description>&lt;h1 id=&quot;simple-java-to-c-bindings-via-jna&quot;&gt;Simple Java to C bindings via JNA&lt;/h1&gt;
&lt;p&gt;This post is an introduction to &lt;em&gt;JNI&lt;/em&gt;, an FFI system for Java.&lt;/p&gt;
&lt;p&gt;Most languages offer a way to bind to (use) shared libraries, which are often written in C (Rust is becoming popular too). The general name for such a facility is &lt;a href=&quot;https://en.wikipedia.org/wiki/Foreign_function_interface&quot;&gt;&lt;em&gt;foreign function interface&lt;/em&gt;&lt;/a&gt; (&lt;em&gt;FFI&lt;/em&gt;). FFIs facilitate code reuse, and use of operating system-level functions that would not otherwise be possible.&lt;/p&gt;
&lt;p&gt;There are two significant FFI systems for Java. The older is &lt;a href=&quot;https://docs.oracle.com/en/java/javase/14/docs/specs/jni/index.html&quot;&gt;&lt;em&gt;Java Native Interface&lt;/em&gt;&lt;/a&gt; (&lt;em&gt;JNI&lt;/em&gt;)—an official Java standard. The &lt;a href=&quot;https://github.com/dogtagpki/jss&quot;&gt;&lt;em&gt;JSS&lt;/em&gt;&lt;/a&gt; Java binding to the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Mozilla/Projects/NSS&quot;&gt;&lt;em&gt;NSS&lt;/em&gt;&lt;/a&gt; cryptography and security library makes heavy use of JNI. The main drawbacks of JNI are that it involves writing C, and is boilerplate-heavy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/java-native-access/jna&quot;&gt;&lt;em&gt;Java Native Access&lt;/em&gt;&lt;/a&gt; (&lt;em&gt;JNA&lt;/em&gt;) offers a more lightweight approach. You import JNA as a library and define your binding as a native Java object. There is only a small amount of boilerplate to import the JNA packages, open the shared library, and declare Java method signatures for the functions you want to use. JNA performs &lt;a href=&quot;https://github.com/java-native-access/jna/blob/5.6.0/www/Mappings.md&quot;&gt;automatic conversion&lt;/a&gt; between native Java and C types.&lt;/p&gt;
&lt;p&gt;If you are familiar with Python, you might recognise that the JNA approach is similar to &lt;a href=&quot;https://cffi.readthedocs.io/en/latest/&quot;&gt;&lt;em&gt;cffi&lt;/em&gt;&lt;/a&gt;. In fact, JNA and cffi use the same underlying FFI library, &lt;a href=&quot;https://sourceware.org/libffi/&quot;&gt;&lt;em&gt;libffi&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;using-jna-in-dogtag&quot;&gt;Using JNA in Dogtag &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#using-jna-in-dogtag&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To simplify and speed up &lt;a href=&quot;https://www.freeipa.org/&quot;&gt;FreeIPA&lt;/a&gt; startup, I needed to implement systemd notification support in &lt;a href=&quot;https://www.dogtagpki.org/&quot;&gt;Dogtag PKI&lt;/a&gt;. Dogtag (when so configured) should call &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/sd_notify.html&quot;&gt;&lt;code&gt;sd_notify(3)&lt;/code&gt;&lt;/a&gt; to notify the system service manager when it has started up and is ready to service requests.&lt;/p&gt;
&lt;p&gt;Dogtag already uses JNI in a few places (as does some of its dependencies, including JSS). But I was not keen to use JNI, with all its complexity, for this small use case. A colleague pointed me to JNA, and I decided to give it a go.&lt;/p&gt;
&lt;p&gt;The resulting code is so small I’ll just include it all here, with commentary. (I made some changes for clarity; you can review the actual patch in the &lt;a href=&quot;https://github.com/dogtagpki/pki/pull/569/files&quot;&gt;pull request&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode java&quot;&gt;&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;im&quot;&gt; com.netscape.cmscore.systemd;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;im&quot;&gt; com.sun.jna.Library;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;im&quot;&gt; com.sun.jna.Native;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-5&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb1-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;class&lt;/span&gt; SystemdStartupNotifier {&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Import JNA and begin the class definition.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode java&quot;&gt;&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;interface&lt;/span&gt; Systemd &lt;span class=&quot;kw&quot;&gt;extends&lt;/span&gt; Library {&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-2&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;sd_booted&lt;/span&gt;();&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-3&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;sd_notify&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; unset_env, &lt;span class=&quot;bu&quot;&gt;String&lt;/span&gt; state);&lt;/span&gt;
&lt;span id=&quot;cb2-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb2-4&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Declare an interface to the shared library by extending &lt;code&gt;sun.jna.Native&lt;/code&gt;. Method signatures must match the native function signatures, according to the &lt;a href=&quot;https://github.com/java-native-access/jna/blob/5.6.0/www/Mappings.md&quot;&gt;type mappings&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode java&quot;&gt;&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-1&quot;&gt;&lt;/a&gt;Systemd systemd = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;init&lt;/span&gt;() {&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-4&quot;&gt;&lt;/a&gt;    systemd = Native.&lt;span class=&quot;fu&quot;&gt;load&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;systemd&amp;quot;&lt;/span&gt;, Systemd.&lt;span class=&quot;fu&quot;&gt;class&lt;/span&gt;);&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb3-5&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;init()&lt;/code&gt; gets called by initialisation code. &lt;code&gt;Native.load()&lt;/code&gt; loads &lt;code&gt;libsystemd.so&lt;/code&gt; and initialises the foreign library proxy with respect to the &lt;code&gt;Systemd&lt;/code&gt; interface. The proxy object is assigned to the instance variable &lt;code&gt;systemd&lt;/code&gt;. An alternative approach is to assign the proxy object to a static variable in the interface definition (&lt;a href=&quot;https://github.com/java-native-access/jna/blob/5.6.0/www/GettingStarted.md#getting-started-with-jna&quot;&gt;example&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb4&quot;&gt;&lt;pre class=&quot;sourceCode java&quot;&gt;&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span id=&quot;cb4-1&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;notify&lt;/span&gt;(&lt;span class=&quot;bu&quot;&gt;String&lt;/span&gt; status) {&lt;/span&gt;
&lt;span id=&quot;cb4-2&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-2&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (!systemd.&lt;span class=&quot;fu&quot;&gt;sd_booted&lt;/span&gt;()) {&lt;/span&gt;
&lt;span id=&quot;cb4-3&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-3&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb4-4&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-4&quot;&gt;&lt;/a&gt;    } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb4-5&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-5&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; r = systemd.&lt;span class=&quot;fu&quot;&gt;sd_notify&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&quot;cb4-6&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-6&quot;&gt;&lt;/a&gt;            &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;/* don't unset environment */&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&quot;cb4-7&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-7&quot;&gt;&lt;/a&gt;            status);&lt;/span&gt;
&lt;span id=&quot;cb4-8&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-8&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (r &amp;lt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&quot;cb4-9&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-9&quot;&gt;&lt;/a&gt;            &lt;span class=&quot;bu&quot;&gt;System&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;err&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;println&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;sd_notify failed&amp;quot;&lt;/span&gt;);&lt;/span&gt;
&lt;span id=&quot;cb4-10&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-10&quot;&gt;&lt;/a&gt;            &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb4-11&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-11&quot;&gt;&lt;/a&gt;        } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb4-12&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-12&quot;&gt;&lt;/a&gt;            &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb4-13&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-13&quot;&gt;&lt;/a&gt;        }&lt;/span&gt;
&lt;span id=&quot;cb4-14&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-14&quot;&gt;&lt;/a&gt;    }&lt;/span&gt;
&lt;span id=&quot;cb4-15&quot;&gt;&lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#cb4-15&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;notify()&lt;/code&gt; makes two foreign calls. First it calls &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/sd_booted.html&quot;&gt;&lt;code&gt;sd_booted(3)&lt;/code&gt;&lt;/a&gt; to see if the system was booted using systemd. If not, we return (successfully). If the program &lt;em&gt;is&lt;/em&gt; running under systemd it calls &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/sd_notify.html&quot;&gt;&lt;code&gt;sd_notify(3)&lt;/code&gt;&lt;/a&gt;, logging an error on failure.&lt;/p&gt;
&lt;p&gt;That’s pretty much all there is to it. This is much, &lt;em&gt;much&lt;/em&gt; nicer than JNI.&lt;/p&gt;
&lt;h2 id=&quot;discussion&quot;&gt;Discussion &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#discussion&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The adoption of JNA in Dogtag—which already (and still) uses JNI—was not without debate. But JNA is mature, widely available and supported in Dogtag’s target platforms (Fedora and RHEL). In the end, it was agreed that JNA is a nice approach. If JNA becomes problematic for any reason we can reimplement the binding to use JNI instead. The patch was accepted.&lt;/p&gt;
&lt;p&gt;As the Dogtag experience demonstrates, where multiple FFI systems are available it is not necessarily an either/or choice. JNI and JNA now happily coexist in the Dogtag database. It would be nice to gradually migrate Dogtag away from JNI and use JNA exclusively, but this is not a priority.&lt;/p&gt;
&lt;p&gt;There are more advanced topics that were not covered in this post. These include callbacks, custom type mapping and dealing with C &lt;code&gt;struct&lt;/code&gt; and &lt;code&gt;union&lt;/code&gt; types. The &lt;a href=&quot;https://github.com/java-native-access/jna/tree/5.6.0#using-the-library&quot;&gt;in-tree documentation&lt;/a&gt; provides guidance on these and other advanced topics.&lt;/p&gt;</description>
	<pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Fraser Tweedale: Kubernetes DNS Service Discovery limitations</title>
	<guid>https://frasertweedale.github.io/blog-redhat/posts/2020-12-08-k8s-srv-limitation.html</guid>
	<link>https://frasertweedale.github.io/blog-redhat/posts/2020-12-08-k8s-srv-limitation.html</link>
	<description>&lt;h1 id=&quot;kubernetes-dns-service-discovery-limitations&quot;&gt;Kubernetes DNS Service Discovery limitations&lt;/h1&gt;
&lt;p&gt;Kubernetes &lt;em&gt;Service&lt;/em&gt; objects expose applications running in Pods as network services. For each combination of service name, port and associated Pod, the Kubernetes DNS system creates a DNS &lt;code&gt;SRV&lt;/code&gt; record that can be used for service discovery.&lt;/p&gt;
&lt;p&gt;In this post I demonstrate a deficiency in this system that obstructs important, real-world use cases, and sketch potential solutions.&lt;/p&gt;
&lt;h2 id=&quot;overview-of-kubernetes-services-and-dns&quot;&gt;Overview of Kubernetes Services and DNS &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#overview-of-kubernetes-services-and-dns&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The following Service definition defines an LDAP service:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ oc create -f service-test.yaml 
apiVersion: v1
kind: Service
metadata:
  name: service-test
  labels:
    app: service-test
spec:
  selector:
    app: service-test
  clusterIP: None
  ports:
  - name: ldap
    protocol: TCP
    port: 389

$ oc create -f service-test.yaml
service/service-test created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Service controller creates &lt;em&gt;Endpoint&lt;/em&gt; objects to associating each of the Service &lt;code&gt;ports&lt;/code&gt; with each Pod matching the Service &lt;code&gt;selector&lt;/code&gt;. If there are no matching pods, there are no endpoints:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ oc get endpoints service-test
NAME           ENDPOINTS   AGE
service-test   &amp;lt;none&amp;gt;      8m1s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we add a matching pod:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat pod-service-test.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: service-test
  labels:
    app: service-test
spec:
  containers:
  - name: service-test
    image: freeipa/freeipa-server:fedora-31
    command: [&amp;quot;sleep&amp;quot;, &amp;quot;3601&amp;quot;]

$ oc create -f pod-service-test.yaml 
pod/service-test created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then the Service controller creates an endpoint that maps the Service to the Pod:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ oc get endpoints service-test
NAME           ENDPOINTS         AGE
service-test   10.129.2.13:389   16m

$ oc get -o yaml endpoints service-test
apiVersion: v1
kind: Endpoints
metadata:
  labels:
    app: service-test
    service.kubernetes.io/headless: &amp;quot;&amp;quot;
  ... 
subsets:
- addresses:
  - ip: 10.129.2.13
    nodeName: ft-47dev-2-27h8r-worker-0-f8bnl
    targetRef:
      kind: Pod
      name: service-test
      namespace: test
      resourceVersion: &amp;quot;4556709&amp;quot;
      uid: 296030f5-8dff-4f69-be96-ce6f0aa12653
  ports:
  - name: ldap
    port: 389
    protocol: TCP&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cluster DNS systems (there are different implementations, e.g. &lt;a href=&quot;https://github.com/kubernetes/dns&quot;&gt;kubedns&lt;/a&gt;, and the OpenShift &lt;a href=&quot;https://github.com/openshift/cluster-dns-operator&quot;&gt;Cluster DNS Operator&lt;/a&gt;) use the Endpoints objects to manage DNS records for applications running in the cluster. In particular, it creates &lt;code&gt;SRV&lt;/code&gt; records mapping each service &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;protocol&lt;/code&gt; combination to the pod(s) that provide that service. The behaviour is defined in the &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml&quot;&gt;Kubernetes DNS-Based Service Discovery specification&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The SRV record owner name has the form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;_&amp;lt;port&amp;gt;._&amp;lt;proto&amp;gt;.&amp;lt;service&amp;gt;.&amp;lt;ns&amp;gt;.svc.&amp;lt;zone&amp;gt;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;ns&lt;/code&gt; is the project namespace and &lt;code&gt;zone&lt;/code&gt; is the cluster DNS zone. The objects created above result in the follow &lt;code&gt;SRV&lt;/code&gt; and &lt;code&gt;A&lt;/code&gt; records:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ oc rsh service-test

sh-5.0# dig +short SRV \
    _ldap._tcp.service-test.test.svc.cluster.local
0 100 389 10-129-2-13.service-test.test.svc.cluster.local.

sh-5.0# dig +short A \
    10-129-2-13.service-test.test.svc.cluster.local
10.129.2.13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information above DNS &lt;code&gt;SRV&lt;/code&gt; records, see &lt;a href=&quot;https://tools.ietf.org/html/rfc2782&quot;&gt;RFC 2782&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;kubernetes-srv-limitation&quot;&gt;Kubernetes SRV limitation &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#kubernetes-srv-limitation&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Some services operate over TCP, some over UDP. And some operate over &lt;em&gt;both&lt;/em&gt; TCP and UDP. Two examples are DNS and Kerberos. &lt;code&gt;SRV&lt;/code&gt; records are of particular importance for Kerberos; they are used (&lt;a href=&quot;https://web.mit.edu/kerberos/krb5-devel/doc/admin/realm_config.html#hostnames-for-kdcs&quot;&gt;widely&lt;/a&gt;, by &lt;a href=&quot;https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-adts/7fcdce70-5205-44d6-9c3a-260e616a2f04&quot;&gt;multiple&lt;/a&gt; &lt;a href=&quot;https://www.freeipa.org/page/V4/DNS_Location_Mechanism&quot;&gt;implementations&lt;/a&gt;) for KDC discovery.&lt;/p&gt;
&lt;p&gt;So to host a Kerberos KDC in Kubernetes and enable service discovery, we need two sets of SRV records: &lt;code&gt;_kerberos._tcp&lt;/code&gt; and &lt;code&gt;_kerberos._udp&lt;/code&gt;. And likewise for the &lt;code&gt;kpasswd&lt;/code&gt; and &lt;code&gt;kerberos-master&lt;/code&gt; service names. There could be (probably are) other protocols where a similar arrangement is required.&lt;/p&gt;
&lt;p&gt;So, let’s update the Service object and add the &lt;code&gt;kerberos&lt;/code&gt; ServicePort specs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat service-test.yaml 
apiVersion: v1
kind: Service
metadata:
  name: service-test
  labels:
    app: service-test
spec:
  selector:
    app: service-test
  clusterIP: None
  ports:
  - name: ldap
    protocol: TCP
    port: 389
  - name: kerberos
    protocol: TCP
    port: 88
  - name: kerberos
    protocol: UDP
    port: 88

$ oc replace -f service-test.yaml
The Service &amp;quot;service-test&amp;quot; is invalid:
spec.ports[2].name: Duplicate value: &amp;quot;kerberos&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, that’s a shame. Kerberos does not admit this important use case.&lt;/p&gt;
&lt;h3 id=&quot;endpoints-do-not-have-the-limitation&quot;&gt;Endpoints do not have the limitation &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#endpoints-do-not-have-the-limitation&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Interestingly, the Endpoints type does not have this limitation. The Service controller automatically creates Endpoints objects for Services. The ServicePorts are (as far as I can tell) copied across to the Endpoints object.&lt;/p&gt;
&lt;p&gt;I can manually replace the &lt;code&gt;endpoints/service-test&lt;/code&gt; object (see above) with the following spec that includes the “duplicate” &lt;code&gt;kerberos&lt;/code&gt; port:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat endpoints.yaml
apiVersion: v1
kind: Endpoints
metadata:
  creationTimestamp: &amp;quot;2020-12-07T03:51:30Z&amp;quot;
  labels:
    app: service-test
    service.kubernetes.io/headless: &amp;quot;&amp;quot;
  name: service-test
subsets:
- addresses:
  - ip: 10.129.2.13
    nodeName: ft-47dev-2-27h8r-worker-0-f8bnl
    targetRef:
      kind: Pod
      name: service-test
      namespace: test
      resourceVersion: &amp;quot;5522680&amp;quot;
      uid: 296030f5-8dff-4f69-be96-ce6f0aa12653
  ports:
  - name: ldap
    port: 389
    protocol: TCP
  - name: kerberos
    port: 88
    protocol: TCP
  - name: kerberos
    port: 88
    protocol: UDP

$ oc replace -f endpoints.yaml
endpoints/service-test replaced&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The object was accepted! Observe that the DNS system responds and creates &lt;em&gt;both&lt;/em&gt; the &lt;code&gt;_kerberos._tcp&lt;/code&gt; and &lt;code&gt;_kerberos._udp&lt;/code&gt; &lt;code&gt;SRV&lt;/code&gt; records:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ oc rsh service-test

sh-5.0# dig +short SRV \
    _kerberos._tcp.service-test.test.svc.cluster.local
0 100 88 10-129-2-13.service-test.test.svc.cluster.local.

sh-5.0# dig +short SRV \
    _kerberos._udp.service-test.test.svc.cluster.local
0 100 88 10-129-2-13.service-test.test.svc.cluster.local.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Therefore it seems the scope of this problem is limited to validation and processing of the &lt;code&gt;Service&lt;/code&gt; object. Other components of Kubernetes (Endpoint validation and the Cluster DNS Operator, at least) can already handle this use case.&lt;/p&gt;
&lt;h2 id=&quot;possible-resolutions&quot;&gt;Possible resolutions &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#possible-resolutions&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Besides manually fiddling with the Endpoints (eww) I am not aware of any workarounds, but I see two possible approaches to resolving this issue.&lt;/p&gt;
&lt;p&gt;One approach is to relax the uniqueness check. Instead of checking for uniqueness of ServicePort &lt;code&gt;name&lt;/code&gt;, check for the uniqueness of the &lt;code&gt;name&lt;/code&gt;/&lt;code&gt;protocol&lt;/code&gt; pair. This is conceptually simple but I am not familiar enough with Kubernetes internals to judge the feasibility or technical tradeoffs of this approach. For users, nothing changes (except the example above would work!)&lt;/p&gt;
&lt;p&gt;Another approach is to add a new ServicePort field to specify the actual DNS service label to use. For the sake of discussion I’ll call it &lt;code&gt;serviceName&lt;/code&gt;. It would be optional, defaulting to the value of &lt;code&gt;name&lt;/code&gt;. This means &lt;code&gt;name&lt;/code&gt; can still be the “primary key”, but the approach requires &lt;em&gt;another&lt;/em&gt; uniqueness check on the &lt;code&gt;serviceName&lt;/code&gt;/&lt;code&gt;protocol&lt;/code&gt; pair. In our use case the configuration would look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...
ports:
- name: ldap
  protocol: TCP
  port: 389
- name: kerberos-tcp
  serviceName: kerberos
  protocol: TCP
  port: 88
- name: kerberos-udp
  serviceName: kerberos
  protocol: UDP
  port: 88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From a UX perspective I prefer the first approach, because there are no changes or additions to the ServicePort configuration schema. But to maintain compatibility with programs that assume that &lt;code&gt;name&lt;/code&gt; is unique (as is currently enforced), it might be necessary to introduce a new field.&lt;/p&gt;
&lt;h2 id=&quot;next-steps&quot;&gt;Next steps &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml#next-steps&quot; class=&quot;section&quot;&gt;§&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I &lt;a href=&quot;https://github.com/kubernetes/kubernetes/issues/97149&quot;&gt;filed a bug report&lt;/a&gt; and submitted a &lt;a href=&quot;https://frasertweedale.github.io/blog-redhat/atom.xml&quot;&gt;proof-of-concept pull request&lt;/a&gt; to bring attention to the problem and solicit feedback from Kubernetes and OpenShift DNS experts. It might be necessary to submit a &lt;a href=&quot;https://github.com/kubernetes/enhancements/blob/master/keps/README.md&quot;&gt;Kubernetes Enhancement Proposal&lt;/a&gt; (KEP), but that seems (as a Kubernetes outsider) a long and windy road to landing what is a conceptually small change.&lt;/p&gt;</description>
	<pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Adam Young: Dealing with reused Serial Numbers for CAs</title>
	<guid>http://adam.younglogic.com/?p=6968</guid>
	<link>http://adam.younglogic.com/2020/08/dealing-with-reused-serial-numbers-for-cas/</link>
	<description>&lt;p&gt;&amp;#8220;An error occurred during a connection to nuzleaf.home.younglogic.net. You are attempting to import a cert with the same issuer/serial as an existing cert, but that is not the same cert.&amp;#8221;&lt;/p&gt;



&lt;p&gt;Many years ago I battled this problem and had different solutions.  Today, I got one that worked for Firefox on Fedora 32.&lt;/p&gt;



&lt;span id=&quot;more-6968&quot;&gt;&lt;/span&gt;



&lt;p&gt;My IPA server is for HOME.YOUNGLOGIC.NET&lt;/p&gt;



&lt;p&gt;My backing store for my default profile in firefox is /home/ayoung/.mozilla/firefox/x4kktanr.default&lt;/p&gt;



&lt;p&gt;To see the certificates I have in that store:&lt;/p&gt;



&lt;pre lang=&quot;bash&quot;&gt;
$ pwd
/home/ayoung/.mozilla/firefox/x4kktanr.default
$ certutil -L -d . | grep -i younglogic
adam.younglogic.com                                          ,,   
younglogic.com                                               ,,   
openshift.younglogic.info                                    ,,   
nuzleaf.home.younglogic.net                                  ,,   
Certificate Authority - HOME.YOUNGLOGIC.NET                  CT,C,
&lt;/pre&gt;



&lt;p&gt;To delete that last one:&lt;/p&gt;



&lt;pre lang=&quot;bash&quot;&gt;
certutil  -d . -D -n &quot;Certificate Authority - HOME.YOUNGLOGIC.NET
&lt;/pre&gt;



&lt;p&gt;Then restart Firefox.  It holds this in some other cache, perhaps memory, until a restart.  Note that the file that backs the certificate database is: cert9.db.  It is a SQLite database with a very unfriendly schema.&lt;/p&gt;



&lt;p&gt;&lt;/p&gt;</description>
	<pubDate>Thu, 27 Aug 2020 18:03:51 +0000</pubDate>
</item>
<item>
	<title>Adam Young: Talking to FreeIPA with python-requests</title>
	<guid>http://adam.younglogic.com/?p=6911</guid>
	<link>http://adam.younglogic.com/2020/08/talking-to-freeipa-with-python-requests/</link>
	<description>&lt;p&gt;The code that &lt;a href=&quot;http:// https://adam.younglogic.com/2010/07/talking-to-freeipa-json-web-api-via-curl/&quot;&gt;Rich M gave me a while back has bit rotted&lt;/a&gt;.  At some point, I need to get an updated version, but until then, I can continue to talk to the FreeIPA server using Python and the Requests library.  In the future, I can get a session cookie, but for now, python3-request-gssapi  will work to authenticate me, provided I have a valid TGT.&lt;/p&gt;



&lt;p&gt;I pulled the requests-gssapi library from Koji, as it does not currently ship in any of the RHEL8 repos.  Here is the one I installed.&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;https://koji.fedoraproject.org/koji/buildinfo?buildID=1371255&quot;&gt;https://koji.fedoraproject.org/koji/buildinfo?buildID=1371255&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Note that this quick-and-dirty code runs on the IPA server itself.  A better approach would be to read the Server name out of /etc/ipa/default.conf. &lt;br /&gt;&lt;/p&gt;



&lt;pre lang=&quot;python&quot;&gt;
#!/bin/python3
import requests
from requests_gssapi import HTTPSPNEGOAuth
import socket
hostname = socket.gethostname()
url = &quot;https://%s/ipa/json&quot; % hostname
referer =  &quot;https://%s/ipa&quot; % hostname
body = {&quot;method&quot;:&quot;user_find&quot;,&quot;params&quot;:[[&quot;&quot;],{}],&quot;id&quot;:0}

r = requests.post(url,
                  json = body,
                  auth=HTTPSPNEGOAuth(),
                  headers = {
                    'Content-Type': 'application/json',
                    'Accept': 'applicaton/json',
                    'referer': referer})
print(r.status_code)
if r.status_code  == 200:
    print(r.text)
&lt;/pre&gt;



&lt;p&gt;&lt;/p&gt;</description>
	<pubDate>Thu, 06 Aug 2020 23:09:43 +0000</pubDate>
</item>
<item>
	<title>Nathaniel McCallum: Do Not Use ring (or rustls)</title>
	<guid>https://npmccallum.gitlab.io/post/do-not-use-ring-or-rustls/</guid>
	<link>https://npmccallum.gitlab.io/post/do-not-use-ring-or-rustls/</link>
	<description>&lt;p&gt;Rust is a fantastic systems language. And without a runtime, it is an exciting
new language for cryptography. Further, mapping existing cryptographic
libraries, such as &lt;a href=&quot;https://github.com/sfackler/rust-openssl&quot;&gt;openssl&lt;/a&gt; and &lt;a href=&quot;https://github.com/fortanix/rust-mbedtls&quot;&gt;mbedtls&lt;/a&gt;, into the Rust landscape requires a
variety of trade-offs that would not have to be made if we had native Rust
cryptography. All of this makes the desire for a native Rust crypto library
very high.&lt;/p&gt;

&lt;p&gt;Enter &lt;a href=&quot;https://github.com/briansmith/ring&quot;&gt;ring&lt;/a&gt;. The ring project has all appearances of a serious native Rust
cryptography project. It has thousands of commits over multiple years. It has a
robust test framework. What could go wrong?&lt;/p&gt;

&lt;h3 id=&quot;the-ring-project-is-now-holding-pull-request-reviews-for-ransom&quot;&gt;The ring project is now holding pull request reviews for ransom.&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m not joking. If you file a pull request, you will be &lt;a href=&quot;https://github.com/briansmith/ring/pull/883#issuecomment-517502600&quot;&gt;asked for money&lt;/a&gt;.
And it isn&amp;rsquo;t the &lt;a href=&quot;https://github.com/briansmith/ring/pull/738#issuecomment-495374980&quot;&gt;first time&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Might I also mention that ring&amp;rsquo;s implementation doesn&amp;rsquo;t use blinding during RSA
signing? Nor have they merged the latest attack mitigations for &lt;code&gt;pkcs1_encode()&lt;/code&gt;
from BoringSSL. It is easy to be fast when you&amp;rsquo;re insecure.&lt;/p&gt;

&lt;p&gt;Then there&amp;rsquo;s the fact that they don&amp;rsquo;t do security embargoes. All disclosures
are zero days. Never mind the fact that GitHub gives the ability to do all this
sanely.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m willing to work around (and patch) some of these issues. But if I can&amp;rsquo;t
contribute without a shakedown, what&amp;rsquo;s the point?&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t use ring.&lt;/p&gt;

&lt;p&gt;Unfortunately, this means that &lt;a href=&quot;https://github.com/ctz/rustls&quot;&gt;rustls&lt;/a&gt; is now stuck. They are built on top of
ring and are widely used in the Rust community. So I can&amp;rsquo;t recommend rustls
until ring fixes its problems.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t use rustls.&lt;/p&gt;</description>
	<pubDate>Fri, 02 Aug 2019 13:38:40 +0000</pubDate>
</item>
<item>
	<title>Nathaniel McCallum: Foreign-Architecture Docker</title>
	<guid>https://npmccallum.gitlab.io/post/foreign-architecture-docker/</guid>
	<link>https://npmccallum.gitlab.io/post/foreign-architecture-docker/</link>
	<description>&lt;p&gt;Sometimes you need to run a Docker image for a CPU architecture you
don&amp;rsquo;t own.  The &lt;a href=&quot;https://hub.docker.com/u/multiarch/&quot;&gt;multiarch&lt;/a&gt; project
has attempted to do this in the past. But the approach they have taken
requires you to run modified images. This is a lot of maintenance
overhead. And it means the images are perpetually out of date.&lt;/p&gt;

&lt;p&gt;Enter &lt;code&gt;npmccallum/qemu-register&lt;/code&gt;. This Docker image enables the host to
run &lt;strong&gt;unmodified&lt;/strong&gt; foreign-architecture Docker images. Want an example?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ sudo docker run --rm --privileged npmccallum/qemu-register
$ sudo docker run --rm aarch64/busybox uname -m
aarch64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yup! That&amp;rsquo;s it!&lt;/p&gt;

&lt;h3 id=&quot;requirements&quot;&gt;Requirements&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The host must be running Linux 4.8 or later.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-it-works&quot;&gt;How it Works&lt;/h3&gt;

&lt;p&gt;Linux 4.8 added the &lt;code&gt;F&lt;/code&gt; flag to &lt;code&gt;binfmt_misc&lt;/code&gt;. This flag causes the
kernel to load the interpreter for the binary as soon as the
configuration is loaded rather than lazily on program execution.&lt;/p&gt;

&lt;p&gt;This configuration really helps with containers because it means the
interpreter from one container can be used in another container. For
example, when you load an &lt;code&gt;aarch64&lt;/code&gt; binary from the &lt;code&gt;aarch64/busybox&lt;/code&gt;
Docker image above, the &lt;code&gt;qemu-user-aarch64&lt;/code&gt; emulation binary is used
from the &lt;code&gt;npmccallum/qemu-register&lt;/code&gt; Docker image. Therefore,
foreign-architecture images can run unmodified with this strategy.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;npmccallum/qemu-register&lt;/code&gt; Docker image is built with Fedora since
they are the only major distro that has chosen this configuration by
default.&lt;/p&gt;

&lt;h3 id=&quot;security-implications&quot;&gt;Security Implications&lt;/h3&gt;

&lt;p&gt;Any &lt;code&gt;qemu&lt;/code&gt; vulnerabilities in &lt;code&gt;npmccallum/qemu-register&lt;/code&gt; may impact your
application. This could result in an escalation of privileges. But
containers don&amp;rsquo;t contain anyway. You probably don&amp;rsquo;t need to be scared if
you aren&amp;rsquo;t using this for public-facing services.&lt;/p&gt;</description>
	<pubDate>Mon, 29 Jul 2019 18:39:50 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: Lost in (Kerberos) service translation?</title>
	<guid>https://vda.li/en/posts/2019/03/24/Kerberos-host-to-realm-translation/</guid>
	<link>https://vda.li/en/posts/2019/03/24/Kerberos-host-to-realm-translation/</link>
	<description>&lt;p&gt;A year ago Brian J. Atkisson from Red Hat IT filed &lt;a href=&quot;https://bugzilla.redhat.com/show_bug.cgi?id=1561584&quot;&gt;a bug&lt;/a&gt; against FreeIPA asking to remove a default &lt;code&gt;[domain_realm]&lt;/code&gt; mapping section from the &lt;code&gt;krb5.conf&lt;/code&gt; configuration file generated during installation of a FreeIPA client. The bug is still open and I’d like to use this opportunity to discuss some less known aspects of a Kerberos service principal resolution.&lt;/p&gt;

&lt;p&gt;When an application uses Kerberos to authenticate to a remote service, it needs to talk to a Kerberos key distribution center (KDC) to obtain a service ticket to that remote service. There are multiple ways how an application could construct a name of a service but in a simplistic view it boils down to getting a remote service host name and attaching it to a remote service type name. Type names are customary and really depend on an established tradition for a protocol in use. For example, browsers universally assume that a component &lt;code&gt;HTTP/&lt;/code&gt; is used in the service name; to authenticate to &lt;code&gt;www.example.com&lt;/code&gt; server they would ask a KDC a service ticket to &lt;code&gt;HTTP/www.example.com&lt;/code&gt; principal. When an LDAP client talks to an LDAP server &lt;code&gt;ldap.example.com&lt;/code&gt; and uses SASL GSSAPI authentication, it will ask KDC for a service ticket to &lt;code&gt;ldap/ldap.example.com&lt;/code&gt;. Sometimes these assumptions are written down in a corresponding RFC document, sometimes not, but they assume both client and server know what they are doing.&lt;/p&gt;

&lt;p&gt;There are, however, few more moving parts at play. A host name part of a service principal might come from an interaction with a user. For browser, this would be a server name from a URL entered by a user and browser would need to construct the target service principal from it. The host name part might be incomplete in some cases: if you only have a single DNS domain in use, server names would be unique in that domain and your users might find it handy to only use the first label of a DNS name of the server to address it. Such approach was certainly very popular among system administrators who relied on capabilities of a Kerberos library to expand the short name into a fully qualified one.&lt;/p&gt;

&lt;p&gt;Let’s look into that. Kerberos configuration file, &lt;code&gt;krb5.conf&lt;/code&gt;, allows to say for any application that a hostname passed down to the library would need to be canonicalized. This option, &lt;code&gt;dns_canonicalize_hostname&lt;/code&gt;, allows us to say “I want to connect to a server &lt;code&gt;bastion&lt;/code&gt;” and let libkrb5 to expand that one to a &lt;code&gt;bastion.example.com&lt;/code&gt; host name. While this behavior is handy, it relies on DNS. A downside of disabling canonicalization of the hostnames is that short hostnames will not be canonicalized and upon requests to KDC might be not recognized. Finally, there is a possibility of DNS hijacking. For Kerberos, use cases when DNS responses are spoofed aren’t too problematic since the fake KDC or the fake service wouldn’t gain much knowledge, but even in a normal situation a latency of DNS responses might be a considerable problem.&lt;/p&gt;

&lt;p&gt;Another part of the equation is to find out which Kerberos realm a specified target service principal belongs to. If you have a single Kerberos realm, it might not be an issue; by setting &lt;code&gt;default_realm&lt;/code&gt; option in the &lt;code&gt;krb5.conf&lt;/code&gt; we can make sure a client always assumes the only realm we have. However, if there are multiple Kerberos realms, it is important to map the target service principal to the target realm at a client side, before a request is issued to a KDC.&lt;/p&gt;

&lt;p&gt;There might be multiple Kerberos realms in existence at any site. For example, FreeIPA deployment provides one. If FreeIPA has established a trust to an Active Directory forest, then that forest would represent another Kerberos realm. Potentially, even more than one as each Active Directory domain in an Active Directory forest is a separate Kerberos realm in itself.&lt;/p&gt;

&lt;p&gt;Kerberos protocol defines that a realm in which the application server is located must be determined by the client (&lt;a href=&quot;https://tools.ietf.org/html/rfc4120#section-3.3.1&quot;&gt;RFC 4120 section 3.3.1&lt;/a&gt;). The specification also defines several strategies how a client may map the hostname of the application server to the realm it believes the server belongs to.&lt;/p&gt;

&lt;h2 id=&quot;domain-to-realm-mapping&quot;&gt;Domain to realm mapping&lt;/h2&gt;

&lt;p&gt;Let us stop and think a bit at this point. A Kerberos client has full control over the decision process of to which realm a particular application server belongs to. If it decides that the application server is from a different realm than the client is itself, then it needs to ask for a cross-realm ticket granting ticket from its own KDC. Then, with the cross-realm TGT in possession, the client can ask a KDC of the application server’s realm for the actual service ticket.&lt;/p&gt;

&lt;p&gt;As a client, we want to be sure we would be talking to the correct KDC. As mentioned earlier, overly relying on DNS is not always a particulary secure action. As a result, &lt;code&gt;krb5&lt;/code&gt; library provides a way to consider how a particular hostname is mapped to a realm. The search mechanism for a realm mapping is pluggable and by default includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;registry-based search on WIN32 (does nothing for Linux)&lt;/li&gt;
  &lt;li&gt;profile-based search: uses &lt;code&gt;[domain_realm]&lt;/code&gt; section in &lt;code&gt;krb5.conf&lt;/code&gt; to do actual mapping&lt;/li&gt;
  &lt;li&gt;dns-based search that can be disabled with &lt;code&gt;dns_lookup_realm = false&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;domain-based search: it is disabled by default and can be enabled with
&lt;code&gt;realm_try_domains = ...&lt;/code&gt; option in &lt;code&gt;krb5.conf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The order of search is important. It is hard-coded in &lt;code&gt;krb5&lt;/code&gt; library and depends on what operation is performed. For realm selection it is hard-coded that profile-based search is done before DNS-based search and domain-based
search is done as the last one.&lt;/p&gt;

&lt;h3 id=&quot;profile-based-search&quot;&gt;Profile-based search&lt;/h3&gt;

&lt;p&gt;When &lt;code&gt;[domain_realm]&lt;/code&gt; section exists in &lt;code&gt;krb5.conf&lt;/code&gt;, it will be used to map a hostname of the application server to a realm. The mapping table in this section is typically build up based on the host and domain maps:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[domain_realm]
   www.example.com = EXAMPLE.COM
   .dev.example.com = DEVEXAMPLE.COM
   .example.com = EXAMPLE.COM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The mapping above says that &lt;code&gt;www.example.com&lt;/code&gt; would be explicitly mapped to &lt;code&gt;EXAMPLE.COM&lt;/code&gt; realm, all machines in DNS zone &lt;code&gt;dev.example.com&lt;/code&gt; would be mapped to &lt;code&gt;DEVEXAMPLE.COM&lt;/code&gt; realm and the rest of hosts in DNS zone &lt;code&gt;example.com&lt;/code&gt; would be mapped to &lt;code&gt;EXAMPLE.COM&lt;/code&gt;. This mapping only applies to hostnames, so a hostname &lt;code&gt;foo.bar.example.com&lt;/code&gt; would not be mapped by this schema to any realm.&lt;/p&gt;

&lt;p&gt;Profile-based search is visible in the Kerberos trace output as a selection of the realm right at the beginning of a request for a service ticket to a host-based service principal:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@client ~]# kinit -k
[root@client ~]# KRB5_TRACE=/dev/stderr kvno -S cifs client.example.com
[30798] 1552847822.721561: Getting credentials host/client.example.com@EXAMPLE.COM -&amp;gt; cifs/client.example.com@EXAMPLE.COM using ccache KEYRING:persistent:0:0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The difference here is that for a service principal not mapped with profile-based search there will be no assumed realm and the target principal would be constructed without a realm:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@client ~]# kinit -k
[root@client ~]# KRB5_TRACE=/dev/stderr kvno -S ldap dc.ad.example.com
[30684] 1552841274.602324: Getting credentials host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@ using ccache KEYRING:persistent:0:0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;dns-based-search&quot;&gt;DNS-based search&lt;/h3&gt;

&lt;p&gt;DNS-based search is activated when &lt;code&gt;dns_lookup_realm&lt;/code&gt; option is set to &lt;code&gt;true&lt;/code&gt; in &lt;code&gt;krb5.conf&lt;/code&gt; and profile-based search did not return any results. Kerberos library will do a number of DNS queries for a TXT record starting with &lt;code&gt;_kerberos&lt;/code&gt;. It will help it to discover which Kerberos realm is responsible for the DNS host of the application server. Kerberos library will perform these searches for the hostname itself first and then for each domain component in the hostname until it finds an answer or processes all domain components.&lt;/p&gt;

&lt;p&gt;If we have &lt;code&gt;www.example.com&lt;/code&gt; as a hostname, then Kerberos library would issue a DNS query for TXT record &lt;code&gt;_kerberos.www.example.com&lt;/code&gt; to find a name of the Kerberos realm of &lt;code&gt;www.example.com&lt;/code&gt;. If that fails, next try will be for a TXT record &lt;code&gt;_kerberos.example.com&lt;/code&gt; and so on, until DNS components are all processed.&lt;/p&gt;

&lt;p&gt;It should be noted that this algorithm is only implemented in MIT and Heimdal Kerberos libraries. Active Directory implementation from Microsoft does not allow to query &lt;code&gt;_kerberos.$hostname&lt;/code&gt; DNS TXT record to find out which realm a target application server belongs to. Instead, Windows environments delegate the discovery process to their domain controllers.&lt;/p&gt;

&lt;p&gt;DNS canonicalization feature (or lack of) also affects DNS search since without it we wouldn’t know what realm to map to a non-fully qualified hostname. When &lt;code&gt;dns_canonicalize_hostname&lt;/code&gt; option is set to &lt;code&gt;false&lt;/code&gt;, Kerberos client would send the request to KDC with a default realm associated with the non-fully qualified hostname. Most likely such service principal wouldn’t be understood by the KDC and reported as not found.&lt;/p&gt;

&lt;p&gt;To help in this situations, FreeIPA KDC supports Kerberos principal aliases. One can use the following &lt;code&gt;ipa&lt;/code&gt; command line tool’s command to add aliases to hosts. Remember that a host principal is really a &lt;code&gt;host/&amp;lt;hostname&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ipa help host-add-principal
Usage: ipa [global-options] host-add-principal HOSTNAME KRBPRINCIPALNAME... [options]

Add new principal alias to host entry
Options:
  -h, --help    show this help message and exit
  --all         Retrieve and print all attributes from the server. Affects
                command output.
  --raw         Print entries as stored on the server. Only affects output
                format.
  --no-members  Suppress processing of membership attributes.

$ ipa host-add-principal bastion.example.com host/bastion
-------------------------------------------
Added new aliases to host &quot;bastion.example.com&quot;
-------------------------------------------
  Host name: bastion.example.com
  Principal alias: host/bastion.example.com@EXAMPLE.COM, host/bastion@EXAMPLE.COM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and for other Kerberos service principals the corresponding command is &lt;code&gt;ipa service-add-principal&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ipa help service-add-principal
Usage: ipa [global-options] service-add-principal CANONICAL-PRINCIPAL PRINCIPAL... [options]

Add new principal alias to a service
Options:
  -h, --help    show this help message and exit
  --all         Retrieve and print all attributes from the server. Affects
                command output.
  --raw         Print entries as stored on the server. Only affects output
                format.
  --no-members  Suppress processing of membership attributes.

$ ipa service-show HTTP/bastion.example.com
  Principal name: HTTP/bastion.example.com@EXAMPLE.COM
  Principal alias: HTTP/bastion.example.com@EXAMPLE.COM
  Keytab: False
  Managed by: bastion.example.com
  Groups allowed to create keytab: admins
[root@nyx ~]# ipa service-add-principal HTTP/bastion.example.com HTTP/bastion
---------------------------------------------------------------------------------
Added new aliases to the service principal &quot;HTTP/bastion.example.com@EXAMPLE.COM&quot;
---------------------------------------------------------------------------------
  Principal name: HTTP/bastion.example.com@EXAMPLE.COM
  Principal alias: HTTP/bastion.example.com@EXAMPLE.COM, HTTP/bastion@EXAMPLE.COM

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;domain-based-search&quot;&gt;Domain-based search&lt;/h3&gt;

&lt;p&gt;Finally, domain-based search is activated when &lt;code&gt;realm_try_domains = ...&lt;/code&gt; is specified. In this case Kerberos library will try heuristics based on the hostname of the target application server and a specific number of domain components of the application server hostname depending on how many components &lt;code&gt;realm_try_domains&lt;/code&gt; option is allowing to cut off. More about that later.&lt;/p&gt;

&lt;h3 id=&quot;kdc-based-hostname-search&quot;&gt;KDC-based hostname search&lt;/h3&gt;

&lt;p&gt;However, there is another option employed by MIT Kerberos library. In case when MIT Kerberos client is unable to find out a realm on its own, starting with MIT krb5 1.6 version, a client will issue a request for without a known realm to own KDC. A KDC (must be MIT krb5 1.7 or later) can opt to recognize the hostname against own &lt;code&gt;[domain_realm]&lt;/code&gt; mapping table and choose to issue a referral to the appropriate service realm.&lt;/p&gt;

&lt;p&gt;The latter approach would only work if the KDC has been configured to allow such referrals to be issued and if client is asking for a host-based service. FreeIPA KDC, by default, allows this behavior. For trusted Active Directory realms there is also a support from SSSD on IPA masters: SSSD generates automatically &lt;code&gt;[domain_realm]&lt;/code&gt; and &lt;code&gt;[capaths]&lt;/code&gt; sections for all known trusted realms so that KDC is able to respond with the referrals.&lt;/p&gt;

&lt;p&gt;However, a care should be taken by an application itself on the client side when constructing such Kerberos principal. For example, if we would use &lt;code&gt;kvno&lt;/code&gt; utility, then a request &lt;code&gt;kvno -S service hostname&lt;/code&gt; would ask for a referral while &lt;code&gt;kvno service/hostname&lt;/code&gt; would not. The former is constructing a host-based principal while the latter is not.&lt;/p&gt;

&lt;p&gt;When looking at the Kerberos trace, we can see the difference. Below &lt;code&gt;host/client.example.com&lt;/code&gt; is asking for a service ticket to &lt;code&gt;ldap/dc.ad.example.com&lt;/code&gt; as a host-based principal, without knowing which realm the application server’s principal belongs to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@client ~]# kinit -k
[root@client ~]# KRB5_TRACE=/dev/stderr kvno -S ldap dc.ad.example.com
[30684] 1552841274.602324: Getting credentials host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@ using ccache KEYRING:persistent:0:0
[30684] 1552841274.602325: Retrieving host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@ from KEYRING:persistent:0:0 with result: -1765328243/Matching credential not found
[30684] 1552841274.602326: Retrying host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@EXAMPLE.COM with result: -1765328243/Matching credential not found
[30684] 1552841274.602327: Server has referral realm; starting with ldap/dc.ad.example.com@EXAMPLE.COM
[30684] 1552841274.602328: Retrieving host/client.example.com@EXAMPLE.COM -&amp;gt; krbtgt/EXAMPLE.COM@EXAMPLE.COM from KEYRING:persistent:0:0 with result: 0/Success
[30684] 1552841274.602329: Starting with TGT for client realm: host/client.example.com@EXAMPLE.COM -&amp;gt; krbtgt/EXAMPLE.COM@EXAMPLE.COM
[30684] 1552841274.602330: Requesting tickets for ldap/dc.ad.example.com@EXAMPLE.COM, referrals on
[30684] 1552841274.602331: Generated subkey for TGS request: aes256-cts/A93C
[30684] 1552841274.602332: etypes requested in TGS request: aes256-cts, aes128-cts, aes256-sha2, aes128-sha2, des3-cbc-sha1, rc4-hmac, camellia128-cts, camellia256-cts
[30684] 1552841274.602334: Encoding request body and padata into FAST request
[30684] 1552841274.602335: Sending request (965 bytes) to EXAMPLE.COM
[30684] 1552841274.602336: Initiating TCP connection to stream ip.ad.dr.ess:88
[30684] 1552841274.602337: Sending TCP request to stream ip.ad.dr.ess:88
[30684] 1552841274.602338: Received answer (856 bytes) from stream ip.ad.dr.ess:88
[30684] 1552841274.602339: Terminating TCP connection to stream ip.ad.dr.ess:88
[30684] 1552841274.602340: Response was from master KDC
[30684] 1552841274.602341: Decoding FAST response
[30684] 1552841274.602342: FAST reply key: aes256-cts/D1E2
[30684] 1552841274.602343: Reply server krbtgt/AD.EXAMPLE.COM@EXAMPLE.COM differs from requested ldap/dc.ad.example.com@EXAMPLE.COM
[30684] 1552841274.602344: TGS reply is for host/client.example.com@EXAMPLE.COM -&amp;gt; krbtgt/AD.EXAMPLE.COM@EXAMPLE.COM with session key aes256-cts/470F
[30684] 1552841274.602345: TGS request result: 0/Success
[30684] 1552841274.602346: Following referral TGT krbtgt/AD.EXAMPLE.COM@EXAMPLE.COM
[30684] 1552841274.602347: Requesting tickets for ldap/dc.ad.example.com@AD.EXAMPLE.COM, referrals on
[30684] 1552841274.602348: Generated subkey for TGS request: aes256-cts/F0C6
[30684] 1552841274.602349: etypes requested in TGS request: aes256-cts, aes128-cts, aes256-sha2, aes128-sha2, des3-cbc-sha1, rc4-hmac, camellia128-cts, camellia256-cts
[30684] 1552841274.602351: Encoding request body and padata into FAST request
[30684] 1552841274.602352: Sending request (921 bytes) to AD.EXAMPLE.COM
[30684] 1552841274.602353: Sending DNS URI query for _kerberos.AD.EXAMPLE.COM.
[30684] 1552841274.602354: No URI records found
[30684] 1552841274.602355: Sending DNS SRV query for _kerberos._udp.AD.EXAMPLE.COM.
[30684] 1552841274.602356: SRV answer: 0 0 88 &quot;dc.ad.example.com.&quot;
[30684] 1552841274.602357: Sending DNS SRV query for _kerberos._tcp.AD.EXAMPLE.COM.
[30684] 1552841274.602358: SRV answer: 0 0 88 &quot;dc.ad.example.com.&quot;
[30684] 1552841274.602359: Resolving hostname dc.ad.example.com.
[30684] 1552841274.602360: Resolving hostname dc.ad.example.com.
[30684] 1552841274.602361: Initiating TCP connection to stream ano.ther.add.ress:88
[30684] 1552841274.602362: Sending TCP request to stream ano.ther.add.ress:88
[30684] 1552841274.602363: Received answer (888 bytes) from stream ano.ther.add.ress:88
[30684] 1552841274.602364: Terminating TCP connection to stream ano.ther.add.ress:88
[30684] 1552841274.602365: Sending DNS URI query for _kerberos.AD.EXAMPLE.COM.
[30684] 1552841274.602366: No URI records found
[30684] 1552841274.602367: Sending DNS SRV query for _kerberos-master._tcp.AD.EXAMPLE.COM.
[30684] 1552841274.602368: No SRV records found
[30684] 1552841274.602369: Response was not from master KDC
[30684] 1552841274.602370: Decoding FAST response
[30684] 1552841274.602371: FAST reply key: aes256-cts/10DE
[30684] 1552841274.602372: TGS reply is for host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@AD.EXAMPLE.COM with session key aes256-cts/24D1
[30684] 1552841274.602373: TGS request result: 0/Success
[30684] 1552841274.602374: Received creds for desired service ldap/dc.ad.example.com@AD.EXAMPLE.COM
[30684] 1552841274.602375: Storing host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@ in KEYRING:persistent:0:0
[30684] 1552841274.602376: Also storing host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@AD.EXAMPLE.COM based on ticket
[30684] 1552841274.602377: Removing host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@AD.EXAMPLE.COM from KEYRING:persistent:0:0
ldap/dc.ad.example.com@: kvno = 28
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, when not using a host-based principal in the request we’ll fail.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@client ~]# kinit -k
[root@client ~]# KRB5_TRACE=/dev/stderr kvno ldap/dc.ad.example.com
[30695] 1552841932.100975: Getting credentials host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@EXAMPLE.COM using ccache KEYRING:persistent:0:0
[30695] 1552841932.100976: Retrieving host/client.example.com@EXAMPLE.COM -&amp;gt; ldap/dc.ad.example.com@EXAMPLE.COM from KEYRING:persistent:0:0 with result: -1765328243/Matching credential not found
[30695] 1552841932.100977: Retrieving host/client.example.com@EXAMPLE.COM -&amp;gt; krbtgt/EXAMPLE.COM@EXAMPLE.COM from KEYRING:persistent:0:0 with result: 0/Success
[30695] 1552841932.100978: Starting with TGT for client realm: host/client.example.com@EXAMPLE.COM -&amp;gt; krbtgt/EXAMPLE.COM@EXAMPLE.COM
[30695] 1552841932.100979: Requesting tickets for ldap/dc.ad.example.com@EXAMPLE.COM, referrals on
[30695] 1552841932.100980: Generated subkey for TGS request: aes256-cts/27DA
[30695] 1552841932.100981: etypes requested in TGS request: aes256-cts, aes128-cts, aes256-sha2, aes128-sha2, des3-cbc-sha1, rc4-hmac, camellia128-cts, camellia256-cts
[30695] 1552841932.100983: Encoding request body and padata into FAST request
[30695] 1552841932.100984: Sending request (965 bytes) to EXAMPLE.COM
[30695] 1552841932.100985: Initiating TCP connection to stream ip.ad.dr.ess:88
[30695] 1552841932.100986: Sending TCP request to stream ip.ad.dr.ess:88
[30695] 1552841932.100987: Received answer (461 bytes) from stream ip.ad.dr.ess:88
[30695] 1552841932.100988: Terminating TCP connection to stream ip.ad.dr.ess:88
[30695] 1552841932.100989: Response was from master KDC
[30695] 1552841932.100990: Decoding FAST response
[30695] 1552841932.100991: TGS request result: -1765328377/Server ldap/dc.ad.example.com@EXAMPLE.COM not found in Kerberos database
[30695] 1552841932.100992: Requesting tickets for ldap/dc.ad.example.com@EXAMPLE.COM, referrals off
[30695] 1552841932.100993: Generated subkey for TGS request: aes256-cts/C1BF
[30695] 1552841932.100994: etypes requested in TGS request: aes256-cts, aes128-cts, aes256-sha2, aes128-sha2, des3-cbc-sha1, rc4-hmac, camellia128-cts, camellia256-cts
[30695] 1552841932.100996: Encoding request body and padata into FAST request
[30695] 1552841932.100997: Sending request (965 bytes) to EXAMPLE.COM
[30695] 1552841932.100998: Initiating TCP connection to stream ip.ad.dr.ess:88
[30695] 1552841932.100999: Sending TCP request to stream ip.ad.dr.ess:88
[30695] 1552841932.101000: Received answer (461 bytes) from stream ip.ad.dr.ess:88
[30695] 1552841932.101001: Terminating TCP connection to stream ip.ad.dr.ess:88
[30695] 1552841932.101002: Response was from master KDC
[30695] 1552841932.101003: Decoding FAST response
[30695] 1552841932.101004: TGS request result: -1765328377/Server ldap/dc.ad.example.com@EXAMPLE.COM not found in Kerberos database
kvno: Server ldap/dc.ad.example.com@EXAMPLE.COM not found in Kerberos database while getting credentials for ldap/dc.ad.example.com@EXAMPLE.COM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, our client tried to ask for a service ticket to a non-host-based service principal from outside our realm and this was not accepted by the KDC, thus resolution failing.&lt;/p&gt;

&lt;h2 id=&quot;mixed-realm-deployments&quot;&gt;Mixed realm deployments&lt;/h2&gt;

&lt;p&gt;The behavior above is predictable. However, a client-side processing of the target realm behaves wrongly in case a client needs to request a service ticket to a service principal located in a trusted realm but situated in a DNS zone belonging to our own realm. This might sound like a complication but it is a typical situation for deployments with FreeIPA trusting Active Directory forests. In such cases customers often want to place Linux machines right in the DNS zones associated with Active Directory domains.&lt;/p&gt;

&lt;p&gt;Since Microsoft Active Directory implementation does not support per-host Kerberos realm hint, unlike MIT Kerberos or Heimdal, such request from Windows client will always fail. It will be not possible to obtain a service ticket in such situation from Windows machines.&lt;/p&gt;

&lt;p&gt;However, when both realms trusting each other are MIT Kerberos, their KDCs and clients can be configured for a selective realm discovery.&lt;/p&gt;

&lt;p&gt;As explained at &lt;a href=&quot;https://archive.fosdem.org/2018/schedule/event/opensource_idm_in_enterprise/&quot;&gt;FOSDEM 2018&lt;/a&gt; and &lt;a href=&quot;https://devconfcz2019.sched.com/event/JcfK/migrating-a-linux-environment-to-idm&quot;&gt;devconf.cz 2019&lt;/a&gt;, Red Hat IT moved from an old plain Kerberos realm to the FreeIPA deployment.
This is a situation where we have EXAMPLE.COM and IPA.EXAMPLE.COM both trusting each other and migrating systems to IPA.EXAMPLE.COM over long period of time. We want to continue providing services in example.com DNS zone but use IPA.EXAMPLE.COM realm. Our clients are in both Kerberos realms but over time they will all eventually migrate to IPA.EXAMPLE.COM.&lt;/p&gt;

&lt;p&gt;Working with such situation can be tricky. Let’s start with a simple example.&lt;/p&gt;

&lt;p&gt;Suppose our client’s &lt;code&gt;krb5.conf&lt;/code&gt; has &lt;code&gt;[domain_realm]&lt;/code&gt; section that looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[domain_realm]
   client.example.com = EXAMPLE.COM
   .example.com = EXAMPLE.COM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we need to ask for a &lt;code&gt;HTTP/app.example.com&lt;/code&gt; service ticket to the application server hosted on &lt;code&gt;app.example.com&lt;/code&gt;, the Kerberos library on the client will map &lt;code&gt;HTTP/app.example.com&lt;/code&gt; to the &lt;code&gt;EXAMPLE.COM&lt;/code&gt; and will not attempt to request a referral from a KDC. If our application server is enrolled into &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt; realm, it means the client with such configuration will never try to discover &lt;code&gt;HTTP/app.example.com@IPA.EXAMPLE.COM&lt;/code&gt; and will never be able to authenticate to &lt;code&gt;app.example.com&lt;/code&gt; with Kerberos.&lt;/p&gt;

&lt;p&gt;There are two possible solutions here. We can either add an explicit mapping for &lt;code&gt;app.example.com&lt;/code&gt; host to &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt; in the client’s &lt;code&gt;[domain_realm]&lt;/code&gt; section in &lt;code&gt;krb5.conf&lt;/code&gt; or remove &lt;code&gt;.example.com&lt;/code&gt; mapping entry from the &lt;code&gt;[domain_realm]&lt;/code&gt; on the client side completely and rely on KDC or DNS-based search.&lt;/p&gt;

&lt;p&gt;First solution does not scale and is a management issue. Updating all clients when a new application server is migrated to the new realm sounds like a nightmare if majority of your clients are laptops. You’d really want to force them to delegate to the KDC or do DNS-based search instead.&lt;/p&gt;

&lt;p&gt;Of course, there is a simple solution: add &lt;code&gt;_kerberos.app.example.com&lt;/code&gt; TXT record pointing out to &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt; in the DNS and let clients to use it. This would assume that all clients will not have &lt;code&gt;.example.com = EXAMPLE.COM&lt;/code&gt; mapping rule.&lt;/p&gt;

&lt;p&gt;Unfortunately, it is more complicated. As Robbie Harwood, Fedora and RHEL maintainer of MIT Kerberos, explained to me, the problem is what happens if there’s inadequate DNS information, e.g. DNS-based search failed. A client would fall back to heuristics (domain-based search) and these would differ depending which MIT Kerberos version is in use. Since MIT Kerberos 1.16 heuristics would be trying to prefer mapping &lt;code&gt;HTTP/app.ipa.example.com&lt;/code&gt; into &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt; over &lt;code&gt;EXAMPLE.COM&lt;/code&gt;, and prefer &lt;code&gt;EXAMPLE.COM&lt;/code&gt; to failure. However, there is no a way to map &lt;code&gt;HTTP/app.example.com&lt;/code&gt; to &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt; with these heuristics.&lt;/p&gt;

&lt;p&gt;Domain-based search gives us another heuristics based on the realm. It is tunable via &lt;code&gt;realm_try_domains&lt;/code&gt; option but it also would affect the way how MIT Kerberos library would choose which credentials cache from a credentials cache collection (KEYRING:, DIR:, KCM: ccache types). This logic is present since MIT Kerberos 1.12 but it also wouldn’t help us to map &lt;code&gt;HTTP/app.example.com&lt;/code&gt; to &lt;code&gt;IPA.EXAMPLE.COM&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;After some discussions, Robbie and I came to a conclusion that perhaps changing the order how these methods are applied by the MIT Kerberos library could help. As I mentioned in &lt;a href=&quot;https://vda.li/en/freeipa.xml#domain-to-realm-mapping&quot;&gt;“Domain to realm mapping”&lt;/a&gt; section, the current order is hard-coded: for realm selection the profile-based search is done before DNS-based search and domain-based search is done as the last one. Ideally, choosing which search is done after which could be given to administrators. However, there aren’t many reasonable orders out there. Perhaps, allowing just two options would be enough:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;prioritizing DNS search over a profile search&lt;/li&gt;
  &lt;li&gt;prioritizing a profile search over DNS search&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Until it is done, we are left with the following recommendation for mixed-domain Kerberos principals from multiple realms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;make sure you don’t use &lt;code&gt;[domain_realm]&lt;/code&gt; mapping for mixed realm domains&lt;/li&gt;
  &lt;li&gt;make sure you have &lt;code&gt;_kerberos.$hostname&lt;/code&gt; TXT record set per &lt;code&gt;host/domain&lt;/code&gt;
for the right realm name. Remember that Kerberos realm is case-sensitive and almost everywhere it is uppercase, so be sure the value of the TXT record is correct.&lt;/li&gt;
&lt;/ul&gt;</description>
	<pubDate>Sun, 24 Mar 2019 07:13:00 +0000</pubDate>
</item>
<item>
	<title>Jakub Hrozek: IPA sudo rules for local users</title>
	<guid>http://jhrozek.wordpress.com/?p=415</guid>
	<link></link>
	<description>Central identity management solutions like IPA offer a very nice capability &amp;#8211; in addition to storing users and groups on the server, also certain kinds of policies can be defined in one place and used by all the machines in the domain. Sudo rules are one of the most common policies that administrators define for &amp;#8230; &lt;a href=&quot;https://jhrozek.wordpress.com/2018/03/26/ipa-sudo-rules-for-local-users/&quot; class=&quot;more-link&quot;&gt;Continue reading &lt;span class=&quot;screen-reader-text&quot;&gt;IPA sudo rules for local&amp;#160;users&lt;/span&gt; &lt;span class=&quot;meta-nav&quot;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;</description>
	<pubDate>Mon, 26 Mar 2018 10:33:40 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: FOSDEM 2018 IAM devroom</title>
	<guid>https://vda.li/en/posts/2017/12/21/FOSDEM-2018-IAM-devroom/</guid>
	<link>https://vda.li/en/posts/2017/12/21/FOSDEM-2018-IAM-devroom/</link>
	<description>&lt;p&gt;&lt;a href=&quot;https://www.fosdem.org/2018/&quot;&gt;FOSDEM&lt;/a&gt; is one of largest free software
conferences in Europe. It is run by volunteers for volunteers and since 2001
gathers together more than 8000 people every year. Sure, during first years
there were less visitors (I had been lucky to actually present at the first
FOSDEM and also ran a workshop there) but the atmosphere didn’t change and it
is still has the same classical hacker gathering feeling.&lt;/p&gt;

&lt;p&gt;In 2018 FOSDEM will run on the weekend of February 3rd and 4th. Since the
event has grown up significantly, there are multiple development rooms in
addition to the main tracks. Each development room is given a room for Saturday
or Sunday (or both). Each development room issues own call for proposals (CfP),
chooses talks for the schedule and runs the event. FOSDEM crew films and
streams all devrooms online for those who couldn’t attend them in real time but
the teams behind actual devrooms are what powers the event.&lt;/p&gt;

&lt;p&gt;In 2018 there will be 42 devrooms in addition to the main track. Think about it
as 43 different conferences happening at the same time, that’s the scale and
power of FOSDEM. I’m still being impressed by the power of volunteers who
contribute to FOSDEM success even long since the original crew of sysadmins of
Free University of Brussels decided to stop working on FOSDEM.&lt;/p&gt;

&lt;p&gt;Identity management related topics has been always part of FOSDEM. In 2016 I
was presenting in the main track about our progress with GNOME desktop
readiness for enteprise environments, integration with freeIPA and other
topics, including a demo of freeIPA and Ipsilon powering authentication for
Owncloud and Google Apps. Some of my colleagues ran freeIPA presentation well
before that too.&lt;/p&gt;

&lt;p&gt;We wanted to have a bit more focused story telling too. Radovan Semancik tried
to organize a devroom in 2016 but it wasn’t accepted. Michael Ströder tried the
same in 2017. Getting a devroom proposal to pass always comes with a fair
amount of luck but finally we suceeded with FOSDEM 2018. I’d like to thank you
my colleague Fraser Tweedale who wrote the original proposal draft out of which
grew up the effort with &lt;a href=&quot;https://fosdem.org/2018/schedule/track/identity_and_access_management/&quot;&gt;Identity and Access Management devroom.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We tried to keep a balance between a number of talks and a variety of topics
presented. We only have 8.5 hours of schedule allocated.  With 5 minutes
intervals between the talks we were able to accomodate 14 talks out of 25
proposals.&lt;/p&gt;

&lt;p&gt;The talks are structured in roughly five categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Identity and access management for operating systems&lt;/li&gt;
  &lt;li&gt;Application level identity and access management&lt;/li&gt;
  &lt;li&gt;Interoperability issues between POSIX and Active Directory environments&lt;/li&gt;
  &lt;li&gt;Deployment reports for open source identity management solutions&lt;/li&gt;
  &lt;li&gt;Security and cryptography on a system and application level&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Admittedly, we’ve got one of smallest rooms (50 people) allocated but this is a
start. On Saturday, February 3rd, 2018, please come to room
&lt;a href=&quot;https://fosdem.org/2018/schedule/buildings/#u&quot;&gt;UD2.119&lt;/a&gt;. And if you couldn’t
be in person at FOSDEM, streaming will be available too.&lt;/p&gt;

&lt;p&gt;See you in Brussels!&lt;/p&gt;</description>
	<pubDate>Thu, 21 Dec 2017 10:35:00 +0000</pubDate>
</item>
<item>
	<title>Florence Blanc-Renaud: Demystifying the Certificate Authority component in FreeIPA</title>
	<guid>http://floblanc.wordpress.com/?p=1634</guid>
	<link></link>
	<description>When I joined the FreeIPA team, I wanted to start by getting more familiar with the product from a user perspective and the first step was to install FreeIPA server. I opened the Linux Domain Identity, Authentication, and Policy Guide, tried to figure out which options would be useful and&amp;#8230; I froze when I reached &amp;#8230; &lt;a href=&quot;https://floblanc.wordpress.com/2017/12/05/demystifying-the-certificate-authority-component-in-freeipa/&quot; class=&quot;more-link&quot;&gt;Continue reading &lt;span class=&quot;screen-reader-text&quot;&gt;Demystifying the Certificate Authority component in FreeIPA&lt;/span&gt; &lt;span class=&quot;meta-nav&quot;&gt;&amp;#8594;&lt;/span&gt;&lt;/a&gt;</description>
	<pubDate>Tue, 05 Dec 2017 15:05:38 +0000</pubDate>
</item>
<item>
	<title>Rich Megginson: How to debug &quot;undefined method for nil:NilClass&quot; in OpenShift Aggregated Logging</title>
	<guid>https://richmegginson.livejournal.com/29741.html</guid>
	<link>https://richmegginson.livejournal.com/29741.html</link>
	<description>&lt;p&gt;In OpenShift Aggregated Logging &lt;a href=&quot;https://github.com/openshift/origin-aggregated-logging&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;https://github.com/openshift/origin-aggregated-logging&lt;/a&gt; the Fluentd pipeline tries very hard to ensure that the data is correct, because it depends on having clean data in the output section in order to construct the index names for Elasticsearch. If the fields and values are not correct, then the index name construction will fail with an unhelpful error like this:&lt;br /&gt;&lt;pre&gt;&lt;code&gt;2017-09-28 13:22:22 -0400 [warn]: temporarily failed to flush the buffer. next_retry=2017-09-28 13:22:23 -0400 error_class=&quot;NoMethodError&quot;
error=&quot;undefined method `[]' for nil:NilClass&quot; plugin_id=&quot;object:1c0bd1c&quot;
2017-09-28 13:22:22 -0400 [warn]: /opt/app-root/src/gems/fluent-plugin-elasticsearch-1.9.5.1/lib/fluent/plugin/out_elasticsearch_dynamic.rb:240:in `eval'
2017-09-28 13:22:22 -0400 [warn]: /opt/app-root/src/gems/fluent-plugin-elasticsearch-1.9.5.1/lib/fluent/plugin/out_elasticsearch_dynamic.rb:240:in `eval'
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;There is no context about what field might be missing, what tag is matching, or even which plugin it is, the operations output or the applications output (although you do get the plugin_id, which could be used to look up the actual plugin information, if the Fluentd monitoring is enabled).&lt;br /&gt;One solution is to just edit the &lt;tt&gt;logging-fluentd&lt;/tt&gt; ConfigMap, and add a &lt;tt&gt;stdout&lt;/tt&gt; filter in the right place:&lt;br /&gt;&lt;pre&gt;&lt;code&gt;## matches
          &amp;lt;filter **&amp;gt;
            @type stdout
          &amp;lt;/filter&amp;gt;
          @include configs.d/openshift/output-pre-*.conf
          ...
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;and dump the time, tag, and record just before the outputs.  The problem with this is that it will cause a feedback loop, since Fluentd is reading from its own pod log.  The solution to this is to also throw away Fluentd pod logs.&lt;br /&gt;&lt;pre&gt;&lt;code&gt;## filters
          @include configs.d/openshift/filter-pre-*.conf
          @include configs.d/openshift/filter-retag-journal.conf
          &amp;lt;match kubernetes.journal.container.fluentd kubernetes.var.log.containers.fluentd**&amp;gt;
            @type null
          &amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;This must come after the &lt;tt&gt;filter-retag-journal.conf&lt;/tt&gt; which identifies and tags Fluentd pod log records.  Then restart Fluentd (oc pod delete $fluentd_pod, oc label node, etc.).  The Fluentd pod log will now contain data like this:&lt;br /&gt;&lt;pre&gt;&lt;code&gt;2017-09-28 13:44:47 -0400 output_tag: {&quot;type&quot;:&quot;response&quot;,&quot;@timestamp&quot;:&quot;2017-09-28T17:44:19.524989+00:00&quot;,&quot;pid&quot;:8,&quot;method&quot;:&quot;head&quot;,&quot;statusCode&quot;:200,
&quot;req&quot;:{&quot;url&quot;:&quot;/&quot;,&quot;method&quot;:&quot;head&quot;,&quot;headers&quot;:{&quot;user-agent&quot;:&quot;curl/7.29.0&quot;,&quot;host&quot;:&quot;localhost:5601&quot;,&quot;accept&quot;:&quot;*/*&quot;},&quot;remoteAddress&quot;:&quot;127.0.0.1&quot;,&quot;userAgent&quot;:&quot;127.0.0.1&quot;},
&quot;res&quot;:{&quot;statusCode&quot;:200,&quot;responseTime&quot;:2,&quot;contentLength&quot;:9},
&quot;message&quot;:&quot;HEAD / 200 2ms - 9.0B&quot;,
&quot;docker&quot;:{&quot;container_id&quot;:&quot;e1cc1b22d04683645b00de53c0891e284c492358fd2830142f4523ad29eec060&quot;},
&quot;kubernetes&quot;:{&quot;container_name&quot;:&quot;kibana&quot;,&quot;namespace_name&quot;:&quot;logging&quot;,&quot;pod_name&quot;:&quot;logging-kibana-1-t9tvv&quot;,
&quot;pod_id&quot;:&quot;358622d8-a467-11e7-ab9a-0e43285e8fce&quot;,&quot;labels&quot;:{&quot;component&quot;:&quot;kibana&quot;,&quot;deployment&quot;:&quot;logging-kibana-1&quot;,
&quot;deploymentconfig&quot;:&quot;logging-kibana&quot;,&quot;logging-infra&quot;:&quot;kibana&quot;,&quot;provider&quot;:&quot;openshift&quot;},
&quot;host&quot;:&quot;ip-172-18-0-133.ec2.internal&quot;,&quot;master_url&quot;:&quot;https://kubernetes.default.svc.cluster.local&quot;,
&quot;namespace_id&quot;:&quot;9dbd679c-a466-11e7-ab9a-0e43285e8fce&quot;},...
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Now, if you see a record that is missing &lt;tt&gt;@timestamp&lt;/tt&gt;, or a record from a pod that is missing &lt;tt&gt;kubernetes.namespace_name&lt;/tt&gt; or &lt;tt&gt;kubernetes.namespace_id&lt;/tt&gt;, you know that the exception is caused by one of these missing fields.&lt;/p&gt;</description>
	<pubDate>Thu, 28 Sep 2017 20:07:25 +0000</pubDate>
</item>
<item>
	<title>Striker Leggette: Deploy Windows 2016 AD and Fedora 25 IPA with a One-way Trust</title>
	<guid>http://strikerttd.wordpress.com/?p=197</guid>
	<link></link>
	<description>Introduction For the purpose of this post, the two machines I used for these instructions are VMs running atop a Fedora 25 hypervisor which was configured as outlined here: Configuring Fedora 25 as a Hypervisor using Virtual Machine Manager Note: Make sure that when deploying IPA and AD that you do so on separate domains.  Otherwise, &amp;#8230; &lt;a href=&quot;https://strikerttd.wordpress.com/2017/05/30/deploy-windows-2016-ad-and-fedora-25-ipa-with-a-one-way-trust/&quot; class=&quot;more-link&quot;&gt;Continue reading&lt;span class=&quot;screen-reader-text&quot;&gt; &quot;Deploy Windows 2016 AD and Fedora 25 IPA with a One-way&amp;#160;Trust&quot;&lt;/span&gt;&lt;/a&gt;</description>
	<pubDate>Tue, 30 May 2017 05:38:00 +0000</pubDate>
</item>
<item>
	<title>Justin Stephenson: Measuring SSSD performance with SystemTap</title>
	<guid>tag:blogger.com,1999:blog-8317082414319754746.post-4779932653839170767</guid>
	<link>http://justin-stephenson.blogspot.com/2017/05/measuring-sssd-performance-with.html</link>
	<description>&lt;p&gt;This post is intended to provide information about finding SSSD bottlenecks with SystemTap.&lt;/p&gt;&lt;p&gt;One of the most common complaints with SSSD is slowness during login or NSS commands such as ‘getent’ or ‘id’ especially in large LDAP/Active Directory environments. Log analysis alone can be difficult to track down the source of the delay, especially with certain configurations(Indirect AD Integration) where there is a significant number of backend operations that occur during login.&lt;/p&gt;&lt;p&gt;In SSSD 1.14, performance enhancements were made to optimize cache write operations decreasing overall time spent updating the filesystem cache. These bottlenecks were discovered by developers based on userspace probing in certain areas of the SSSD code with SystemTap.&lt;/p&gt;&lt;p&gt;Below are some steps on getting started with SystemTap and SSSD, in this example we will use recent additions of High-Level Data Provider request probes.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;First, install the necessary packages mentioned here: &lt;a href=&quot;https://www.sourceware.org/systemtap/SystemTap_Beginners_Guide/using-systemtap.html&quot;&gt;Installation and Setup&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It is not required to install &lt;strong&gt;kernel-debuginfo&lt;/strong&gt; or &lt;strong&gt;sssd-debuginfo&lt;/strong&gt; to run these userspace systemtap scripts.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You can now check if the probe markers are available with:&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# stap -L 'process(&quot;/usr/libexec/sssd/sssd_be&quot;).mark(&quot;*&quot;)'&lt;/span&gt;&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/libexec/sssd/sssd_be&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;dp_req_done&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/libexec/sssd/sssd_be&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;dp_req_send&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# stap -L 'process(&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;).mark(&quot;*&quot;)' | head&lt;/span&gt;&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_acct_req_recv&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg4&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_acct_req_send&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg4&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_deref_search_recv&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_deref_search_send&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_get_generic_ext_recv&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_get_generic_ext_send&quot;&lt;/span&gt;) &lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;:long &lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;:long&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_nested_group_check_cache_post&quot;&lt;/span&gt;)&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_nested_group_check_cache_pre&quot;&lt;/span&gt;)&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_nested_group_deref_process_post&quot;&lt;/span&gt;)&lt;br /&gt;process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_nested_group_deref_process_pre&quot;&lt;/span&gt;)&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The existing SystemTap scripts are located in &lt;em&gt;/usr/share/sssd/systemtap&lt;/em&gt;. The &lt;em&gt;id_perf.stp&lt;/em&gt; can be used to measure performance specifically with the ‘id’ command, while the &lt;em&gt;nested_group_perf.stp&lt;/em&gt; generates metrics and useful information associated with nested group processing code.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# ll /usr/share/sssd/systemtap/&lt;/span&gt;&lt;br /&gt;-rw-r--r--. &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; root root &lt;span class=&quot;hljs-number&quot;&gt;2038&lt;/span&gt; May  &lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;18&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;16&lt;/span&gt; dp_request.stp&lt;br /&gt;-rw-r--r--. &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; root root &lt;span class=&quot;hljs-number&quot;&gt;3854&lt;/span&gt; May  &lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;13&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;56&lt;/span&gt; id_perf.stp&lt;br /&gt;-rw-r--r--. &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; root root &lt;span class=&quot;hljs-number&quot;&gt;8613&lt;/span&gt; May  &lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;14&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;44&lt;/span&gt; nested_group_perf.stp&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Running the &lt;em&gt;dp_request.stp&lt;/em&gt; script will track Data Provider requests and provide information about the request which took the most time to complete.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# vim /usr/share/sssd/systemtap/dp_request.stp &lt;/span&gt;&lt;br /&gt;/* Start Run with:&lt;br /&gt; *   stap -v dp_request.stp&lt;br /&gt; *&lt;br /&gt; * Then reproduce slow login or id/getent &lt;span class=&quot;hljs-keyword&quot;&gt;in&lt;/span&gt; another terminal.&lt;br /&gt; * Ctrl-C running stap once login completes.&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# stap -v /usr/share/sssd/systemtap/dp_request.stp &lt;/span&gt;&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;: parsed user script and &lt;span class=&quot;hljs-number&quot;&gt;469&lt;/span&gt; library scripts using &lt;span class=&quot;hljs-number&quot;&gt;244964&lt;/span&gt;virt/&lt;span class=&quot;hljs-number&quot;&gt;45004&lt;/span&gt;res/&lt;span class=&quot;hljs-number&quot;&gt;7588&lt;/span&gt;shr/&lt;span class=&quot;hljs-number&quot;&gt;37596&lt;/span&gt;data kb, &lt;span class=&quot;hljs-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;100&lt;/span&gt;usr/&lt;span class=&quot;hljs-number&quot;&gt;20&lt;/span&gt;sys/&lt;span class=&quot;hljs-number&quot;&gt;128&lt;/span&gt;real ms.&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;: analyzed script: &lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt; probes, &lt;span class=&quot;hljs-number&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;hljs-built_in&quot;&gt;functions&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; embeds, &lt;span class=&quot;hljs-number&quot;&gt;11&lt;/span&gt; globals using &lt;span class=&quot;hljs-number&quot;&gt;246992&lt;/span&gt;virt/&lt;span class=&quot;hljs-number&quot;&gt;48356&lt;/span&gt;res/&lt;span class=&quot;hljs-number&quot;&gt;8816&lt;/span&gt;shr/&lt;span class=&quot;hljs-number&quot;&gt;39624&lt;/span&gt;data kb, &lt;span class=&quot;hljs-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;30&lt;/span&gt;usr/&lt;span class=&quot;hljs-number&quot;&gt;160&lt;/span&gt;sys/&lt;span class=&quot;hljs-number&quot;&gt;396&lt;/span&gt;real ms.&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;: using cached /root/.systemtap/cache/d5/stap_d5d7fd869e61741e13b43b7a6932a761_11210.c&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;: using cached /root/.systemtap/cache/d5/stap_d5d7fd869e61741e13b43b7a6932a761_11210.ko&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;: starting run.&lt;br /&gt;        *** Beginning run! ***&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#1] sent for domain [AD.JSTEPHEN]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#1] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m8.&lt;span class=&quot;hljs-number&quot;&gt;476&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#2] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#2] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;003&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Initgroups &lt;span class=&quot;hljs-comment&quot;&gt;#3] sent for domain [AD.JSTEPHEN]&lt;/span&gt;&lt;br /&gt;                 DP Request [Initgroups &lt;span class=&quot;hljs-comment&quot;&gt;#3] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;115&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#4] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#4] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;001&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#5] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#5] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;002&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#6] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#6] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;001&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#7] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#7] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;000&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#8] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#8] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;001&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;        --&amp;gt; DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#9] sent for domain [idm.jstephen]&lt;/span&gt;&lt;br /&gt;                 DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#9] finished with return code [0]: [Success]&lt;/span&gt;&lt;br /&gt;                 Elapsed time [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m0.&lt;span class=&quot;hljs-number&quot;&gt;001&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;^C&lt;br /&gt;Ending Systemtap Run - Providing Summary&lt;br /&gt;Total Number of DP requests: [&lt;span class=&quot;hljs-number&quot;&gt;9&lt;/span&gt;]&lt;br /&gt;Total time &lt;span class=&quot;hljs-keyword&quot;&gt;in&lt;/span&gt; DP requests: [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m8.&lt;span class=&quot;hljs-number&quot;&gt;600&lt;/span&gt;s]&lt;br /&gt;Slowest request data:&lt;br /&gt;        Request: [Account &lt;span class=&quot;hljs-comment&quot;&gt;#1]&lt;/span&gt;&lt;br /&gt;        Start Time: [Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt; EDT]&lt;br /&gt;        End Time: [Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;23&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt; EDT]&lt;br /&gt;        Duration: [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;m8.&lt;span class=&quot;hljs-number&quot;&gt;476&lt;/span&gt;s]&lt;br /&gt;&lt;br /&gt;Pass &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;: run completed &lt;span class=&quot;hljs-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;usr/&lt;span class=&quot;hljs-number&quot;&gt;40&lt;/span&gt;sys/&lt;span class=&quot;hljs-number&quot;&gt;15329&lt;/span&gt;real ms.&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;We can see that the &lt;strong&gt;getAccountInfo #1&lt;/strong&gt; DP request completed in 8.476 seconds, the Start Time/End Time provided here can be used to help narrow down log analysis.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;(Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt;) [sssd[be[idm.jstephen]]] [dp_get_account_info_handler] (&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;x0200): Got request &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; [&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;x1][BE_REQ_USER][name=trustuser1@ad.jstephen]&lt;br /&gt;(Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt;) [sssd[be[idm.jstephen]]] [dp_attach_req] (&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;x0400): DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#1]: New request. Flags [0x0001].&lt;/span&gt;&lt;br /&gt;(Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt;) [sssd[be[idm.jstephen]]] [dp_attach_req] (&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;x0400): Number of active DP request: &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;&lt;br /&gt;...&lt;br /&gt;&amp;lt;snip&amp;gt;&lt;br /&gt;...&lt;br /&gt;(Fri May  &lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;47&lt;/span&gt;:&lt;span class=&quot;hljs-number&quot;&gt;23&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2017&lt;/span&gt;) [sssd[be[idm.jstephen]]] [dp_req_&lt;span class=&quot;hljs-keyword&quot;&gt;done&lt;/span&gt;] (&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;x0400): DP Request [Account &lt;span class=&quot;hljs-comment&quot;&gt;#1]: Request handler finished [0]: Success&lt;/span&gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The existing SystemTap scripts can be modified or new scripts can be created for a certain use-case as long as the existing probes/tapsets in &lt;strong&gt;/usr/share/systemtap/tapset/sssd.stp&lt;/strong&gt; are used.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;# LDAP search probes&lt;/span&gt;&lt;br /&gt;probe sdap_search_send = process(&lt;span class=&quot;hljs-string&quot;&gt;&quot;/usr/lib64/sssd/libsss_ldap_common.so&quot;&lt;/span&gt;).mark(&lt;span class=&quot;hljs-string&quot;&gt;&quot;sdap_get_generic_ext_send&quot;&lt;/span&gt;)&lt;br /&gt;{&lt;br /&gt;    base = user_string(&lt;span class=&quot;hljs-variable&quot;&gt;$arg1&lt;/span&gt;);&lt;br /&gt;    scope = &lt;span class=&quot;hljs-variable&quot;&gt;$arg2&lt;/span&gt;;&lt;br /&gt;    filter = user_string(&lt;span class=&quot;hljs-variable&quot;&gt;$arg3&lt;/span&gt;);&lt;br /&gt;&lt;br /&gt;    probestr = sprintf(&lt;span class=&quot;hljs-string&quot;&gt;&quot;-&amp;gt; search base [%s] scope [%d] filter [%s]&quot;&lt;/span&gt;,&lt;br /&gt;                       base, scope, filter);&lt;br /&gt;}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;em&gt;stap -L&lt;/em&gt; command shown previously will list out the functions where probes were added making these markers available for writing scripts with.&lt;/p&gt;&lt;p&gt;The goal will be to add more low-level probes to iterative functions where SSSD spends a lot of time. This will allow developers and administrators to analyze performance issues in detail.&lt;/p&gt;</description>
	<pubDate>Fri, 05 May 2017 16:39:00 +0000</pubDate>
	<author>noreply@blogger.com (Justin Stephenson)</author>
</item>
<item>
	<title>Alexander Bokovoy: How to debug FreeIPA privilege separation issues</title>
	<guid>https://vda.li/en/posts/2017/04/28/FreeIPA-Debugging-Privilege-Separation/</guid>
	<link>https://vda.li/en/posts/2017/04/28/FreeIPA-Debugging-Privilege-Separation/</link>
	<description>&lt;p&gt;FreeIPA 4.5 has a lot of internal changes. A server side of the FreeIPA framework now runs in a privilege separation mode. This improves security of FreeIPA management operations but complicates debugging of the server. During FreeIPA 4.5 development phase Simo Sorce and I spent a lot of time debugging regressions and decided to document how we log events and how to debug server side operations. As result, &lt;a href=&quot;https://vda.li/en/docs/freeipa-debug-privsep/&quot;&gt;this article&lt;/a&gt; details on what privilege separation means in FreeIPA management framework context and how to debug it.&lt;/p&gt;</description>
	<pubDate>Fri, 28 Apr 2017 19:00:00 +0000</pubDate>
</item>
<item>
	<title>Rich Megginson: Elasticsearch Troubleshooting - unassigned_shard and cluster state RED</title>
	<guid>https://richmegginson.livejournal.com/29454.html</guid>
	<link>https://richmegginson.livejournal.com/29454.html</link>
	<description>&lt;h1&gt;Problem - unassigned_shards and cluster status RED&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;Using OpenShift origin-aggregated-logging 1.2, Elasticsearch 1.5.2, the cluster status is RED.&lt;pre&gt;&lt;code&gt;oc exec logging-es-xxx-N-yyy -n logging -- curl -s \
  --key /etc/elasticsearch/keys/admin-key \
  --cert /etc/elasticsearch/keys/admin-cert \
  --cacert /etc/elasticsearch/keys/admin-ca \
  https://localhost:9200/_cluster/health | \
  python -mjson.tool
{
    &quot;active_primary_shards&quot;: 12345,
    &quot;active_shards&quot;: 12345,
    &quot;cluster_name&quot;: &quot;logging-es&quot;,
    &quot;initializing_shards&quot;: 0,
    &quot;number_of_data_nodes&quot;: 3,
    &quot;number_of_nodes&quot;: 3,
    &quot;number_of_pending_tasks&quot;: 0,
    &quot;relocating_shards&quot;: 0,
    &quot;status&quot;: &quot;red&quot;,
    &quot;timed_out&quot;: false,
    &quot;unassigned_shards&quot;: 7
}
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;The problem is the unassigned_shards.  We need to identify those shards and&lt;br /&gt;figure out how to deal with them so the cluster can move to &lt;code&gt;yellow&lt;/code&gt; or&lt;br /&gt;&lt;code&gt;green&lt;/code&gt;.&lt;p&gt;&lt;br /&gt;&lt;h1&gt;Solution - identify and delete problematic indices&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;Use the &lt;code&gt;/_cluster/health?level=indices&lt;/code&gt; to get a list of the indices status:&lt;pre&gt;&lt;code&gt;oc exec logging-es-xxx-N-yyy -n logging -- curl -s \
  --key /etc/elasticsearch/keys/admin-key \
  --cert /etc/elasticsearch/keys/admin-cert \
  --cacert /etc/elasticsearch/keys/admin-ca \
  https://localhost:9200/_cluster/health?level=indices | \
  python -mjson.tool &amp;gt; indices.json
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;The report will list each index and its state:&lt;pre&gt;&lt;code&gt;&quot;my-index.2017.03.15&quot;:{
   &quot;active_primary_shards&quot;: 4,
   &quot;active_shards&quot;: 4,
   &quot;initializing_shards&quot;: 0,
   &quot;number_of_replicas&quot;: 0,
   &quot;number_of_shards&quot;: 5,
   &quot;relocating_shards&quot;: 0,
   &quot;status&quot;: &quot;red&quot;,
   &quot;unassigned_shards&quot;: 1
 },
 ...
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;Look for records that have &lt;code&gt;&quot;status&quot;: &quot;red&quot;&lt;/code&gt; and an &lt;code&gt;&quot;unassigned_shards&quot;&lt;/code&gt; with&lt;br /&gt;a value of &lt;code&gt;1&lt;/code&gt; or higher.  IF YOU DON&amp;rsquo;T NEED THE DATA ANYMORE, AND ARE SURE&lt;br /&gt;THAT THIS DATA CAN BE LOST, then it might be easiest to just delete these using&lt;br /&gt;the REST API:&lt;pre&gt;&lt;code&gt;oc exec logging-es-xxx-N-yyy -n logging -- curl -s \
  --key /etc/elasticsearch/keys/admin-key \
  --cert /etc/elasticsearch/keys/admin-cert \
  --cacert /etc/elasticsearch/keys/admin-ca \
  -XDELETE https://localhost:9200/my-index.2017.03.15
&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;If you need to recover this data, or deletion is not working, then use the&lt;br /&gt;recovery procedure documented at&lt;br /&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/1.5/indices-recovery.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;indices recovery&lt;/a&gt;&lt;/p&gt;</description>
	<pubDate>Wed, 15 Mar 2017 17:45:33 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: FreeIPA JSON-RPC API article</title>
	<guid>https://vda.li/en/posts/2016/11/02/FreeIPA-JSON-RPC-API-article/</guid>
	<link>https://vda.li/en/posts/2016/11/02/FreeIPA-JSON-RPC-API-article/</link>
	<description>&lt;p&gt;FreeIPA Web UI provides a browser for discovering application programming interface (API) since version FreeIPA 4.2. However, the API itself is not yet officially supported and there is no documentation on how to access it. Some time ago I wrote a blog post detailing on how to access the API from an external client, like &lt;code&gt;curl&lt;/code&gt; utility. &lt;a href=&quot;https://vda.li/en/posts/2015/05/28/talking-to-freeipa-api-with-sessions/&quot;&gt;The blog post&lt;/a&gt; was quite popular and allowed to create bindings to FreeIPA API in Perl and other languages. However, the blog post assumed you know what you are doing. In order to help those starting from scratch, I wrote a larger article, &lt;a href=&quot;https://vda.li/en/docs/freeipa-management-in-a-nutshell&quot;&gt;FreeIPA management API a nutshell&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The article is available in a new documentation section so that it stays independent of the blog. I plan to extend the API documentation and add more details later. The document assumes you are using FreeIPA 4.4 or later which is available in upcoming Fedora 25 and RHEL 7.3 releases.&lt;/p&gt;</description>
	<pubDate>Wed, 02 Nov 2016 14:00:00 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: Creating permissions in FreeIPA</title>
	<guid>https://vda.li/en/posts/2016/08/30/Creating-permissions-in-FreeIPA/</guid>
	<link>https://vda.li/en/posts/2016/08/30/Creating-permissions-in-FreeIPA/</link>
	<description>&lt;p&gt;FreeIPA has quite flexible system to define access rights for any resources in
the LDAP store. The system consists of three different parts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a permission object&lt;/li&gt;
  &lt;li&gt;a privilege object, and&lt;/li&gt;
  &lt;li&gt;a role object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Permission object specifies the target of the access grant: what attributes of
which objects in LDAP would be subject of the checks.&lt;/p&gt;

&lt;p&gt;A privilege allows to combine several permissions together in a logical task. A
role defines who can have access to privileges.&lt;/p&gt;

&lt;p&gt;An example below is a somewhat complex use of the permission system to allow
groups of administrators to manage specific hosts. We want administrators in
group ‘my-admins’ to manage hosts in ‘my-hostgroup’ but otherwise have no other
privileges.&lt;/p&gt;

&lt;p&gt;Let’s start with a host group ‘my-hostgroup’:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa hostgroup-add my-hostgroup
-----------------------------
Added hostgroup &quot;my-hostgroup&quot;
-----------------------------
  Host-group: my-hostgroup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And with a group ‘my-admins’:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa group-add my-admins
-----------------------
Added group &quot;my-admins&quot;
-----------------------
  Group name: my-admins
  GID: 903200040
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A member of ‘my-admins’ should be able to edit all attributes of the hosts in
the host group ‘my-hostgroup’.&lt;/p&gt;

&lt;p&gt;To manage permissions, use &lt;code&gt;ipa permission&lt;/code&gt; family of commands. You need to
create a basic permission which applies to hosts:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa permission-add manage-my-hostgroup --right=all --bindtype=permission --type=host
--------------------------------------
Added permission &quot;manage-my-hostgroup&quot;
--------------------------------------
  Permission name: manage-my-hostgroup
  Granted rights: all
  Bind rule type: permission
  Subtree: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  Type: host
  Permission flags: V2, SYSTEM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A permission automatically generates an access control item (ACI) in the LDAP.
To check all low-level details of the permission, use &lt;code&gt;--all&lt;/code&gt; and &lt;code&gt;--raw&lt;/code&gt;
options:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa permission-show --all --raw manage-my-hostgroup
  dn: cn=manage-my-hostgroup,cn=permissions,cn=pbac,dc=ipa,dc=ad,dc=test
  cn: manage-my-hostgroup
  ipapermright: all
  ipapermbindruletype: permission
  ipapermlocation: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  ipapermtargetfilter: (objectclass=ipahost)
  ipapermissiontype: V2
  ipapermissiontype: SYSTEM
  aci: (targetfilter = &quot;(objectclass=ipahost)&quot;)
       (version 3.0; acl &quot;permission:manage-my-hostgroup&quot;;
                     allow (all)
                     groupdn = &quot;ldap:///cn=manage-my-hostgroup,cn=permissions,cn=pbac,dc=ipa,dc=ad,dc=test&quot;;)
  objectclass: ipapermission
  objectclass: top
  objectclass: groupofnames
  objectclass: ipapermissionv2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, it applies to hosts: cn=computers,cn=accounts,$SUFFIX
subtree, and target filter is set to (objectclass=ipahost). So it would
apply to any host. To further limit the permission, you have to add more
target filters.&lt;/p&gt;

&lt;p&gt;To define raw target filter, we need to know a DN of the hostgroup that
will be our target limit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa hostgroup-show --raw --all my-hostgroup
  dn: cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test
  cn: my-hostgroup
  ipaUniqueID: 6d8c72f2-6e6d-11e6-b9e4-525400bf08fe
  mepManagedEntry: cn=my-hostgroup,cn=ng,cn=alt,dc=ipa,dc=ad,dc=test
  objectClass: ipahostgroup
  objectClass: ipaobject
  objectClass: nestedGroup
  objectClass: groupOfNames
  objectClass: top
  objectClass: mepOriginEntry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the DN of the &lt;code&gt;my-hostgroup&lt;/code&gt;, we can now add a filter to the
permission:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa permission-mod manage-my-hostgroup --filter '(memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)'
-----------------------------------------
Modified permission &quot;manage-my-hostgroup&quot;
-----------------------------------------
  Permission name: manage-my-hostgroup
  Granted rights: all
  Bind rule type: permission
  Subtree: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  Extra target filter: (memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)
  Type: host
  Permission flags: V2, SYSTEM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take a look at the permission in detail:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa permission-show --all --raw manage-my-hostgroup
  dn: cn=manage-my-hostgroup,cn=permissions,cn=pbac,dc=ipa,dc=ad,dc=test
  cn: manage-my-hostgroup
  ipapermright: all
  ipapermbindruletype: permission
  ipapermlocation: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  ipapermtargetfilter: (objectclass=ipahost)
  ipapermtargetfilter: (memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)
  ipapermissiontype: V2
  ipapermissiontype: SYSTEM
  aci: (targetfilter = &quot;(&amp;amp;(memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)(objectclass=ipahost))&quot;)
       (version 3.0;acl &quot;permission:manage-my-hostgroup&quot;;
        allow (all) groupdn = &quot;ldap:///cn=manage-my-hostgroup,cn=permissions,cn=pbac,dc=ipa,dc=ad,dc=test&quot;;)
  objectclass: ipapermission
  objectclass: top
  objectclass: groupofnames
  objectclass: ipapermissionv2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our ACI says: “Allow any changes to be done in all objects of
objectclass ipahost that belong to a host group &lt;code&gt;my-hostgroup&lt;/code&gt; to members
of the permission group &lt;code&gt;manage-my-hostgroup&lt;/code&gt;”&lt;/p&gt;

&lt;p&gt;Now you can add the &lt;code&gt;manage-my-hostgroup&lt;/code&gt; permission to a new privilege
and add that privilege to a role, and then assign users of the group &lt;code&gt;my-admins&lt;/code&gt;
to that role. Those users will be able to manage hosts targeted by the permission.&lt;/p&gt;

&lt;p&gt;Start with a privilege:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa privilege-add 'manage-hostgroup-my-hostgroup'
-----------------------------------------------
Added privilege &quot;manage-hostgroup-my-hostgroup&quot;
-----------------------------------------------
  Privilege name: manage-hostgroup-my-hostgroup

# ipa privilege-add-permission 'manage-hostgroup-my-hostgroup'
[permission]: manage-my-hostgroup
  Privilege name: manage-hostgroup-my-hostgroup
  Permissions: manage-my-hostgroup
-----------------------------
Number of permissions added 1
-----------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, create a role and add a privilege to it, and then add members that could
use the privilege:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa role-add role-manage-hostgroup-my-hostgroup
-----------------------------------------------
Added role &quot;role-manage-hostgroup-my-hostgroup&quot;
-----------------------------------------------
  Role name: role-manage-hostgroup-my-hostgroup

# ipa role-add-privilege role-manage-hostgroup-my-hostgroup
[privilege]: manage-hostgroup-my-hostgroup
  Role name: role-manage-hostgroup-my-hostgroup
  Privileges: manage-hostgroup-my-hostgroup
----------------------------
Number of privileges added 1
----------------------------

# ipa role-add-member role-manage-hostgroup-my-hostgroup --groups=my-admins
  Role name: role-manage-hostgroup-my-hostgroup
  Member groups: my-admins
  Privileges: manage-hostgroup-my-hostgroup
-------------------------
Number of members added 1
-------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we look at the original permission, we can see it is now an indirect member
of a role:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa permission-show manage-my-hostgroup
  Permission name: manage-my-hostgroup
  Granted rights: all
  Bind rule type: permission
  Subtree: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  Extra target filter: (memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)
  Type: host
  Permission flags: V2, SYSTEM
  Granted to Privilege: manage-hostgroup-my-hostgroup
  Indirect Member of roles: role-manage-hostgroup-my-hostgroup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When user is added to the &lt;code&gt;my-admins&lt;/code&gt; group, it automatically assumes a role
that allows to manage the host group:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ipa user-add hadmin
First name: Joe
Last name: Doe
-------------------
Added user &quot;hadmin&quot;
-------------------
  User login: hadmin
  First name: Joe
  Last name: Doe
  Full name: Joe Doe
  Display name: Joe Doe
  Initials: JD
  Home directory: /home/hadmin
  GECOS: Joe Doe
  Login shell: /bin/sh
  Principal name: hadmin@IPA.AD.TEST
  Principal alias: hadmin@IPA.AD.TEST
  Email address: hadmin@ipa.ad.test
  UID: 903200041
  GID: 903200041
  Password: False
  Member of groups: ipausers
  Kerberos keys available: False

# ipa group-add-member my-admins --users=hadmin
  Group name: my-admins
  GID: 903200040
  Member users: hadmin
  Roles: role-manage-hostgroup-my-hostgroup
-------------------------
Number of members added 1
-------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In real life scenario we would probably like to tune our permission a bit more.
For example, we definitely don’t want to allow full access to all attributes of
the host – if users can write to &lt;code&gt;objectclass&lt;/code&gt; attribute, they can turn that
host into anything else in LDAP. But before tuning it, we need to see if our
permission actually works:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# kinit hadmin
Password for hadmin@IPA.AD.TEST:

# ipa host-mod my-host --random
ipa: ERROR: Insufficient access: Insufficient 'write' privilege to the 'userPassword' 
            attribute of entry 'fqdn=my-host.ipa.ad.test,cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test'.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops, it does not work – we cannot write to a &lt;code&gt;userPassword&lt;/code&gt; attribute of the
host. What is wrong? To answer this question we need to look at the
documentation of the LDAP server FreeIPA builds upon: &lt;a href=&quot;http://www.port389.org/&quot;&gt;389-ds&lt;/a&gt;.
&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Directory_Server/10/html/Administration_Guide/Managing_Access_Control-Creating_ACIs_Manually.html#Defining_Targets-Targeting_Entries_or_Attributes_Using_LDAP_Filters&quot;&gt;Red Hat Directory Server Administration Guide&lt;/a&gt; 
says the following in the section “Targeting Entries or Attributes Using LDAP Filters”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note
Although using LDAP filters can be useful when you are targeting entries and
attributes that are spread across the directory, the results are sometimes
unpredictable because filters do not directly name the object for which you
are managing access. The set of entries targeted by a filtered ACI is likely
to change as attributes are added or deleted. Therefore, if you use LDAP
filters in ACIs, you should verify that they target the correct entries and
attributes by using the same filter in an ldapsearch operation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The documentation doesn’t tell this explicitly, but when &lt;code&gt;targetattr&lt;/code&gt; is missing, the
default for matching target attributes when matching with target filter for
modification is &lt;code&gt;none&lt;/code&gt;, not &lt;code&gt;*&lt;/code&gt;. This is done to deny &lt;code&gt;modrdn&lt;/code&gt; (entry rename).&lt;/p&gt;

&lt;p&gt;To allow modification of the host entries, we need to list attributes which
can be modified by our host group admins. The list below is an example only: it
allows to set meta-data about the host, change one-time enrollment password,
assigned ID view, add certificates and SSH public keys. One needs to carefully review
what attributes should be allowed to modify.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# kinit admin
Password for admin@IPA.AD.TEST: 

# ipa permission-mod manage-my-hostgroup --attrs={'userPassword','description','l',\
               'nshardwareplatform','nsosversion','usercertificate','userclass',\
               'macaddress','ipaassignedidview','ipasshpubkey'}
-----------------------------------------
Modified permission &quot;manage-my-hostgroup&quot;
-----------------------------------------
  Permission name: manage-my-hostgroup
  Granted rights: all
  Effective attributes: description, ipaassignedidview, ipakrbauthzdata, ipasshpubkey,
                        l, macaddress, nshardwareplatform, nsosversion, userPassword,
                        usercertificate, userclass
  Bind rule type: permission
  Subtree: cn=computers,cn=accounts,dc=ipa,dc=ad,dc=test
  Extra target filter: (memberOf=cn=my-hostgroup,cn=hostgroups,cn=accounts,dc=ipa,dc=ad,dc=test)
  Type: host
  Permission flags: V2, SYSTEM
  Granted to Privilege: manage-hostgroup-my-hostgroup
  Indirect Member of roles: role-manage-hostgroup-my-hostgroup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With these changes, our admin can now set a random one-time password:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# kinit hadmin
Password for hadmin@IPA.AD.TEST:

# ipa host-mod my-host --random
-----------------------
Modified host &quot;my-host&quot;
-----------------------
  Host name: my-host.ipa.ad.test
  Random password: 5Krkbj_eW7UR@SUxj0lx22
  Principal name: host/my-host.ipa.ad.test@IPA.AD.TEST
  Principal alias: host/my-host.ipa.ad.test@IPA.AD.TEST
  Password: True
  Member of host-groups: my-hostgroup
  Keytab: False
  Managed by: my-host.ipa.ad.test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, this is not all. The permission we created above doesn’t answer a very
important question: how the host &lt;code&gt;my-host&lt;/code&gt; would appear in the host group? We
surely want to be able to add and remove hosts from the host group.  But if we
create a permission that allows per-hostgroup admins to add and remove members
of the host group at will, they could take over any host – by simply adding it
in the host group they manage.&lt;/p&gt;

&lt;p&gt;An easiest way to solve this problem, no surprise, is organizational: do not
give host group admin rights to include hosts to the hostgroup or delete them,
only allow them to manage what’s in the host group.&lt;/p&gt;

&lt;p&gt;A separation of rights requires to create a separate permission for ‘add’/’del’
rights against ‘member’ attribute that would allow to include/remove hosts.
That’s easy but it would not allow us to limit &lt;em&gt;what&lt;/em&gt; hosts could be
added/removed from the host group.&lt;/p&gt;

&lt;p&gt;Unfortunately, to make that possible, permission-add/permission-mod
should be extended to allow specifying target attribute’s values like
described in the &lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Directory_Server/10/html/Administration_Guide/Managing_Access_Control-Creating_ACIs_Manually.html#Defining_Targets-Targeting_Attribute_Values_Using_LDAP_Filters&quot;&gt;RHDS Administration Guide&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Even then to define something like this, we’d need to have specific
naming of hosts to be able to specify a pattern as a ‘member’ attribute
value.&lt;/p&gt;

&lt;p&gt;An alternative is to use automembership rules, defined with &lt;code&gt;ipa automember&lt;/code&gt;
family of commands. It might work with predictable host names but would
probably be hard to implement in case of host names coming out of existing
cloud provider where you don’t have control over the undercloud.&lt;/p&gt;

&lt;p&gt;This is why I’m saying it is an organizational issue, not really a
technical one.&lt;/p&gt;</description>
	<pubDate>Tue, 30 Aug 2016 05:00:00 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: Single sign-on into virtual machines on Linux</title>
	<guid>https://vda.li/en/posts/2016/05/30/Single-sign-on-to-virtual-machines/</guid>
	<link>https://vda.li/en/posts/2016/05/30/Single-sign-on-to-virtual-machines/</link>
	<description>&lt;p&gt;This weekend I looked into making possible a single sign-on into Fedora 24
guests running on libvirt/KVM. Suppose you have a libvirt-based server where a
number VMs is deployed with VMs presenting graphical workstations. This
is not far from what ovirt.org does (RHEV product). You want to have
both your virtualization infrastructure and OS environments in VMs to be
enrolled into FreeIPA and thus accessible with single sign-on from an
external client.&lt;/p&gt;

&lt;p&gt;There are several layers of single sign-on here. Once you signed into
your external client, supposedly you have valid Kerberos credentials
that can be used to obtain service tickets to other services in the
realm.&lt;/p&gt;

&lt;p&gt;Second layer is the connectivity to your virtualization infrastructure.
This is possible already with libvirtd/Qemu as they both support SASL
authentication. It is matter of setting appropriate configuration
variables in /etc/libvirt/libvirtd.conf and /etc/libvirt/qemu.conf, and
tuning /etc/sasl2/libvirt.conf and /etc/sasl2/qemu.conf to allow SASL
GSSAPI authentication. You also need to create appropriate services in
FreeIPA (libvirt/hostname, vnc/hostname, and spice/hostname) and obtain
actual keys with ipa-getkeytab. This is all described relatively well in
&lt;a href=&quot;http://www.freeipa.org/page/Libvirt_with_VNC_Consoles&quot;&gt;the FreeIPA libvirt howto&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once configured, one can authenticate with SASL GSSAPI to VNC server
using virt-manager UI or other VNC clients in GNOME that use gtk-vnc
library. This works pretty well but only gives you access to the actual
screen of the VM, not single sign-on into an operating system in the VM.&lt;/p&gt;

&lt;p&gt;SPICE, on other hand, does not work with SASL GSSAPI. While SPICE server
embedded into Qemu can be configured easily to listen for SASL GSSAPI,
SPICE client libraries in GNOME don’t actually support SASL GSSAPI. In
fact, the code is there, it is copied from gtk-vnc, but it does not
work.&lt;/p&gt;

&lt;p&gt;SPICE client code lacks actual sequence to obtain Kerberos identity out
of existing ticket in a default credentials cache. As result, instead of
authenticating with SASL GSSAPI, a user is left with a request to enter
‘server password’ which is a concept built around existing SPICE
authentication approach where both client and server share a single
password.&lt;/p&gt;

&lt;p&gt;After I fixed this problem by inquiring a Kerberos principal from the
default ccache, SPICE is now working well in a way similar to VNC. I’ll
submit patch to upstream once I have time for that.&lt;/p&gt;

&lt;p&gt;This still doesn’t give any chance to actually log-in to the VM because
both VNC and SPICE servers only represent fancy screens/input devices
for the VMs. There is no existing way to pass through authentication via
SPICE or VNC so that a software running in the VM would accept Kerberos
ticket and authenticate a user based on that.&lt;/p&gt;

&lt;p&gt;Here a concept of guest agent is introduced. Qemu has its own guest
agent (&lt;a href=&quot;https://github.com/qemu/qemu/tree/master/qga&quot;&gt;here&lt;/a&gt;) which only supports
a minimal set of commands needed to make virtualization management
working. OVirt/RHEV have their own guest agent
&lt;a href=&quot;https://github.com/oVirt/ovirt-guest-agent/&quot;&gt;here&lt;/a&gt; that supports much more
than QEmu’s version and has own protocol. Finally, SPICE has own agent,
vdagent, that supports even more operations related to use of graphical
resources within the VM.&lt;/p&gt;

&lt;p&gt;The idea behind these agents is to have a separate trusted channel into
VM that can be used to query/execute something inside the VM. OVirt guest
agent supports logon into the VM by plugging into PAM stack and into
graphical greeters. When user asks OVirt portal to logon into a console of
a VM, a login request can also be sent to the guest agent. This request
doesn’t really present a single sign-on, as user have to enter actual
credentials and then guest agent injects them into GDM, KDM, or console
via D-Bus.&lt;/p&gt;

&lt;p&gt;SPICE vdagent can inject both keyboard and mouse events, and even has
systemd-login integration that allows it to query sessions to know which
X session is used by which user so that mouse/keyboard events are
properly injected. It doesn’t though, have a way to force GNOME GDM to
create a new session automatically based on the credentials
authenticated by the SPICE server.&lt;/p&gt;

&lt;p&gt;It would, perhaps, be a good path forward to hack both SPICE server and
vdagent to make possible use of delegated GSSAPI credentials to perform
a logon into GDM. This would require support from GDM too but as OVirt
experience shows, it is possible to create a GDM plugin to help with the
task. The goal is to have such logon triggered on opening of the SPICE
session if GDM is running and no session is available yet. As result of
such logon, valid Kerberos credentials would need to appear in the
system so that further use of them would be possible. This means
delegation of the credentials – something that SPICE or VNC doesn’t
support either (but SASL GSSAPI allows to achieve, it is a single flag
change and a policy at KDC to define).&lt;/p&gt;

&lt;p&gt;There is another technology to remotely access other systems – RDesktop
protocol. XFreeRDP project has experimental patches to support GSSAPI.
They don’t work yet, but I have good progress on them to make SSO
possible.&lt;/p&gt;

&lt;p&gt;So in the end, current implementations don’t allow actual single sign-on in a
way that would allow using Kerberos credentials in and out of VMs. To make that
possible, more work is needed. It looks like extending vdagent to be able to
pass Kerberos ccache content to SSSD via PAM sessiona and trigger that from the
greeter plugins as developed in OVirt we could actually reach the point with
less effort than creating something from scratch.&lt;/p&gt;</description>
	<pubDate>Mon, 30 May 2016 15:41:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Distributing Secrets with Custodia</title>
	<guid>tag:ssimo.org.blog:id_021</guid>
	<link>https://ssimo.org/blog/id_021.html</link>
	<description>&lt;p&gt;My last &lt;a href=&quot;https://ssimo.org/blog/id_020.html&quot;&gt;blog post&lt;/a&gt; described a crypto library
I created named &lt;a href=&quot;https://github.com/simo5/jwcrypto&quot;&gt;JWCrypto&lt;/a&gt;.
I've built this library as a building block of &lt;a href=&quot;https://github.com/simo5/custodia&quot;&gt;Custodia&lt;/a&gt;, a Service that helps
sharing Secrets, Keys, Passwords in distributed applications like
&lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;micro service
architectures&lt;/a&gt; built on &lt;a href=&quot;https://en.wikipedia.org/wiki/Operating-system-level_virtualization&quot;&gt;containers&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/simo5/custodia&quot;&gt;Custodia&lt;/a&gt; is itself a
building block of a new &lt;a href=&quot;http://freeipa.org&quot;&gt;FreeIPA&lt;/a&gt; feature to
improve the experience of &lt;a href=&quot;https://www.freeipa.org/page/V4/Replica_Promotion&quot;&gt;setting up
replicas&lt;/a&gt;. In fact Custodia at the moment is mostly plumbing for this
feature, and although the plumbing is all there, it is not very usable outside
of the FreeIPA project without some thinkering.&lt;/p&gt;

&lt;p&gt;The past week I was at Flock where I gave a &lt;a href=&quot;https://flock2015.sched.org/event/755ecb20360ff3e82f7b6ab1f62f9ac3&quot;&gt;presentation&lt;/a&gt;
on the problem of distributing Secrets Securely, which is based on my work and my
thinking about the general problem and how I applied that thinking to build a
generic service which I then specializes for use by FreeIPA. If you are
curious, I have &lt;a href=&quot;https://ssimo.org/slides/Secrets.pdf&quot;&gt;posted the slides&lt;/a&gt; I used
during my talk, and they assure me soon there will soon be video recordings of
all the talks available online.&lt;/p&gt;</description>
	<pubDate>Sat, 15 Aug 2015 20:56:00 +0000</pubDate>
</item>
<item>
	<title>Pavel Reichl: Dynamic DNS updates in SSSD</title>
	<guid>http://preichl.wordpress.com/?p=43</guid>
	<link></link>
	<description>SSSD supports dynamic DNS (DDNS) and utilizes nsupdate tool for this purpose. To enable/disable DDNS dyndns_update domain option is used. When DDNS was enabled, by default the address of LDAP connection was used for the DNS updates. This behaviour has changed in the recent SSSD version. Now all (DNS valid) IPv4 and IPv6 addresses of [&amp;#8230;]</description>
	<pubDate>Sun, 09 Aug 2015 22:39:36 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: Talking to FreeIPA API with sessions and JSON-RPC</title>
	<guid>https://vda.li/en/posts/2015/05/28/talking-to-freeipa-api-with-sessions/</guid>
	<link>https://vda.li/en/posts/2015/05/28/talking-to-freeipa-api-with-sessions/</link>
	<description>&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Occasionally I see questions on how to drive FreeIPA programmatically.
One can use &lt;code&gt;ipa &amp;lt;command&amp;gt;&lt;/code&gt; from enrolled IPA clients or go directly to
Python API (as &lt;code&gt;/usr/sbin/ipa&lt;/code&gt; utility is just a tiny shim over the Python API).
However, if you want to drive operations from other frameworks or from non-IPA
clients, there is another way and it is actually very simple.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;FreeIPA web UI is one example of such use. It is a JavaScript-based application
which is downloaded by the browser when visiting IPA web site. The application
bootstraps itself and issues JSON-RPC requests to the server. Browser does authentication
and caching via cookies.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Surely, we can achieve the same from any other framework. There are two separate
stages we&amp;#8217;d have to go through to avoid constant re-authentication:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;olist arabic&quot;&gt;
&lt;ol class=&quot;arabic&quot;&gt;
&lt;li&gt;
&lt;p&gt;Authenticate against IPA server and remember the cookie for our session&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use cookie with session data while issuing our commands&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are separate authentication end points in IPA, one for Kerberos and another
for password-based authentication. Both return a session cookie which we need to store
and present to the server. If cookie is invalid, authentication need to be repeated again.
This flow is well-known to any web application developer so no surprises here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;freeipa-rpc-expectations&quot;&gt;FreeIPA RPC expectations&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to support secure web application development, FreeIPA web API expects
web applications set HTTP referer back to the IPA host. Web browsers do this automatically,
other frameworks have to provide it explicitly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, with &lt;code&gt;curl&lt;/code&gt; you&amp;#8217;d need to specify &lt;code&gt;-H referer:https://$IPAHOSTNAME/ipa&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;kerberos-authentication&quot;&gt;Kerberos authentication&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To authenticate with Kerberos, post an authorization request using Negotiate
scheme over HTTPS to the end point at
&lt;code&gt;&lt;a href=&quot;https://$IPAHOSTNAME/ipa/session/login_kerberos&quot; class=&quot;bare&quot;&gt;https://$IPAHOSTNAME/ipa/session/login_kerberos&lt;/a&gt;&lt;/code&gt;. You need to have actual
credentials in your credentials cache (ccache) prior to sending the request.
The way Kerberos authentication is done, one obtains a ticket granting ticket
(TGT) first, storing it in a ccache and then an application can request a
ticket to a service using existing TGT. A typical non-interactive use is when
ccache is initialized with the TGT based on pre-existing key from a service
keytab:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ export KRB5CCNAME=FILE:/path/to/ccache
$ export COOKIEJAR=/path/to/my.cookie
$ export IPAHOSTNAME=ipa-master.example.com
$ kinit -k -t /path/to/service.keytab service/ipa-client.example.com
$ curl -v  \
        -H referer:https://$IPAHOSTNAME/ipa  \
        -c $COOKIEJAR -b $COOKIEJAR \
        --cacert /etc/ipa/ca.crt  \
        --negotiate -u : \
        -X POST \
        https://$IPAHOSTNAME/ipa/session/login_kerberos&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If authentication was successful, our &lt;code&gt;$COOKIEJAR&lt;/code&gt; file will contain all
session cookies returned by FreeIPA web server. We don&amp;#8217;t need to authenticate
anymore until the session expires. All we need to do is to ensure we pass back
the session cookies back to the server.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;password-authentication&quot;&gt;Password Authentication&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Password authentication is more traditional: post over HTTPS a form with username
and password fields to the end point at &lt;code&gt;&lt;a href=&quot;https://$IPAHOSTNAME/ipa/session/login_password&quot; class=&quot;bare&quot;&gt;https://$IPAHOSTNAME/ipa/session/login_password&lt;/a&gt;&lt;/code&gt;.
A form has to be setup with appropriate MIME type, &lt;code&gt;application/x-www-form-urlencoded&lt;/code&gt; but
the rest is plain old HTTPS post.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ export COOKIEJAR=/path/to/my.cookie
$ export IPAHOSTNAME=ipa-master.example.com
$ s_username=admin s_password=mYSecReT1P2 curl -v  \
        -H referer:https://$IPAHOSTNAME/ipa  \
        -H &quot;Content-Type:application/x-www-form-urlencoded&quot; \
        -H &quot;Accept:text/plain&quot;\
        -c $COOKIEJAR -b $COOKIEJAR \
        --cacert /etc/ipa/ca.crt  \
        --data &quot;user=$s_username&amp;amp;password=$s_password&quot; \
        -X POST \
        https://$IPAHOSTNAME/ipa/session/login_password&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If authentication was successful, our &lt;code&gt;$COOKIEJAR&lt;/code&gt; file will contain all
session cookies returned by FreeIPA web server. We don&amp;#8217;t need to authenticate
anymore until the session expires. All we need to do is to ensure we pass back
the session cookies back to the server.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;sending-json-rpc-request&quot;&gt;Sending JSON-RPC request&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A session-based request needs to be posted to
&lt;code&gt;&lt;a href=&quot;https://$IPAHOSTNAME/ipa/session/json&quot; class=&quot;bare&quot;&gt;https://$IPAHOSTNAME/ipa/session/json&lt;/a&gt;&lt;/code&gt; end point over HTTPS. A content type
should set to &lt;code&gt;application/json&lt;/code&gt; and HTTP POST method has to be used. There
isn&amp;#8217;t any difference, again, from a typical JSON-RPC.  Session cookies should
not be forgotten, of course, or our request will fail spectacular.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;FreeIPA JSON-RPC interface is not documented. However, it is easy to discover
via existing command line utility, &lt;code&gt;/usr/sbin/ipa&lt;/code&gt; by supplying &lt;code&gt;-vv&lt;/code&gt; option to
it:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ ipa -vv ping
ipa: INFO: trying https://ipa-master.example.com/ipa/session/json
ipa: INFO: Forwarding 'ping' to json server 'https://ipa-master.example.com/ipa/session/json'
ipa: INFO: Request: {
    &quot;id&quot;: 0,
    &quot;method&quot;: &quot;ping&quot;,
    &quot;params&quot;: [
        [],
        {
            &quot;version&quot;: &quot;2.117&quot;
        }
    ]
}
ipa: INFO: Response: {
    &quot;error&quot;: null,
    &quot;id&quot;: 0,
    &quot;principal&quot;: &quot;admin@EXAMPLE.COM&quot;,
    &quot;result&quot;: {
        &quot;summary&quot;: &quot;IPA server version 4.1.99.201505121153GITed639c7. API version 2.117&quot;
    },
    &quot;version&quot;: &quot;4.1.99.201505121153GITed639c7&quot;
}
-------------------------------------------------------------------
IPA server version 4.1.99.201505121153GITed639c7. API version 2.117
-------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Each request has a &lt;code&gt;method&lt;/code&gt; and parameters, &lt;code&gt;params&lt;/code&gt; structure. A method is a
command to execute.  Commands of &lt;code&gt;/usr/sbin/ipa&lt;/code&gt; utility have simple structure
of &lt;code&gt;topic-action&lt;/code&gt; and methods corresponding for them are &lt;code&gt;topic_action&lt;/code&gt;, i.e.
dash is replaced by underscore. This is because they map one to one to Python
API classes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Structure of parameters is simple too. &lt;code&gt;params&lt;/code&gt; is an array of two elements:
. an array of positional arguments, and
. a dictionary of options&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As can be seen above, &lt;code&gt;ping&lt;/code&gt; method does not have positional arguments and IPA
command line client always sends own version as an option.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another example is &lt;code&gt;user-show&lt;/code&gt; with &lt;code&gt;--raw&lt;/code&gt; option passed:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ ipa -vv user-show admin --raw
ipa: INFO: trying https://ipa-master.example.com/ipa/session/json
ipa: INFO: Forwarding 'user_show' to json server 'https://ipa-master.example.com/ipa/session/json'
ipa: INFO: Request: {
    &quot;id&quot;: 0,
    &quot;method&quot;: &quot;user_show&quot;,
    &quot;params&quot;: [
        [
            &quot;admin&quot;
        ],
        {
            &quot;all&quot;: false,
            &quot;no_members&quot;: false,
            &quot;raw&quot;: true,
            &quot;rights&quot;: false,
            &quot;version&quot;: &quot;2.117&quot;
        }
    ]
}
[.... lots of output ....]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The resulting entry output is skipped for brevity.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;gathering-things-together&quot;&gt;Gathering things together&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Finally, a script below combines both password and Kerberos authentication
and then sends &lt;code&gt;user_find&lt;/code&gt; request to receive list of all users.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;# testcurl.sh
s_username=admin
s_password=mYSecReT1P2
IPAHOSTNAME=ipa-master.example.com
COOKIEJAR=my.cookie.jar
#rm -f $COOKIEJAR

klist -s
use_kerberos=$?

if [ ! -f $COOKIEJAR ] ; then
 if [ $use_kerberos -eq 0 ] ; then
        # Login with Kerberos
        curl -v  \
        -H referer:https://$IPAHOSTNAME/ipa  \
        -c $COOKIEJAR -b $COOKIEJAR \
        --cacert /etc/ipa/ca.crt  \
        --negotiate -u : \
        -X POST \
        https://$IPAHOSTNAME/ipa/session/login_kerberos
  else
        # Login with user name and password
        curl -v  \
        -H referer:https://$IPAHOSTNAME/ipa  \
        -H &quot;Content-Type:application/x-www-form-urlencoded&quot; \
        -H &quot;Accept:text/plain&quot;\
        -c $COOKIEJAR -b $COOKIEJAR \
        --cacert /etc/ipa/ca.crt  \
        --data &quot;user=$s_username&amp;amp;password=$s_password&quot; \
        -X POST \
        https://$IPAHOSTNAME/ipa/session/login_password
  fi
fi

# Send user_find method request
curl -v  \
	-H referer:https://$IPAHOSTNAME/ipa  \
        -H &quot;Content-Type:application/json&quot; \
        -H &quot;Accept:applicaton/json&quot;\
        -c $COOKIEJAR -b $COOKIEJAR \
        --cacert /etc/ipa/ca.crt  \
        -d  '{&quot;method&quot;:&quot;user_find&quot;,&quot;params&quot;:[[&quot;&quot;],{}],&quot;id&quot;:0}' \
        -X POST \
        https://$IPAHOSTNAME/ipa/session/json&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;using-json-rpc-calls-on-non-ipa-clients&quot;&gt;Using JSON-RPC calls on non-IPA clients&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If FreeIPA JSON-RPC API needs to be access from non-enrolled client, there is a
bit more work.  Kerberos authentication would most likely require properly
configured &lt;code&gt;/etc/krb5.conf&lt;/code&gt;. Luckily, the configuration can be copied over from
existing IPA client and placed somewhere --- Kerberos library allows to specify
configuration file via &lt;code&gt;KRB5_CONFIG&lt;/code&gt; environmental variable. A keytab can be
copied over too but make sure to store it securely.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another thing to copy over to a non-IPA client is a CA root certificate to
allow secure HTTPS communication.  Other than that, everything stays the same&amp;#8201;&amp;#8212;&amp;#8201;authenticate first, store session cookies, and re-use them.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
	<pubDate>Thu, 28 May 2015 19:07:10 +0000</pubDate>
</item>
<item>
	<title>Alexander Bokovoy: SambaXP 2015 travel report</title>
	<guid>https://vda.li/en/posts/2015/05/23/SambaXP-report/</guid>
	<link>https://vda.li/en/posts/2015/05/23/SambaXP-report/</link>
	<description>&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;ve attended annual  &lt;a href=&quot;http://www.sambaxp.org/&quot;&gt;SambaXP conference&lt;/a&gt; on May 19th-21st. I&amp;#8217;ve
presented about &lt;a href=&quot;http://samba.org/~ab/sambaxp/2015/freeipa_idviews.pdf&quot;&gt;FreeIPA ID Views&lt;/a&gt; and this year we also had quite a few Red
Hat&amp;#8217;s talks in the program so that organizers even made a 'Red Hat track' on
the last day, with all speakers in that track coming with a Shadowman.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;SambaXP is a conference run by SerNet GmbH in Goettingen, Lower Saxony,
Germany. SerNet is one of core contributors to Samba project, organized
by, among others, Volker Lendecke who is founder of Samba project along
with Andrew Tridgell and Jeremy Allison.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The conference is well attended; Microsoft is both sponsoring and
sending participants for last six or more years&amp;#8201;&amp;#8212;&amp;#8201;including key
managers and developers of Windows Server and SMB protocols stack.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The conference itself is spanning two days. However, the day before
the official start there are workshops and tutorials. A tutorial by Stefan
Kania was dedicated to the Samba 4 migration experience. Tutorials and
workshops are paid-for events, as well as the conference itself, but very
valuable to all attendees.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This year we had protocols interop event on the 'minus one' day where Microsoft team
ran a number of detailed presentations about changes in SMB protocol coming
with SMB 3.1.1 specification and Windows 10, Windows Server 2016. Enhancements
in SMB 3.1.1 clearly point to the direction of running HyperV workloads
directly over SMB protocol in the cloud. There are multiple extensions to allow
to map HyperV semantics for serving large volumes of VMs off scale out file
systems. Another area of improvements in SMB 3.1.1 is related to getting
security tightened to the point of forcing pre-authentication integrity. This
is a continuation of a more general effort publicized by Microsoft to 'get rid
of passwords' for Windows 10. More on SMB 3.1.1 extensions can be read in the
&lt;a href=&quot;http://blogs.technet.com/b/josebda/archive/2015/05/05/what-s-new-in-smb-3-1-1-in-the-windows-server-technical-preview-2.aspx&quot;&gt;Jose
Barreto&amp;#8217;s blog&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another part of the protocols interop event was familiarizing with Microsoft&amp;#8217;s
Protocol Test Suite. The suite is available already from MSDN and is important
part of validating correctness of implementations because its tests are
generated out of the actual specifications. A hint was given on some positive news
to be expected in June in time for Interop Plugfest (June 20-25th) in Redmond
with regards to the suite itself but already now there is a change as running
the Protocol Test Suite does not require having access to Visual Studio
anymore.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;SMB 3.1.1 pre-authentication integrity makes harder to analyze traffic. Microsoft
decided to use ETW tracing facilities available since Windows 7 which produce a
log output of the internal SMB code just before encrypting packets and handing them
over to NDIS layer. ETW tracing format is then possible to load into Message Analyzer
and watch both encrypted and unencrypted content side to side. We&amp;#8217;ve been told
ETW tracing also contains debugging output from SMB routines otherwise not seen at all.
This feature does not require installing additional software and one can run analysis
on a different machine than the trace was obtained.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It would be interesting to add support of reading ETW traces to Wireshark. With PCAPNG
format its is possible to associate comments and 'notes' with the networking packets
so having both ETW and NDIS level traces in the same capture is certainly possible.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Continuing Microsoft tune, Tom Talpey, Microsoft&amp;#8217;s architect in File Server
team, also demonstrated the performance improvements with SMB 3.1.1, storage
quality of service additions, and laid out the problem space with newer memory
types like persistent and phase memory. For next step of this work at SDC
conference in September, Tom promised 'paradigm changes in the protocol'.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;More on SMB 3 and HyperV integration can be found in
&lt;a href=&quot;http://blogs.technet.com/b/josebda/archive/2015/04/30/smb3-networking-links-for-windows-server-2012-r2.aspx&quot;&gt;this post of links by Jose Barreto&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A final note on Microsoft&amp;#8217;s take is that they want to outlaw SMB1 protocol.
When this finally will happen, is unclear, but there is huge incentive
to move away from NTLMSSP variants and anonymous data access. This will
in particular affect RHEL 6 after 2016-2018, especially in the area of
domain controllers because Windows Server 2016 at some point will move
to drop SMB1 communication between the DCs. A more detailed overview of
plans is available in &lt;a href=&quot;http://blogs.technet.com/b/josebda/archive/2015/04/21/the-deprecation-of-smb1-you-should-be-planning-to-get-rid-of-this-old-smb-dialect.aspx&quot;&gt;this blog post&lt;/a&gt;.
These changes should not be taken with a light heart&amp;#8201;&amp;#8212;&amp;#8201;majority of consumer
NAS devices use SMB1 protocol and force anonymous access by default.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jeremy Allison also made a loud rant about how we deliver media from these NAS
devices to our screens. All Smart TVs, he said, now run Linux. It means they
are SMB clients or can be made so with relative ease. SMB3 as a protocol is
perfect on low latency high throughput often needed for streaming media. He wants
to work with TV manufacturers and turn DLNA from HTTP to SMB media serving.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The keynote by Marc Muehlfeld (Samba Team) gave us results of a survey of Samba
community. The presentation is available at
&lt;a href=&quot;https://www.samba.org/~mmuehlfeld/UserSurvey2015/SummaryReports/Samba_User_Survey_2015_Summary_report_Completed_only_with_comments.pdf&quot;&gt;Samba
site&lt;/a&gt;. More than 50% of respondents run Samba 4.x, with ~38% on Samba 3.6&amp;#8201;&amp;#8212;&amp;#8201;the version which is not supported by upstream anymore. About 60% of
respondents are planning to migrate to Samba AD in next two years, with 25% are
targeting the upcoming half a year, so migration seem to happen naturally.
Samba AD is not an easy feat, most of responses mention that majority of issues
they experienced are in Authentication (44%), File Serving (30%), and Active
Directory backend (28%).  While issues is what typically makes us in
infrastructure world visible to upper management, it was interesting to see
that 15% of respondents never experienced any issues.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of defining topics for this year SambaXP is cloud. We had two separate
talks on SMB in the cloud from Google and SuSE Linux, clear message on cloud
readiness of the SMB protocol from Microsoft (they now have a separate
implementation of SMB protocol for Azure cloud, tuned for cloud-specific
workloads). Majority of talks during the first day were related to clustering
and high availability (IBM, Red Hat, Nutanix) as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Red Hat&amp;#8217;s talks also centered on using libraries provided by Samba project in
other solutions. SSSD is building on talloc, tevent, ldb, and tdb as key
components on our identity management client-side solution. We also implement
various pluggable interfaces to augment what Samba daemons see themselves when
interoperating with FreeIPA and SSSD.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Steve French (Primary Data) presented his view on the client side of SMB&amp;#8201;&amp;#8212;&amp;#8201;he
is working on cifs.ko kernel driver but also looking beyond Linux.  Apple went
with first SMB 3 extensions related to OS X-specific features and Steve is
currently designing an equivalent of what we had as UNIX extensions in SMB1 for
SMB3. A first rough cut into the client-side code was done during the
conference and we identified few handy extensions which would allow to reduce
greatly memory consumption and string manipulations in case of both server and
client running in UTF-8 environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;SMB 2 and particularly SMB 3 protocol families are interested in that it is
much cleaner spec to start with&amp;#8201;&amp;#8212;&amp;#8201;there is a number of startups that have
their own SMB protocol implementations, all SMB2+ only, without legacy support
at all. They may not have all the required features yet but it looks like SMB3
is gaining a good base across cloud/storage startups as a good starting point
for a modern performance-oriented networking file and block system, extensible
enough to cover specific workloads. This, on the other hand, creates a
possibility to fragment the spec and it will be interesting to see if common
protocol testing platform will help in keeping protocol forks close to each
other.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Aside from talks there were intense development and hacking sessions, often
well into after midnight. Many bugs were fixed and some of important long term
development branches were reviewed in face to face sessions. Below are few
examples relevant to identity management work:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Our effort to move Samba AD to MIT Kerberos is nearing completion. We
are hoping to get it polished in next ~6-8 months but the current
patchset is passing all but few tests in the Samba testsuite which is
run on every commit to the upstream git tree (~1750 different testing
scenarios). There is now a common agreement upstream to move to MIT
Kerberos as the primary Kerberos implementation. Both Heimdal and MIT
Kerberos will be supported but it seems that Heimdal upstream situation
is not that healthy since Apple moved full way with the project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We are very close to land initial implementation of cross-forest trusts in
Samba AD, sponsored by Red Hat and implemented by SerNet. Some of key
interoperability bugs were fixed during the conference sprints and I have now
an environment where FreeIPA 4.1 can establish trust to Samba AD. Our long term
goal of allowing users to maintain Windows workstations in Samba AD and Linux
machines in FreeIPA is on track.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is active work on scalability. Volker Lendecke presented his
progress of improving the messaging system used by Samba that allows
to scale both in number of processes on the single host and with a
number of hosts beyond currently supported by CTDB. At the same time,
Jakub Hrozek (Red Hat, SSSD) demonstrated some of his findings when
trying to move ldb database (key part of SSSD caching system and crucial
component of Samba AD DC) to a faster backend based on LMDB from OpenLDAP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A new version of patchset to re-target Samba AD to use OpenLDAP was
published by Nadezhda Ivanova (Symas). The work has stalled a bit due
to other customer-related work by Nadezhda but general work to
externalize Samba AD components is moving forward. As usual, projects like
this aren&amp;#8217;t easy and pretty hard to achieve without being able to dedicate
months of sustained attention to details.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There is a common effort to make predictable and manageable release
cycles. While with autobuild we have always buildable and releasable
git master tree, it is currently tested only in a single environment.
Michael Adam (Red Hat) presented his set of Vagrant-based scripts to
quickly test Samba under multiple distributions, increasing developer
productivity and test coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;ve been lucky at finding a reason for a long standing bug in IPv6 support
that caused some of gripes in testing FreeIPA as far as two years ago. Samba
client libraries support Active Directory Domain Controller&amp;#8217;s resolution via
CLDAP pings but the code that actually tried to reach multiple servers in order
to find the one with right capabilities was not taking into account a case when
it is impossible to establish actual connection due to IPv6 routes missing in
the environment. DNS might return you IPv6 hosts but opening sockets to them
may subtly fail with network being unreachable or blocked at firewall level.
Samba client libraries weren&amp;#8217;t paying attention to the greater context and the
whole CLDAP request processing got aborted even though more possible targets
were available to test. The fix is in git master and both stable branches now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Finally, an SMB 3 panel on the last day demonstrated that Samba is in
fairly good shape with regards to SMB 3 implementation and there is a
healthy communication with Microsoft on the protocol development. Now
that Windows Server release cycle is decoupled from Windows (client)
release cycle, there seems to be less pressure from the schedule point
of view in avoiding discussion of protocol improvements well in advance&amp;#8201;&amp;#8212;&amp;#8201;a definite change in behavior over last five years.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Slides and audio recordings of the talks will start appearing on
sambaxp.org in upcoming weeks. It was impossible to visit all the
talks of three parallel tracks so I&amp;#8217;m looking forward to listen to them.&lt;/p&gt;
&lt;/div&gt;</description>
	<pubDate>Sat, 23 May 2015 08:28:10 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: JWCrypto a python module to do crypto using JSON</title>
	<guid>tag:ssimo.org.blog:id_020</guid>
	<link>https://ssimo.org/blog/id_020.html</link>
	<description>&lt;p&gt;Lately I had the need to do use some crypto in a web-like scenario,
a.k.a over-HTTP(S) so I set out to look at what could be used.&lt;/p&gt;
&lt;p&gt;Pretty quickly it came clear that the &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-encryption/&quot;&gt;JSON
Web Encryption&lt;/a&gt; standard proposed in the IETF &lt;a href=&quot;https://datatracker.ietf.org/wg/jose/charter/&quot;&gt;JOSE Working
Group&lt;/a&gt; would be a good fit and actually the &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-signature/&quot;&gt;JSON
Web Signature&lt;/a&gt; would come useful too.&lt;/p&gt;

&lt;p&gt;Once I was convinced this was the standard to use I tried to find out
a python module that implemented it as the project I am going to use this
stuff in (&lt;a href=&quot;http://freeipa.org/&quot;&gt;FreeIPA&lt;/a&gt; ultimately) is python
based.&lt;/p&gt;

&lt;p&gt;The only implementation I found initially (since then I've found other
projects scattered over the web) was this &lt;a href=&quot;https://github.com/Demonware/jose&quot;&gt;Jose&lt;/a&gt; project on GitHub.&lt;/p&gt;
&lt;p&gt;After a quick look I was not satisfied by three things:
&lt;ul&gt;&lt;li&gt;It is not a complete implementation of the specs&lt;/li&gt;
&lt;li&gt;It uses obsolete python crypto-libraries wrappers&lt;/li&gt;
&lt;li&gt;It is not Python3 compatible&lt;/li&gt;&lt;/ul&gt;
While the first was not a big problem as I could simply contribute the
missing parts, the second is, and the third is a big minus too. I wanted
to use the new Python &lt;a href=&quot;https://cryptography.io&quot;&gt;Cryptography&lt;/a&gt;
library as it has proper interfaces and support for modern crypto, and
neatly abstracts away the underlying crypto-library bindings.&lt;/p&gt;

&lt;p&gt;So after some looking over the specs in details to see how much work it
would entail I decided to build a python modules to implement all relevant
specs myself.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/simo5/jwcrypto&quot;&gt;JWCrypto&lt;/a&gt; project is
the result of a few weeks of work, complete of &lt;a href=&quot;http://jwcrypto.readthedocs.org/&quot;&gt;Documentation&lt;/a&gt; hosted by
ReadTheDocs.&lt;/p&gt;

&lt;p&gt;It is an almost complete implementation of the &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-key/&quot;&gt;JWK&lt;/a&gt;,
&lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-encryption/&quot;&gt;JWE&lt;/a&gt;,
&lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-signature/&quot;&gt;JWS&lt;/a&gt;
and &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-oauth-json-web-token/&quot;&gt;JWT&lt;/a&gt;
specs and implements most of the algorithms defined in the &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-json-web-algorithms/&quot;&gt;JWA&lt;/a&gt;
spec. It has been reviewed internally by a member of the Red Hat Security Team
and has an extensive test suite based on the specs and the test vectors
included in the JOSE WG &lt;a href=&quot;https://datatracker.ietf.org/doc/draft-ietf-jose-cookbook/&quot;&gt;Cookbook&lt;/a&gt;.
It is also both Python2.7 and Python3.3 compatible!&lt;/p&gt;

&lt;p&gt;I had a lot of fun implementing it, so if you find it useful feel free to
drop me a note.&lt;/p&gt;</description>
	<pubDate>Wed, 15 Apr 2015 20:56:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: On Load Balancers and Kerberos</title>
	<guid>tag:ssimo.org.blog:id_019</guid>
	<link>https://ssimo.org/blog/id_019.html</link>
	<description>&lt;p&gt;I've recently witnessed a lot of discussions around using load balancers and
FreeIPA on the user's mailing list, and I realized there is a lot of confusion
around how to use load balancers when Kerberos is used for authentication.&lt;/p&gt;

&lt;p&gt;One of the issues is that Kerberos depends on accurate naming as server
names are used to build the Service &lt;a href=&quot;https://ssimo.org/blog/id_016.html&quot;&gt;Principal Name&lt;/a&gt;
(SPN) used to request tickets from a KDC.&lt;/p&gt;

&lt;p&gt;When people introduce a load balancer on a network they usually assign it a
new name which is used to redirect all clients to a single box that redirects
traffic to multiple hosts behind the balancer.&lt;/p&gt;

&lt;p&gt;From a transport point of view this is just fine, the box just handles
packets. But from the client point of view all servers now look alike (same
name). They have, intentionally, no idea what server they are going to hit.&lt;/p&gt;

&lt;p&gt;This is the crux of the problem. When a client wants to authenticate using
Kerberos it needs to ask the KDC for a ticket for a specific SPN. The only name
available in this case is that of the load balancer, so that names is used to
request a ticket.&lt;/p&gt;

&lt;p&gt;For example, if we have three HTTP servers in a domain: uno.ipa.dom,
due.ipa.dom, tre.ipa.dom; and for some reason we want to load balance them
using the name all.ipa.dom then all a client can do is to go to the KDC and ask
for a ticket for the SPN named: HTTP/all.ipa.dom@IPA.DOM&lt;/p&gt;

&lt;img src=&quot;https://ssimo.org/blog/id_019-1.svg&quot; /&gt;

&lt;p&gt;Now, once the client actually connect to that IP address and gets redirected
to one of the servers by the load balancer, say uno.ipa.dom it will present
this server a ticket that can be utilized only if the server has the key for
the SPN named HTTP/all.ipa.dom@IPA.DOM&lt;/p&gt;

&lt;p&gt;There are a few ways to satisfy this condition depending on what a KDC
supports and what is the use case.&lt;/p&gt;

&lt;h4&gt;Use only one common Service Principal Name&lt;/h4&gt;

&lt;p&gt;One of the solutions is to create a new Service Principal in the KDC for the
name HTTP/all.ipa.dom@IPA.DOM then generate a keytab and distribute it to all
servers. The servers will use no other key, and they will identify themselves
with the common name, so if a client tries to contact them using their
individual name, then authentication will fail, as the KDC will not have a
principal for the other names and the services themselves are not configure to
use their hostname only the common name.&lt;/p&gt;

&lt;h4&gt;Use one key and multiple SPNs&lt;/h4&gt;

&lt;p&gt;A slightly friendlier way is to assign aliases to a single principal name,
so that clients can contact the servers both with the common name and directly
using the server's individual names. This is possible if the KDC can create
aliases to the canonical principal name. The SPNs HTTP/uno.ipa.dom,
HTTP/due.ipa.dom, HTTP/tre.ipa.dom are created as aliases of HTTP/all.ipa.dom,
so when a client asks for a ticket for any of these names the same key is used
to generate it.&lt;/p&gt;

&lt;h4&gt;Use multiple keys, one per name&lt;/h4&gt;

&lt;p&gt;Another way again is to assign servers multiple keys. For example the server
named uno.ipa.dom will be given a keytab with keys for both
HTTP/uno.ipa.dom@IPA.DOM and HTTP/all.ipa.dom@IPA.DOM, so that regardless of
how the client tries to access it, the KDC will return a ticket using a key the
service has access to.&lt;/p&gt;
&lt;p&gt;It is important to note that the acceptor, in this case, must not be
configured to use a specific SPN or acquire specific credentials before trying
to accept a connection if using GSSAPI, otherwise the wrong key may be selected
from the keytab and context establishment may fail. If no name is specified
then GSSAPI can try all keys in the keytab until one succeeds in decrypting the
ticket.&lt;/p&gt;

&lt;h4&gt;Proxying authentication&lt;/h4&gt;

&lt;p&gt;One last option is to actually terminate the connection on a single server
which then proxies out to the backend servers. In this case only the proxy has
a keytab and the backend servers trust the proxy to set appropriate headers to
identify the authenticated client principal, or set a shared session cookie
that all servers have access to. In this case clients are forbidden from
getting access to the backend server directly by firewalling or similar network
level segregation.&lt;/p&gt;

&lt;h4&gt;Choosing a solution&lt;/h4&gt;

&lt;p&gt;Choosing which option is right depends on many factors, for example, if
(some) clients need to be able to authenticate directly to the backend servers
using their individual names, then using only one name only like in the first
and fourth options is clearly not possible. Using or not aliases may or not be
possible depending on whether the KDC in use supports them.&lt;/p&gt;

&lt;h4&gt;More complex cases, the FreeIPA Web UI&lt;/h4&gt;

&lt;p&gt;The FreeIPA Web UI adds more complexity to the aforementioned cases. The Web
UI is just a frontend to the underlying LDAP database and relies on
&lt;a href=&quot;https://ssimo.org/blog/id_011.html&quot;&gt;constrained delegation&lt;/a&gt; to access the LDAP server, so
that access control is applied by the LDAP server using the correct user
credentials.&lt;/p&gt;
&lt;p&gt;The way constrained delegation is implemented requires the server to obtain
a TGT using the server keytab. What this means is that only one Service
Principal Name can be used in the FreeIPA HTTP server and that name is
determined before the client connects. This factor makes it particularly
difficult for FreeIPA servers to be load balanced. For the HTTP server the
FreeIPA master could theoretically be manually reconfigured to use a single
common name and share a keytab, this would allow clients to connect to any
FreeIPA server and perform constrained delegation using the common name,
however admins wouldn't be able to connect to a specific server and change
local settings. Moreover, internal operations and updates may or may not work
going forward.&lt;/p&gt;
&lt;p&gt;In short, I wouldn't recommend it until the FreeIPA project provides a way
to officially access the Web UI using aliases.&lt;/p&gt;
&lt;p&gt;A poor man solution if you want to offer a single name for ease of access
and some sort of load balancing could be to stand up a server at the common
name and a CGI script that redirects clients randomly to one of the IPA
servers.&lt;/p&gt;</description>
	<pubDate>Sun, 05 Apr 2015 16:56:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: PSA - Smart Cards are still a Hell - Instructions for CardOS cards</title>
	<guid>tag:ssimo.org.blog:id_018</guid>
	<link>https://ssimo.org/blog/id_018.html</link>
	<description>&lt;p&gt;Some time ago I received a Smart Card from work in order to do some
testing. Of course as soon as I received it I got drowned into some other
work and had to postpone playing with it. Come the winter holiday break and
I found some time to try this new toy. Except ...&lt;/p&gt;

&lt;p&gt; ... except I found out that the Smart Card Hell is still a Hell&lt;/p&gt;

&lt;p&gt;I tried to find information online about how to initialize the CardOS
card I got and I found very little cohesive documentation even on the sites
of the tools I ultimately got to use.&lt;/p&gt;

&lt;p&gt;The smart card landscape is still a fragmented lake of incompatibility,
where the same tools work for some functions on some cards and lack in any
way usability.&lt;/p&gt;

&lt;p&gt;Ultimately I couldn't find out the right magic incantation for the reader
and card combo I had, and instead had to ask a coworker that already used
this stuff.&lt;/p&gt;

&lt;p&gt;Luckily he had the magic scroll and it allowed me, at least, to start
playing with the card. So for posterity, and for my own sake, let me register
here the few steps needed to install a certificate in this setup.&lt;/p&gt;

&lt;p&gt;I had to use no less than 3 different CLI tools to manage the job, which is
insane in its own right. The tools as you will see have absurd requirements
like sometimes specifying a shared object name on the CLI ... I think smart
card tools still win the &quot;Unusable jumbled mess of tools - 2013 award&quot;.&lt;/p&gt;

&lt;p&gt; The &lt;em&gt;cardos-tool --info&lt;/em&gt; command let me know that I have a
&lt;em&gt;SCM Microsystems Inc. SCR 3310&lt;/em&gt; Reader using a &lt;em&gt;CardOS V4.3B&lt;/em&gt;
card. Of course you need to know in advance that your card is a CardOS one to
be able to find out the tool to use ...&lt;/p&gt;

&lt;p&gt;The very Lucky thing about this card is that if can be reformatted to
pristine status w/o knowing any PIN or PUK. Of course that means someone can
wipe it out, but that is not a big deal in production (someone can always lock
it dead by failing enough time to enter PIN and PUK codes), but it is great
for developers that keep forgetting whatever test PIN or PUK code was used
with the specific card :-) This way the worst case is that you just need to
format and generate/install a new cert to keep testing.&lt;/p&gt;

&lt;p&gt;So on to the instructions:&lt;/p&gt;

&lt;p&gt;Format the card:
&lt;pre&gt;cardos-tool -f&lt;/pre&gt;
and notice how no confirmation at all is requested, and it works as a user on
my Fedora 20 machine. I find not asking for confirmation a bit bold, given this
operation destroys all current content, but ... whatever ...&lt;/p&gt;

&lt;p&gt;Create necessary PKCS#15 and set admin pins:
&lt;pre&gt;pkcs15-init -CT --so-pin 12345678 --so-puk 23456789&lt;/pre&gt;
note, that you have to know that you need to create this stuff and that a tool
with obscure switches to do it also exists ...&lt;/p&gt;

&lt;p&gt;Separately create user PIN and unlock code:
&lt;pre&gt;pkcs15-init -P -a 1 --pin 87654321 --puk 98765432 --so-pin 12345678 --label &quot;My Cert&quot;&lt;/pre&gt;
No idea why this needs to be a separate operation, part of the magic
scroll.&lt;/p&gt;

&lt;p&gt;Finally import an existing certificate:
&lt;pre&gt;pkcs15-init --store-private-key /path/to/file.cert --auth-id 01 --pin 87654321 --so-pin 12345678&lt;/pre&gt;
again not sure why a separate command, also note that this assumes a PEM
formatted file, if you have a pkcs12 file use the &lt;em&gt;--format pkcs12&lt;/em&gt;
switch to feed it into. Note that the tool assumes pkcs12 cert files are
passphrase protected so you need to know the code before trying to upload such
formatted certs ion the card.&lt;/p&gt;

&lt;p&gt;Check everything went well with:
&lt;pre&gt;pkcs11-tool --module opensc-pkcs11.so -l --pin 87654321 -O&lt;/pre&gt;
of course yet another tool, with the most amusing syntax of them all ...&lt;/p&gt;

&lt;p&gt;... and that is all I know at this point. If you feel the need to weep at
this point feel free, I am reserving a corner of my room to do just that later
on after lunch ...&lt;/p&gt;</description>
	<pubDate>Thu, 02 Jan 2014 17:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: GSS-NTLMSSP a new GSSAPI Mechanism</title>
	<guid>tag:ssimo.org.blog:id_017</guid>
	<link>https://ssimo.org/blog/id_017.html</link>
	<description>&lt;p&gt;Without fanfare here is my latest wandering in the creation of obscure and
complicated security infrastructure software: &lt;a href=&quot;https://ssimo.org/code/gss-ntlmssp/&quot;&gt;GSS-NTLMSSP&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;NTLM is Microsoft's first effort at creating a secure authentication method
that wouldn't rely on exposing the user password to the target service and
instead used a Challenge Response mechanism to create proof of knowledge of a
shared secret between the client and the server.
&lt;/p&gt;

&lt;p&gt;During the years Microsoft has slighlty improved the protocol and later on
when they finally created the SSPI subsystem in Windows they created the
NTLMSSP mechanism that incapsulated all NTLM usages.
&lt;/p&gt;

&lt;p&gt;Micosoft's &lt;a href=&quot;https://en.wikipedia.org/wiki/Security_Support_Provider_Interface&quot;&gt;SSPI&lt;/a&gt;
is the Windows equivalent (and wire-compatible) version of &lt;a href=&quot;https://tools.ietf.org/html/rfc2743&quot;&gt;GSSAPI&lt;/a&gt; and I've been wanting to
build this mechanism since MIT Kerberos added directly supoport for the &lt;a href=&quot;https://tools.ietf.org/html/rfc4178&quot;&gt;SPNEGO&lt;/a&gt; negotiation mechanism.
&lt;/p&gt;

&lt;p&gt;The current code is still young and many things are missing, notably the
ability to use Domain Controller based authentication for the server side.
However I find it is a quite useful module for clients, so here we have our
first shiny release: &lt;a href=&quot;https://ssimo.org/code/gss-ntlmssp/gssntlmssp-0.1.0.tar.gz&quot;&gt;0.1.0&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;Feel free to try and use it and let me know if you have neat ideas to
improve its use and usability.&lt;p&gt;&lt;/p&gt;&lt;/p&gt;</description>
	<pubDate>Sun, 13 Oct 2013 19:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: About Kerberos Principals and Keys</title>
	<guid>tag:ssimo.org.blog:id_016</guid>
	<link>https://ssimo.org/blog/id_016.html</link>
	<description>&lt;p&gt;I find time and again people find the concept of principals is a confusing
unless they are very familiar with Kerberos.&lt;/p&gt;

&lt;p&gt;I see the same issues when discussing about keys and keytabs.&lt;/p&gt;

&lt;p&gt;So what is a Kerberos Principal ?&lt;/p&gt;

&lt;p&gt;The simplest, initial, answer can be that a principal is the analogous of a
user name in a multiuser OS. So why do we call it principal ? And why do you
hear variations like 'User Principal' or 'Service Principal' ?&lt;/p&gt;

&lt;p&gt;The reason why the term principal is used is because 'user' is indeed
insufficient, too generic and misleading. In Kerberos there are many actors
that need keys, any actor that need a key needs to be represented by an
identifier. These identifiers are compounded strings called 'principals'.&lt;/p&gt;

&lt;h4&gt;Anatomy of a principal&lt;/h4&gt;

&lt;p&gt;A principal is a set of components represented by strings. One very
important component is the realm name, each principal is always fully qualified
with the name of the realm, The realm is represented by the last component in
the string form. It is placed after an @ sign and is conventionally all upper
case. The first part of the principal, instead, represents a specific identity
within the realm. The first part can be split in multiple components joined by
a / character.&lt;/p&gt;

&lt;p&gt;Example:
&lt;pre&gt;&lt;font size=&quot;3&quot;&gt;component1 / component2 @ REALM&lt;/font&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;The simplest principals are actually what we think of users, generally
actual people. The simplest identifier to represent users uses just one
component and the realm. For example, the principal simo@EXAMPLE.COM
represents a user named 'simo' that belongs to a realm named EXAMPLE.COM&lt;/p&gt;

&lt;p&gt;The component is what we think of a user name, pretty simple so far. The
realm as you can see resembles a domain name. That is on purpose as normally
Kerberos realms are tied to DNS domain names, although not strictly required
by the protocol specifications. Some implementations of Kerberos like Active
Directory makes this a requirement. In AD the realm name is always the (DNS)
domain name.&lt;/p&gt;

&lt;p&gt;Another set of extremely important principals are the so called Service
Principals. These principals represent actual programs or computers.
Their form normally comprises two components, a service part and a fully
qualified hostname.&lt;/p&gt;

&lt;p&gt;Example:
&lt;pre&gt;&lt;font size=&quot;3&quot;&gt;nfs/server.example.com@EXAMPLE.COM&lt;/font&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Let's analyze this principal name. The first component represents the
service being used, in this case 'nfs' is used to represent a NFS server.
Other well know service types are 'HTTP', 'DNS', 'host', 'cifs', etc...
The second component is a DNS name. This is the server's own name. The realm
specifies that this service is bound to the EXAMPLE.COM realm.&lt;/p&gt;

&lt;p&gt;Why this specific convention was chosen to represent a specific NFS Server
?&lt;/p&gt;

&lt;p&gt;The reason is that the Kerberos protocol does not offer a name resolution
service. So a convention was devised to make it easy for a client to
automatically compute what is the principal name of a target service they want
to contact based on 2 easy to know names: the service type, and the name of the
host that is offering it. This is necessary because this name is used by the
client to contact the KDC and ask for a ticket for that specific service.
If the client doesn't know the specific name of the target service, it cannot
ask for a ticket.&lt;/p&gt;

&lt;p&gt;The service type is easy to know, an NFS client is used to connect to an NFS
server and the type can simply be hard coded to 'nfs', or can be set into a
configuration file quite easily, it will be the same for all services of that
type across the network.&lt;/p&gt;

&lt;p&gt;The host name is also generally a well known name. When a user wants to
connect to a specific server it has to identify it somehow to the NFS client,
and that usually means giving the mount utility a server 'name'. Same for HTTP,
you have to give the browser a server name to contact as part of a URL and so
on. The only limitation, in case of Kerberos is that you need the canonical
form upfront (although there is work to relax this requirement). DNS is often
used to find out the canonical form from a shorter name or sometimes even an
IP address (but see &lt;a href=&quot;https://ssimo.org/blog/id_015.html&quot;&gt;this post&lt;/a&gt; about reverse
resolution).&lt;/p&gt;

&lt;p&gt;The question at this point is why do we need principals to represent
services or whole hosts ? The answer is that each service you want to contact
needs keys in order to decrypt the tickets you present them to authenticate
yourself.&lt;/p&gt;

&lt;h4&gt;Keys and Keytabs&lt;/h4&gt;

&lt;p&gt;Each principal is associated to a specific key in the KDC and this
key is used to encrypt the tickets given to the clients. A service needs the
same key in order to decrypt tickets; this is why Kerberos is called a shared
key system. Any actor in a Kerberos system has a key that is also known to
the KDC and is used to authenticate messages sent to the KDC or received from
the KDC (a ticket can be considered a message received indirectly from the
KDC where the KDC asserts the identity of the client.)&lt;/p&gt;

&lt;p&gt;For user principals the key is the user's password. The KDC stores a copy
of the password (generally transformed from the clear text into a more
cryptographically useful secret through a key derivation process, but
nonetheless perfectly equivalent to the user password).&lt;/p&gt;

&lt;p&gt;For service principals, generally, instead of using a password a random key
is generated and stored both in the KDC and in a file called a 'Keytab'.&lt;/p&gt;

&lt;p&gt;A keytab file contains keys for a specific service, it is completely
equivalent to a password file and needs to be treated as a highly sensitive
secret.&lt;/p&gt;

&lt;p&gt;Possession of the keytab means ability to fully impersonate the
principal whose keys are stored in the keytab file. This means a keytab file
should never be transmitted over a network in the clear (no emailing of keytabs
please) and should be protected by appropriate access control (file
permissions) at all times; a common mistake is to create a file in /tmp that
is readable by anyone and only then move it somewhere else more secure.&lt;/p&gt;

&lt;p&gt;Users can also use keytabs, a password can always be transformed into a
keytab (using the same key derivation process that the KDC uses to store its
copy), but that is less common because any password change will require to
create a new keytab with the new keys.&lt;/p&gt;

&lt;h4&gt;Using and mapping principals&lt;/h4&gt;

&lt;p&gt;One of the things that people seem not to realize when they are first shown
principals is that any principal can be used as a client to contact any service
(this is not always true in AD as sometimes Service Principals are not allowed
to request a TGT, but this is a configuration decision and is not always
true).&lt;/p&gt;

&lt;p&gt;This means that when accepting connections authenticated via Kerberos,
applications need to pay a little bit of attention to who the client is. And
need to perform some basic access control on the client principal before
allowing access.&lt;/p&gt;

&lt;p&gt;A common mistake is to take the principal name in string form
and simply cut anything after the @ sign (the realm name) and use the
remaining part as a 'user name' on the system, then perform calls like
getpwnam() with this user name and grant the client the same access this user
has on the system. Another even worse mistake is to allow ANY client that
could properly authenticate to access data as if it were 'trusted' somehow.
&lt;/p&gt;

&lt;p&gt;On the one hand this may not be sufficient, and on the other this may be
dangerously broad and an actual security issue.&lt;/p&gt;

&lt;p&gt;First of all, as we said above, any principal may try contact a service, not
just users that have a 1-1 corresponding name in the system. A NFS Server may
act as a client and use it's key to contact another service. For example a web
application needs to decide whether it wants to grant access to a client named
nfs/nfsserver.example.com@EXAMPLE.COM just like it gives access to
joe@EXAMPLE.COM or not.&lt;/p&gt;

&lt;p&gt;There are also more exotic principals that may contact a service though, not
just principals that are somehow directly trusted by our own KDC. For example
anonymous principals and principals coming from a trusted realm.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://k5wiki.kerberos.org/wiki/Anonymous_kerberos&quot;&gt;Anonymous
principals&lt;/a&gt; are quite an obscure and little used feature, often it is not
possible to get tickets anonymously in a Kerberos realm, but they are allowed
by some implementation, and if the KDC is configured to allow anonymous
principals then applications need to be careful not to give these clients the
same access they give to fully identified clients.&lt;/p&gt;

&lt;p&gt;The anonymous principal is:
&lt;pre&gt;&lt;font size=&quot;3&quot;&gt;WELLKNOWN/ANONYMOUS@WELLKNOWN:ANONYMOUS&lt;/font&gt;&lt;/pre&gt; &lt;/p&gt;

&lt;p&gt;As can be seen the realm is actually a specially named realm and this is to
avoid legacy apps that match the REALM before allowing access to be fooled in
to thinking this is a fully trusted user. This is one reason why simply blindly
chopping off anything after the @ character is a grave mistake.&lt;/p&gt;

&lt;p&gt;Another reason why the realm part must be validated are Kerberos
cross-realm trusts. A Kerberos realm can be configured to 'trust' another
Kerberos realm. Meaning the principals of Realm A are allowed to get tickets
for services in Realm B if there is a trust relationship between B and A.&lt;/p&gt;

&lt;p&gt;For our application this means that it may be contacted by both the user
joe@REALM.A and a different user joe@REALM.B that has nothing to do
with the previous one. If our application simply cuts off the realm part,
without checking that the realm matches something it understand, it may give
access to data of a user in one realm to an homonym in another realm. &lt;/p&gt;

&lt;p&gt;In general applications that do not want to deal with multiple realms
should define one realm as allowed and refuse access to any principal that
comes from a different realm. If multiple realms need to be supported (and that
is a good idea) then appropriate mapping from the principal to an application
identifier should be performed, by either using the full principal name as
identifier, or by asking the system to map the principal for us including
telling whether the principal is acceptable. This can be done in GSSAPI by using
the gss_localname() function, which respects the auth_to_local configuration
documented in the krb5.conf(5) manpage.&lt;/p&gt;

&lt;p&gt;Using the system provided configuration allows admins to configure rules
only once for the whole machine/network and avoid the need to implement mapping
in every different application, so I highly recommend it where possible.&lt;/p&gt;

&lt;p&gt;Additional warning: Principal names are considered case sensitive by the
reference implementation (MIT Kerberos) but some implementation treat them in
a case-insensitive way (Active Directory for example). It is safer to always
treat principal names in a case sensitive way. (Active Directory will
generally always provide the canonicalized form in tickets although it may
accept mismatching cases when requesting tickets).&lt;/p&gt;

&lt;p&gt;Hopefully this brief explanation will be useful to understand how to deal
with principals and key tabs to the casual programmer that cares more about the
practical implications rather than the abstract semantics and technicalities
of the Kerberos protocol.&lt;/p&gt;</description>
	<pubDate>Thu, 20 Jun 2013 21:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Why depending on DNS Reverse resolution is bad</title>
	<guid>tag:ssimo.org.blog:id_015</guid>
	<link>https://ssimo.org/blog/id_015.html</link>
	<description>&lt;p&gt;I have been recently involved in a discussion about why I go around trying
to stop applications from using and sometime even depending on DNS Reverse
resolution (PTR records lookups).&lt;/p&gt;

&lt;p&gt;There are 2 main reasons:
&lt;ul&gt;
  &lt;li&gt;In many networks you cannot really control the PTR records, so reverse
resolution is simply broken&lt;/li&gt;
  &lt;li&gt;Reverse resolution is bad when used for security protocols like
GSSAPI&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let's start from the first point, which is easy to argue about. In a lot of
cases the person setting up a service is not the same person controlling the
DNS. Even more the DNS person/organization controlling the Forward Zone may not
be at all the same one that controls the Reverse Zone.&lt;/p&gt;

&lt;p&gt;This is true for the general internet usage (try asking your ISP to set a
special PTR record for your residential public IP address ... laughs) but also
for some corporate environments where the Network Ops may be so separate from
the user installing a machine and rules to ask changes to DNS so complex that it
is sometime simply too inconvenient to ask for changes, especially in temporary
settings like Proof of Concept trials, etc.. This is not hypothetical, in my
past life as consultant I've seen it all, and I can tell PTR records are broken
more often than not.&lt;/p&gt;

&lt;p&gt;So by this reason alone depending on a PTR record to obtain the actual name
of a server is a pretty high bar and will inevitably be a barrier for adoption.
It gets to silly levels if an application actually gets the 'right' name in
input and then translates it into an IP only to attempt reverse resolution and
fail. Users legitimately get pissed the app is so stupid as to throw away the
name they just gave it. I just gave the name to you! Don't you see it!&lt;/p&gt;

&lt;p&gt;It is surprising how many applications do this silly game when it comes with
providing the target name to GSSAPI, which introduces the second point.&lt;/p&gt;

&lt;p&gt;Why is it bad from a security point of view ? We understand that it is
unfortunate for cases were reverse resolution is broken, but if reverse
resolution is properly configured what is so bad depending on it ?&lt;/p&gt;

&lt;p&gt;This is a little scenario I wrote up on the &lt;a href=&quot;http://marc.info/?l=linux-nfs&amp;m=136500502805121&amp;w=2&quot;&gt;linux-nfs&lt;/a&gt;
mailing list to explain how the fact rpc.gssd (the client that handles GSSAPI
authentication on the kernel behalf in user space for the nfs client module)
depends on reverse resolution can actually be exploited by an attacker.&lt;/p&gt;

&lt;p&gt;Assume the following scenario:
&lt;ul&gt;
  &lt;li&gt;User Alice has access to secret documents that are automatically backed
up daily by mounting a NFS share from &lt;em&gt;secure.server.name&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Only Alice has write or read access to this server&lt;/li&gt;
  &lt;li&gt;User Eve wants to get hold of those documents and is in a position to
intercept and modify Alice's traffic&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;
  &lt;li&gt;There is a similar server available on the network that Alice has write
access to called &lt;em&gt;public.server.name&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Eve has read access on public.server.name&lt;/li&gt;
  &lt;li&gt;The NFS servers use RPCSEC_GSS (Kerberos) to secure the communications
and perform mutual authentication.&lt;/li&gt;
&lt;/p&gt;

&lt;p&gt;Note that Eve does not need to be controlling any of the servers, and it is
sufficient for her to be able to spoof DNS replies.&lt;/p&gt;

&lt;p&gt;Now the attack: Eve wants to fool Alice's computer to mount the public
server's NFS share instead of the secure server one, so that the automatic
backup job will copy Alice's secret documents to the public server where Eve
has read access and can grab a copy.&lt;/p&gt;

&lt;p&gt;Normally this is not possible, because the Kerberos protocol implies mutual
authentication. Not only the user authenticates to a server by using a ticket,
but the ticket is only usable by the &lt;em&gt;right&lt;/em&gt; target server, therefore
authentication fail if either the user or the server are not who they say they
are.&lt;/p&gt;

&lt;p&gt;In our case normally Alice will grab a ticket for nfs@secure.server.name
(GSSAPI Naming notation), which can be used exclusively to authenticate against
the secure server. If Eve tries to redirect communication to the public server
the authentication will fail because the public server is not able to decrypt
the ticket.&lt;/p&gt;

&lt;p&gt;However, rpc.gssd does a &lt;em&gt;very bad thing(TM)&lt;/em&gt;. When the client runs
the mount command it uses the name provided on the command line to obtain the
server's IP address, then &lt;em&gt;ignores&lt;/em&gt; the fact we already have a name and
proceeds to perform a reverse lookup to 'find' the server name.&lt;/p&gt;

&lt;p&gt;What this means is that Eve can simply spoof the DNS to redirect Alice's
computer to contact the wrong server and then later rpc.gssd will 'find' that
the 'real' name of the server is &lt;em&gt;public.server.name&lt;/em&gt; (Either because
Eve spoofed the original forward resolution reply or by spoofing the reverse
resolution reply later on).&lt;/p&gt;

&lt;p&gt;Now Alice's computer will call into GSSAPI with the constructed name of
nfs@public.server.name and when it connects to that server mutual
authentication is successful because the ticket can be decrypted by the
target server.&lt;/p&gt;

&lt;p&gt;Eve just waits for Alice's computer to complete its backup on the wrong
server on which she has read access, and grabs the documents.&lt;/p&gt;

&lt;p&gt;This type of attack obviously is not limited to the NFS protocol but can
be performed against any client that trusts DNS Reverse resolution to determine
the target server's name. It is also not limited to GSSAPI, an SSL client
might also be fooled the same way if it doesn't check the name that was
provided in the URL but instead uses DNS Reverse resolution to validate the
server certificate. Luckily I am not aware of any client doing that for
HTTPS at least.&lt;/p&gt;

&lt;p&gt;And that is all folks!&lt;/p&gt;</description>
	<pubDate>Wed, 03 Apr 2013 23:10:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: IMAPD via SSH and Thunderbird</title>
	<guid>tag:ssimo.org.blog:id_014</guid>
	<link>https://ssimo.org/blog/id_014.html</link>
	<description>&lt;p&gt;I have been using &lt;a href=&quot;http://projects.gnome.org/evolution/&quot;&gt;Evolution&lt;/a&gt; for many years, and
one of the key features that kept me using it was the ability to run imapd on
another machine via ssh. This was done using a simple command in Evolution's
option:&lt;/p&gt;

&lt;pre&gt;ssh -l &amp;lt;user&amp;gt; &amp;lt;server&amp;gt; exec /usr/sbin/imapd&lt;/pre&gt;

&lt;p&gt;This ssh command will allow Evolution to connect directly to a
pre-authenticated imapd process on my server avoiding the need to run a
network facing service and the need for password based authentication.
Everything is accessed via my ssh connection that uses key based
authentication&lt;/p&gt;

&lt;p&gt;(the option is not directly available anymore and you have to fiddle
with gsettings to use it now, which is a real shame as it is completely
undiscoverable.)&lt;/p&gt;

&lt;p&gt;I recently decided to try out &lt;a href=&quot;https://www.mozilla.org/thunderbird/&quot;&gt;Thunderbird&lt;/a&gt; again and found
out that this is one of the features that is still missing, after all these
years ...&lt;/p&gt;

&lt;p&gt;This was a blocker for me, so I decided to find a workaround that would
allow me to use Thunderbird and still use ssh to reach the imapd daemon on my
server, like I have done for the last decade.&lt;/p&gt;

&lt;p&gt;After some tinkering and reading on all the SSH options for Nth time I came
to the conclusion that ssh alone cannot run a remote command and wire
it's STIDN/STDOUT to a local port even though it can do pretty much any other
forwarding you may think of, including forwarding your local STIDN/STDOUT to
a remote host/port ... a real shame.&lt;/p&gt;

&lt;p&gt;The most I could achieve was to make SMTP available this way, as I do have
an MTA listening to an actual TCP port on the server. Making the MTA available
is easy, you just need to run the following command on your client:&lt;/p&gt;

&lt;pre&gt;
ssh -f -N -C -L 10025:localhost:25 -o ExitOnForwardFailure=yes -l &amp;lt;user&amp;gt; &amp;lt;server&amp;gt;
&lt;/pre&gt;

&lt;p&gt;This command, makes available locally on port 10025 the server's port 25
through a simple forward on a SSH encrypted channel. The -f and -N options,
are used to put ssh in the background without running any command or shell.
The -C option turns on compression and the ExitOnForwardFailure option makes
ssh fail to start if it cannot establish the forwarding. This way if I run the
command multiple times only one tunnel stays up as the other shells will simply
silently exit.&lt;/p&gt;

&lt;p&gt;This is quite cool already but doesn't solve my imap problem, to solve it
I need to employ one of those little know yet very powerful tools available
on Linux (and other *nix OSs as well): &lt;a href=&quot;https://en.wikipedia.org/wiki/Netcat&quot;&gt;netcat&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The version I have installed is the one distributed with the &lt;a href=&quot;http://nmap.org/ncat/&quot;&gt;Nmap&lt;/a&gt; project.&lt;/p&gt;

&lt;p&gt;Netcat (ncat or nc) is an incredibly useful tool. I've used it countless
of times for all sort of things over the network. And it is the perfect
tool to solve my problem when used this way:&lt;/p&gt;

&lt;pre&gt;ncat -k --sh-exec &quot;ssh -C -l &amp;lt;user&amp;gt; &amp;lt;server&amp;gt; exec /usr/sbin/imapd&quot; -l localhost 10143&lt;/pre&gt;

&lt;p&gt;This command does a wonderful thing. It keeps (-k) listening (-l) on the
local port 10143 and every time there is a connection it will run the command
provided by the --sh-exec option in a shell and wire it's STDIN/STDOUT to the
connection that has been just opened over TCP.&lt;/p&gt;

&lt;p&gt;This is exactly what I needed. Now every time Thunderbird connects to my
local port 10143, netcat will run the ssh command that will connect to the
remote server as my user and run the imapd server.&lt;/p&gt;

&lt;p&gt;Although Thunderbird's configuration doesn't seem to allow for 'non'
authenticated connections, everything seem to work fine if I just leave the
password empty. (Remember the imapd server is pre-authenticated via my ssh
connection as my remote user and requires no additional authentication)&lt;/p&gt;

&lt;p&gt;So what is missing here ? The Security paranoids among my readers should
have spotted one glaring issue! Everybody on my local machine can now connect
to my local port 10143 and access my remote mailbox without
authentication!!&lt;/p&gt;

&lt;p&gt;Let me fix that with a single firewall instruction:&lt;/p&gt;

&lt;pre&gt;iptables -A OUTPUT -p tcp --dport 10143 -d 127.0.0.1 -m owner ! --uid-owner simo -j REJECT&lt;/pre&gt;

&lt;p&gt;Yep, it is a simple as that (on Linux at least). But what does it do ?&lt;/p&gt;

&lt;p&gt;This command uses a very nifty feature of iptables that allows the kernel
to recognize who is the owner of any outbound connection and will prevent
any connection to port 10143 for any user on the system that is not me.
Of course iptables filters any non local connection to my machine as well.&lt;/p&gt;

&lt;p&gt; Problem solved! &lt;/p&gt;

&lt;p&gt;Now I can start playing with Thunderbird and see what else I need to tweak
to make it useful for me (one thing I already found is an add-on to
import/export entire folders, a feature I always wanted and missed in
Evolution)&lt;/p&gt;</description>
	<pubDate>Mon, 04 Mar 2013 04:10:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Talking to people</title>
	<guid>tag:ssimo.org.blog:id_013</guid>
	<link>https://ssimo.org/blog/id_013.html</link>
	<description>&lt;p&gt;The new year started with a lot of talks at various conferences.&lt;/p&gt;

&lt;p&gt;For the past few years I had slowed down on attending conferences, but this
year started with my attendance to 2 conferences I like a lot.&lt;/p&gt;

&lt;p&gt;The first is &lt;a href=&quot;https://fosdem.org/&quot;&gt;FOSDEM&lt;/a&gt;, probably the best
Free Software conference and certainly the biggest one in the world. &lt;/p&gt;
&lt;p&gt;I just love FOSDEM, I love Belgium for the Beers and Chocolate, so it is
always a pleasure for me to go there. Plus I have friends in Brussels, where
I have been multiple times in the past so it is always a pleasure to go back
there for a full immerse week end.&lt;/p&gt;

&lt;p&gt;This year I presented 2 talks at FOSDEM.&lt;/p&gt;
&lt;p&gt;One in the main track about &lt;a href=&quot;https://ssimo.org/slides/FOSDEM-2013-Building-IDM.pdf&quot;&gt;
Identity Management on Linux&lt;/a&gt; and a second in the &lt;a href=&quot;https://fosdem.org/2013/schedule/track/legal_issues/&quot;&gt;Legal Devroom&lt;/a&gt;
about a &lt;a href=&quot;https://ssimo.org/slides/FOSDEM-2013-Legal-Track-Simo.pdf&quot;&gt;Veteran's
perspective&lt;/a&gt; on various legal matters surrounding Free and Open Source
Software. I organized this talk as an open discussion between me and the public
and I absolutely loved the conversation.&lt;/p&gt;

&lt;p&gt;The IdM talk in contrast was a classic solo speech on a 30 kilometers high
overview about the problem of building an IdM system on Linux and for Linux.
It does have references to the &lt;a href=&quot;http://freeipa.org&quot;&gt;FreeIPA&lt;/a&gt; project but does not go in deep
technical details beyond explaining why we choose certain technologies.&lt;/p&gt;

&lt;p&gt;This actually led to criticism after the talk: &lt;em&gt;Not technical
enough!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;And it is a fair one, too bad that when I presented the initial abstract to
FOSDEM I got the opposite reply: &lt;em&gt;Too technical!&lt;/em&gt;, so I had to water
down and broaden the initial proposal :-).&lt;/p&gt;

&lt;p&gt;I guess you can never win this game, so my resolution is to oscillate between
the two extremes ...&lt;/p&gt;

&lt;p&gt; ... which brings me to the other talk at &lt;a href=&quot;http://www.devconf.cz&quot;&gt;DevConf.cz&lt;/a&gt;. This is a very nice conference,
organized by &lt;a href=&quot;http://www.redhat.com&quot;&gt;Red Hat&lt;/a&gt; in Brno.&lt;/p&gt;

&lt;p&gt;DevConf.cz is a developer conference so I presented a pretty technical talk
on &lt;a href=&quot;https://ssimo.org/slides/devconf-2013-gss-proxy.pdf&quot;&gt;GSSAPI and privilege
separation using Gss-Proxy&lt;/a&gt; which is the latest project I launched together
with Nico and later the help of Günther.&lt;/p&gt;

&lt;p&gt;This time I got the: &lt;em&gt;Too technical!&lt;/em&gt; red flag. Hopefully, though,
it was still interesting enough for the audience.&lt;/p&gt;

&lt;p&gt;All in all, I enjoyed these conferences very much, I won't list all the
excellent talks I attended, there were too many. Most importantly I was able
to finally meet face to face with some people I interact every day or I needed
to have a more interactive discussion to hash out some problems an ideas. So
fun and very productive time, what more can you ask for as a nerd type ?&lt;/p&gt;</description>
	<pubDate>Fri, 01 Mar 2013 21:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: What a great year!</title>
	<guid>tag:ssimo.org.blog:id_012</guid>
	<link>https://ssimo.org/blog/id_012.html</link>
	<description>&lt;p&gt;This past year has been really great, too bad I found little time to
update my blog :-)&lt;/p&gt;

&lt;p&gt;A few things happened that made me cheer up while thinking about what has
been going on this year.&lt;/p&gt;

&lt;p&gt;Samba &lt;a href=&quot;https://www.samba.org/samba/history/samba-4.0.0.html&quot;&gt;4.0&lt;/a&gt; finally
happened. It has been an incredible, long ride, with highs and lows but
amazingly we pulled it off!&lt;/p&gt;

&lt;p&gt;FreeIPA &lt;a href=&quot;http://www.freeipa.org/page/IPAv3_300_ga&quot;&gt;3.0&lt;/a&gt; &lt;b&gt;and&lt;/b&gt; &lt;a href=&quot;http://www.freeipa.org/page/IPAv3_310&quot;&gt;3.1&lt;/a&gt; with AD cross-forest trust
integration also were released this year. I am so proud of this project, it has
achieved results I hardly hoped for when I started it a few years ago.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://fedorahosted.org/sssd&quot;&gt;SSSD&lt;/a&gt; has seen multiple releases
with the 1.8 Long Term Maintenance series and 1.9 series. SSSD is one of the
most successful projects I started these past years and I used it every day
myself with great pleasure.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://fedorahosted.org/gss-proxy&quot;&gt;Gss-Proxy&lt;/a&gt; is the last
project I started, just this year, and has seen 2 initial no-fanfare releases.
It is one of those plumbing things that are hardly seen (except when things
break :-) but it was exciting to work so deep into GSSAPI code.&lt;/p&gt;</description>
	<pubDate>Sat, 29 Dec 2012 06:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Kerberos: delegation and s4u2proxy</title>
	<guid>tag:ssimo.org.blog:id_011</guid>
	<link>https://ssimo.org/blog/id_011.html</link>
	<description>&lt;p&gt;One of the most obscure parts of the Kerberos protocol is delegation. And
yet it is a very powerful and useful tool to let &quot;agents&quot; work on behalf of
users w/o fully trusting them to do everything a user or an admin can.&lt;/p&gt;

&lt;p&gt;So what is delegation ? Simply put is the ability to give a service a token
that can be used on the user's behalf so that a service can act as if it were
the user himself.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;http://www.freeipa.org&quot;&gt;FreeIPA&lt;/a&gt;, for example, the web
framework used to mediate administration of the system is such an agent. The
framework on it's own has absolutely no privileges over the rest of the system.
It interacts almost exclusively with the LDAP server and authenticates to the
LDAP server using delegated credentials from the user that is sending in
the requests.&lt;/p&gt;

&lt;p&gt;This is possible because through Kerberos and GSSAPI it is possible to
delegate user's credentials during the Negotiate exchange that happens at the
HTTP layer when a user contacts the Web Server and authenticates to it.&lt;/p&gt;

&lt;h4&gt;How does it work ?&lt;/h4&gt;

&lt;p&gt;Before we answer this question we have to make a step back and explain what
kind of delegations are possible. Historically only one kind of very inflexible
delegation was really implemented in standard Kerberos implementations like
MIT's or Heimdal's. The full delegation (transmission) of the user's krbtgt to
the target service.&lt;/p&gt;

&lt;p&gt;This kind of delegation is perfect for services like SSH, where the user
wants to have full access to their own credentials after they jumped on the
target host, and they generally remain in full control of them.&lt;/p&gt;

&lt;p&gt; The drawback of this method is that by transmitting the full krbtgt we are
now giving another host potential access to each and all services our user has
access to. And while that is &quot;powerful&quot; it is also sort of overly broad in many
other situations. the other minor issue is that normally KDC's do not have
fine grained authorization attached to this feature, meaning that a user (or
often more generally a program acting on the user's machine) can delegate these
credentials to any service in the network, w/o much control from admins.&lt;/p&gt;

&lt;h4&gt;Enter S4U constrained delegation&lt;/h4&gt;

&lt;p&gt;Luckily for us Microsoft introduced a new type of &quot;constrained&quot; delegation
normally referred to as
&lt;a href=&quot;http://msdn.microsoft.com/en-us/library/cc246071%28PROT.13%29.aspx&quot;&gt;
S4U&lt;/a&gt;. This is an extension to the age old Kerberos delegation method and
adds 2 flavors of delegation each depending on the KDC for authorization;
they are called Service-for-User-to-Self (S4U2Self) and
Service-for-User-to-Proxy (S4U2Proxy).&lt;/p&gt;

&lt;h4&gt;Service-for-User-to-Self&lt;/h4&gt;

&lt;p&gt;S4U2Self allows a service to get a ticket for itself on behalf of a user,
or in other terms is allows to get a ticket as if a user requested it using
it's krbtgt form a KDC and then contacted the service.&lt;/p&gt;

&lt;p&gt;This option may seem of little use, why would a service care for a ticket
to itself ? If it is asking it, it already knows the identify of the user and
can operate on its behalf right ? Wrong.&lt;/p&gt;

&lt;p&gt;There are at least 3 aspects that makes this function useful. First of all
you get the KDC to give you a ticket and therefore validate that the user
identity actually exist and is active. Second it may attach a MS-PAC (or
other authorization data to the ticket, allowing the service to know, form an
authoritative source, authorization information about the user. Finally, it
may allow the service to do further actions on behalf of a user by using
S4U2Proxy constrained delegation on top.&lt;/p&gt;

&lt;p&gt;All this is possible only if the KDC allows the specific service to request
S4U2Self services. This is an additional layer of authorization that is very
useful to admins, it allows them to limit what services can use this
feature.&lt;/p&gt;

&lt;h4&gt;Service-for-User-to-Proxy&lt;/h4&gt;

&lt;p&gt;S4U2Proxy is the actual method used to perform impersonation against a 3rd
service. To use S4U2Proxy a service A that wants to authenticate to service B
on behalf of user X, contacts the KDC using a ticket for A from user X (this
could also be a ticket obtained through S4U2Self) and sends this ticket to the
KDC as evidence that user X did in fact contact service A. The KDC can now make
authorization decisions about whether to allow service A to get a ticket for
service B in the name of user X. Normally admins will allow this operation only
for services that are authorized &quot;Proxies&quot; to other services.&lt;/p&gt;

&lt;p&gt;In FreeIPA we just switched to using S4U2Proxy in order to reduce the attack
surface against the web framework. By using S4U2Proxy we do not need the user
to delegate us a full krbtgt. By doing this we allow the web framework to
effectively be able to operate against the LDAP server and no other service in
the domain&lt;/p&gt;

&lt;p&gt;These 2 delegation methods are available now both in MIT's and Heimdal's
Kerberos implementations. In MIT's case (which is the implementation we use in
FreeIPA) it is really possible to use these features only if you use an LDAP
back-end (or in general a custom back-end that implements the necessary kdb
functions. The native back-end does not have support for these features, because
it lacks meaningful grouping methods and Access Control facilities to control
them.&lt;/p&gt;

&lt;p&gt;In coding up the support for FreeIPA we ended up fixing a few bugs in
MIT's implementation that will hopefully be available for general use in 1.11
(We have back ported patches to RHEL and Fedora). We also had to modify the
Apache mod_auth_kerb module to properly deal with S4U2Proxy, which requires the
requesting service to have a valid krbtgt in order to send the request to the
KDC. Something mod_auth_kerb did not need before (you do not need a krbtgt if
you are just validating a ticket).&lt;/p&gt;

&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;S4U constrained delegation is extremely useful, it reduces attack surface by
allowing admins to effectively constrain services, and gives admins a lot more
control about what users can delegate to. Finally it also makes clients
simpler, and this is a key winning feature. In the classic delegation scheme
clients needs to decide on their own whether to delegate a krbtgt, which
ultimately means either asking the user or always/never do it. And given it is
quite dangerous to liberally forward your ticket to random services the default
is generally to not delegate the krbtgt, making it very difficult to rely on
this feature to make powerless agents. With S4U the user only needs a
Forward-able TGT, but does not need to actually forward it at all. This is
a reasonable compromise and does not require applications to make choice on
user's behalf, nor to make user's need to make any decision. The decision rests
on admins to allow certain service or not, and is taken generally once, when
the service is put in production, greatly reducing the burden to
administrators and the risks involved in the traditional delegation scheme.&lt;/p&gt;</description>
	<pubDate>Sun, 12 Feb 2012 16:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Code Reviews, Quality and Coverity Results</title>
	<guid>tag:ssimo.org.blog:id_010</guid>
	<link>https://ssimo.org/blog/id_010.html</link>
	<description>&lt;p&gt;As &lt;a href=&quot;https://fedorahosted.org/sssd/&quot;&gt;SSSD&lt;/a&gt; 1.5.0 is &lt;a href=&quot;https://fedorahosted.org/pipermail/sssd-devel/2010-December/005403.html&quot;&gt;
hitting&lt;/a&gt; the street, I want to give some background on how we deal with
code, reviews and quality in SSSD.&lt;/p&gt;

&lt;p&gt;NOTE: if you just want to see the Coverity results, feel free to jump to the
&lt;a href=&quot;https://ssimo.org/blog/#coverity&quot;&gt;end&lt;/a&gt; of this long post :-)&lt;/p&gt;

&lt;p&gt;When I helped jump-starting this project one of the things I wanted to try
out was a very strict Review Policy for a few reasons.&lt;/p&gt;

&lt;p&gt;One of the reasons was consistency. Previous projects I participated in had
very lax policies about pretty much everything. Style, review, quality, where
not strictly enforced, and this is felt as a way to keep the barrier to entry
low. In my experience though, the inconsistent style, unclear direction, poor
or no review, in the end caused other different barriers to a new developer.
&lt;/p&gt;

&lt;p&gt;Lack of enforced consisting style makes code difficult to read,
especially when you have to read a pair of interacting functions that are
written in wildly different styles.&lt;/p&gt;

&lt;p&gt;Lack of required reviews helped creating an environment in which
contributions from outside are not promptly commented upon. The developer
with commit access is used to throw in pretty much everything without having
to wait for someone to review. This makes core developers forget how painful
it is waiting for a review that is never happening. This in turn can
discourage new developers that do not have direct commit access from
proposing patches as they see too little feedback and do not feel properly
engaged.&lt;/p&gt;

&lt;p&gt;Finally quality is something I think suffers a lot from lack of review.
Developers that do not have to stand review tend to become more relaxed,
code is thrown in without much thought, as long as it doesn't break the build.
But breaking the build is a pretty low standard. So often the way a function
perform operations, the semantics, are implicitly assumed by other code.
Reviews, in my experience, tend to expose the same piece of code to different
point of views, and expertise within the project. Things that seem innocuous
are pointed out and both developers at the end of the process gain both more
knowledge of each other points of view, and more knowledge in general about
the piece of software they are modifying. Usually the net result is that in
the mid/long term code quality improves significantly.&lt;/p&gt;

&lt;p&gt;When you use a common SCM tool, like git, code reviews can happen in two
ways. Review before commit or Review-Commit (R-C), and review after commit or
Commit-Review (C-R). In SSSD we use the former. Patches must be reviewed and
acked by a second developer before they can be committed.&lt;/p&gt;

&lt;p&gt;R-C is generally thought as a stricter method, but I find it much better
than C-R.*&lt;/p&gt;

&lt;p&gt;In my experience with the C-R method the reviewer is encouraged to do
sloppier and cursory reviews and just give acks unless something really
stands up as very ugly. Patches regularly slip past review during phases
where a lot of churn happens. Long patches tend to get the least review
(exactly when reviews are more important). People are less engaged. Also
because the code is already committed, bad patches can cause a lot of bad
feelings, the patch is seen as breaking the code, reverts are called for
and the author may feel embarrassed or angered by how they are being
treated.&lt;/p&gt;

&lt;p&gt;R-C instead assures review is done, more importantly it requires active
intervention from the reviewer. This in turn makes it less problematic to
actually comment on all aspects of the code even minor ones. Of course it
also risks abuse from obsessive nitpickers, but in general lets people speak
frankly of the code, and request the appropriate corrections be done or the
code will not be committed. The patch is never seen as breaking anything, as
it is not committed yet, so you rarely see that added anxiety, pressing and
bad feelings that rise when a fix is needed asap. The patch creator have all
interest in fixing the issues and learning why they were issues in the first
place, and resubmit a better patch, without pressure or embarrassment.&lt;/p&gt;

&lt;p&gt;I found this aspect to be fundamental in helping new developers get up to
good code standards quickly. Not only people does not get frustrated by poor
commits that need to be &quot;fixed&quot; asap. But the interaction between more senior
developers and younger ones benefits both greatly. On the one hand the younger
developer gets access to the insights of the more experienced developer. They
get to understand why the patch is not OK and how it need to be improved to be
made acceptable. On the other hand the more experienced developer gets a grasp
of what parts of the code are really difficult to deal with for younger ones.
Sometimes you are so used to do things one way that you don't realize that they
really are pain points and needs refactoring to make them usable.&lt;/p&gt;

&lt;p&gt;Also because all developers are submitted to the same regime there are no
'elites' that escape review. And this prevents bad feelings when a patch takes
some more time to get approved. It generally also prevent the 'elite' from
looking down on new developers. Or other similar 'status' issues. Of course
there always developers that are more authoritative, but that authority is
earned on the field and maintained through reviews&lt;/p&gt;

&lt;p&gt;Arguably all these arguments are strongly biased by my personal view of
things, I definitely do not deny that, but is there a metric that can tell
whether I was right or wrong in some respect ?&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;coverity&quot; href=&quot;http://www.coverity.com/products/static-analysis.html&quot;&gt;Coverity&lt;/a&gt;
Results seem to give some interesting insight.&lt;/p&gt;

&lt;p&gt;We have been running Coverity a couple of times during the 1.2.0 development
cycle, using spare cycles of an internal Red Hat instance. 1.2.0 was an
important release for us because it was going to end up in RHEL 6.0 so we
wanted to find and fix as many critical bugs as possible.&lt;/p&gt;

&lt;p&gt;The first time, ever, that we ran Coverity on the SSSD code base gave us
back a defect density of 1.141 bugs per thousand lines of code. After removing
the false positives we were down to 0.556 bugs per thousands lines of code.&lt;/p&gt;

&lt;p&gt;This was an astounding result. As you can see in the 'Coverity Scan: 2010 Open
Source Integrity Report' the mean of defects for the software industry is
around 1 defect per thousand lines, and the mean for first scan is usually much
higher. Also looking at the 2006 report the mean for the top most 32 open
source projects was around 0.4 defects per thousands lines. So we were pretty
close to that metric too.&lt;/p&gt;

&lt;p&gt;Of course we fixed most of the bugs that were found and a second scan of the
1.2.1 release revealed a defect density of 0.029 bugs per thousands lines. I
call that impressive (and if you know me you know I am not someone that easily
shows enthusiasm).&lt;/p&gt;

&lt;p&gt;That was all and well, but we didn't have further access to Coverity until
recently. During the release of 1.5.0 we got access again to Coverity scans, so
we ran the tool to find out how we fared.&lt;/p&gt;

&lt;p&gt;Before spitting numbers I have to say that the comparison against 1.2.0 is a
bit skewed because we forked off a set of basic libraries that now live in their
own tree.&lt;/p&gt;

&lt;p&gt; 1.2.1 had ~ 74k lines of C code alone and the libraries we forked off
constituted ~12k lines of that code. In 1.5.0 we have ~ 65k lines instead.
So we roughly lost 12k lines and gained 3k lines total. The amount of code
change is quite a different thing though. Using git, I can see that the
removal of the libraries amounted to roughly 34k deletions (this counts also
makefiles, comments, blanklines, etc... that's why it is different than the
11k LOC numbers I gave above) while the diffstat of the diff between 1.2.1 and
1.5.0 gives ~ 73k deletions and 56k additions. So quite a bit of changes
happened on that code base after all.&lt;/p&gt;

&lt;p&gt;In mid December we scanned the code base, roughly 6 months after the release
of 1.2.1, and the results were again astounding: 0.189 bugs per thousand lines.
In total 24 defects, 20 real, and 4 false positive. And a week later the we
were down to 0 (zero) outstanding defects.&lt;/p&gt;

&lt;p&gt;These numbers tell me that our code quality is quite good, and although I
can't claim a causal effect, I believe that our review strategy is to be
accounted for much of it.&lt;/p&gt;

&lt;p&gt;Finally, Congratulations to all SSSD developers. You've done a fine job
guys, quite a fine job!&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;* - &lt;font size=&quot;0.5&quot;&gt;I have to say that w/o git R-C would be probably too
painful, but git let's you manage the code so easily that R-C has become much
simpler and doesn't block a developer as he can keep piling patchs on top of
his own repository while waiting for the review, and later easily use the
rebasing features of git to fix whatever need fixing quite easily.&lt;/font&gt;&lt;/p&gt;</description>
	<pubDate>Wed, 22 Dec 2010 23:00:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: SSSD a tale of community, collaboration, success!</title>
	<guid>tag:ssimo.org.blog:id_009</guid>
	<link>https://ssimo.org/blog/id_009.html</link>
	<description>&lt;p&gt;Today a long development cycle started more than a year an half ago comes to
a conclusion with a great release:
&lt;a href=&quot;https://fedorahosted.org/sssd/&quot;&gt;SSSD&lt;/a&gt; 1.2.0 is &lt;a href=&quot;https://fedorahosted.org/pipermail/sssd-devel/2010-May/003766.html&quot;&gt;
out&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;First of all I must say I am extremely proud of the team. When I started the
project in September 2008 I knew where I wanted to go, and I knew it would have
been a long journey. But I didn't really know how the trip would be.&lt;/p&gt;

&lt;p&gt;Looking back at the first days it seem magic what we achieved, so much was
unknown, so high where my expectations, I almost feared I couldn't live up to
them myself. But thanks to Steve, Sumit, Jakub, Martin and others the project
grew, matured and now SSSD is going to be shipped in the forthcoming RHEL 6
release.&lt;/p&gt;

&lt;p&gt;Since a few months ago Steve really took over the release management role
and he's done an outstanding job. The SSSD 1.2.0 release has his name all over.
The dedication he showed is truly remarkable. Thanks Steve!&lt;/p&gt;

&lt;p&gt;Beside the more dedicated developers I also have to thank a lot of people
that put SSSD under stress and tested it in real deployments, since the the
early 0.x releases.&lt;/p&gt;

&lt;p&gt;One of the most important factors for the success of a FOSS project is the
formation of a community of people that can work together in a very cooperative
way. All these people not only reported bugs but also patches and most importantly
had the patience to interact and test fixes, make requests, discuss needs and
expectations. A great positive feedback loop; extremely motivating! I can say
beyond any doubt that without them SSSD wouldn't be even close to where it is
now.&lt;/p&gt;

&lt;p&gt;THANK YOU contributors, all of you!&lt;/p&gt;

&lt;p&gt;Of course a new cycle opens now, as new releases are already waiting in the
pipeline, but it is a good moment to stop and look at what has been done.&lt;/p&gt;

&lt;p&gt;SSSD is something that I have been thinking about in various forms since I
started working for Red Hat more than 3 years ago, and in vague forms way, way
before that, back when I was still doing consulting jobs in Italy. Since I
started formalizing it within Red Hat it was called in many ways (one of the
stickier names we used internally for a while was &quot;Blue Box&quot;), and was often
thought as a piece of the puzzle we call
&lt;a href=&quot;http://www.freeipa.org&quot;&gt;FreeIPA&lt;/a&gt;. You can still probably find
references to it in the older design plans on the FreeIPA wiki.&lt;/p&gt;

&lt;p&gt;So what can SSSD do today?&lt;/p&gt;

&lt;p&gt;The most interesting features are related to the primary use case we've been
working against. LDAP servers and Kerberos authentication.&lt;/p&gt;

&lt;p&gt;SSSD works like a connection pooling an cache mechanism for a client. It
will provide the machine with users and groups fetched and cached from the
central server. Plus it adds neat feature like offline authentication, a real
boon if you want to use LDAP and laptops at the same time, but in general a
great feature if you have remote machines behind a slow or unstable link and
you want to take sure your users can keep working if the connection goes
temporarily down. It frees you from the need to put an LDAP replica in a remote
office just for a very few users.&lt;/p&gt;

&lt;p&gt;SSSD has a modular multi-process design, it has been built with resilience
and robustness in mind, a very small process controls a bunch of children that
handle specific tasks.  If any component dies, the monitor restarts it to avoid
service disruption. (although I have to say that it has been many many moons
since I had an issues on my machines, and that's just great).&lt;/p&gt;

&lt;p&gt;SSSD is built with frontends to handle NSS and PAM communication, and backend
providers to handle access to remote servers, plus a file based mmaped cache that
works as a unifying glue to store and retrieve data. Multiple different
backends can be configured, to retrieve user information and perform
authentication. And many of these modules can be combined together like in the
case of the IPA backend that is substantially an LDAP identity provider plus a
Kerberos authentication provider.&lt;/p&gt;

&lt;p&gt;Much more could be said, but I think this is enough to ignite some curiosity
for now ;-)&lt;/p&gt;

&lt;p&gt;For the interested people I can say SSSD has been shipped in Fedora for quite
a while now, but only recently authconfig was modified to make it simpler to
configure it with the upcoming F-13 release. The integration is already quite nice
and we hope to improve it even more in future. Although other distributions
have already packaged it and will hopefully ship it soon as a first citizen too.&lt;/p&gt;

&lt;p&gt;Last but not least, I must also thank Red Hat for believing in this small
project and funding most of its development so far. Red Hat is a great place to
stay if you want to develop core infrastructure technology.&lt;/p&gt;</description>
	<pubDate>Mon, 24 May 2010 20:44:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Convincing a Windows Domain that we are trustworthy</title>
	<guid>tag:ssimo.org.blog:id_008</guid>
	<link>https://ssimo.org/blog/id_008.html</link>
	<description>&lt;p&gt;In the last few weeks I have been working on trying to find out how to
make a Windows 2008 R2 Domain Controller, trust a Samba domain so that it
would consider us able to handle PACs and therefore send us them.&lt;/p&gt;

&lt;p&gt; This is different from the normal MIT Kerberos level trust. When using
those trusts, the Windows DC does not expect the other Realm to be able to
send PACs, understand PACs, or understand routing information for transitive
trusts.&lt;/p&gt;

&lt;p&gt;In order to set-up a cross-realm trust you need to make the Windows DC
believe we are actually just another Windows Domain, with all the bells and
whistles of a Windows Domain. Well, actually not all of them, and discovering
exactly which ones was my goal.&lt;/p&gt;

&lt;p&gt;As usual with Windows, there is a lot of redundancy and different ways to
do things. Depending on the way you try to set up cross-forest trust
relationships you will cause different netlogon RPCs to be issued.&lt;/p&gt;

&lt;p&gt;After implementing some of them, and finding that some others were hard, I
tried to find a way to reduce the amount of calls we need.&lt;/p&gt;

It turns out, as one might expect, that creating the 2 half of the trust on
each DC would be easier as only the verification process is left. What I did
not expect was that that was going to be true even if the tool used to create
the trust on the Samba side, was actually a Windows 7 box.

&lt;p&gt;Long story short, after fiddling around and hacking up some netlogon calls
obscenely, in some cases hard coding server names in there, I was able to
convince the Windows DC that we were indeed a trustworthy realm. Something to
which it could route kerberos packets including the PAC.&lt;/p&gt;

&lt;p&gt; At the same time the Samba domain KDC was able to parse the PAC and use
the cross-realm trust account password to release tickets. And the Windows
side was able to use this to seamlessly access the Samba fileserver.&lt;/p&gt;

&lt;p&gt; For the moment it is all a big hack, and I have tested it only with a one
way trust relationships (the Samba domain trusts the Windows domain but not the
other way around). Yet it allowed me to finally confine the problem and
understand exactly what is the minimum set of calls we have to answer and,
most importantly, what we are supposed to answer.&lt;/p&gt;

&lt;p&gt;Because of the hacks this code won't go in any tree for now, but it the
base I need to plan the next steps. There is a lot of work to do before
we have the mechanism needed to substitute the hacks with the proper actions
the Samba server needs to take.&lt;/p&gt;

&lt;p&gt;Ah, almost forgot, while researching this matter I also found interesting
oddities and some protocol issues. Those always spice up your day, as it
derails all your work and distracts you from your path until you understand
and then solve or work around the problem. Usually just to fall into a new one
a few days later, just as soon as you got back to the thread and remembered
what were you actually doing and expecting to happen, so that you can happily
forget it all over again. But this is also fun if you can take it
philosophically :-)&lt;/p&gt;</description>
	<pubDate>Tue, 16 Mar 2010 03:40:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Samba + MIT Kerberos, first steps are done</title>
	<guid>tag:ssimo.org.blog:id_007</guid>
	<link>https://ssimo.org/blog/id_007.html</link>
	<description>&lt;p&gt;I've been working on rebasing the samba patches to be able to push them
upstream. After some quite deep rebasing work I was able to push all of the
changes required to common code. And the amount of changes were surprisingly
small all considered.&lt;/p&gt;

&lt;p&gt;Today I finished nailing the last bits in the samba and mit sides of the
plugin implementing both policy checks calls and constraint delegation
calls. I will propose the patch to both upstreams soon.&lt;/p&gt;

&lt;p&gt;Meanwhile my focus has been shifting toward Cross-Realm trust relationships
and in particular External and Forest trusts in AD parlance, both one-way and
two-way&lt;/p&gt;

&lt;p&gt;Unfortunately the samba 4 code still does not support cross-realm trust so I
had to use 2 Windows 2008 Servers to do my experiments.&lt;/p&gt;

&lt;p&gt;The amount of calls that need to be implementd does not look too big,
although the devil is always in the details. It even seem that there is some
code already available but it is not fully patched in. As we stand, A Windows
DC is able to actually create the trust domain object in Samba's Database, but
then Samba fails to reply to some queries about it and to setup Schannel over
RPC to validate the Trust from the Windows pov.&lt;/p&gt;

&lt;p&gt;I am considering working on Samba 4 to get it to work in a trusted realm
scenario, but I still need to do some more research first.&lt;/p&gt;</description>
	<pubDate>Mon, 01 Feb 2010 23:08:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Habemus PAC</title>
	<guid>tag:ssimo.org.blog:id_006</guid>
	<link>https://ssimo.org/blog/id_006.html</link>
	<description>&lt;p&gt;After some working, digging, changing, re-changing, fixing, cursing, fixing
it again, I've got MIT Kerberos and Samba collaborate also on the PAC
front.&lt;/p&gt;

&lt;p&gt;Today I was able to login on Windows 7 using the MIT KDC, and all players
are happy.&lt;/p&gt;

&lt;p&gt;This was an important mileston, although the job is certainly not finished.
I still have to implement one important authorization function, and go over a
few todo's in the code.&lt;/p&gt;

&lt;p&gt;But as with all milestones this was very satisfing, even more so because it
took me a lot less than I anticipated, and I usually underestimate :-)&lt;/p&gt;

&lt;p&gt;Well, that's it for today!&lt;/p&gt;</description>
	<pubDate>Fri, 15 Jan 2010 00:38:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Hurray! Got the first ticket from MIT Kerberos + Samba 4</title>
	<guid>tag:ssimo.org.blog:id_005</guid>
	<link>https://ssimo.org/blog/id_005.html</link>
	<description>&lt;p&gt;It is always a sweet feeling when things go the way you like, and fast too!&lt;/p&gt;

&lt;p&gt;After just a week working around this Chimera, today I was able to tame the
beast. I made krb5kdc return a TGT reading all data off of samba4 internal
database.&lt;/p&gt;

&lt;p&gt;I can't feel anything but triumph. It is true that it is not that much after
all, but I can't help feeling happy for the result. This effort has been put off
for so long and deemed so difficult that I was very pleased to find out it wasn't
too difficult after all.&lt;/p&gt;

&lt;p&gt;Of course the job is not done. The impedance mismatch between Samba 4's
embedded Heimdal and MIT Kerberos interfaces forced me to defer adding the
PAC. Without the PAC, the nice Windows 7 refuses to log you in of course,
but that was expected, so it didn't bother me in the least.&lt;/p&gt;

&lt;p&gt;Adding the PAC is not difficult, and all the code I need is in Luke's HDB
Bridge code, which provided also most of the guidance and code I needed for
this effort.

&lt;p&gt;Without Luke's code this effort would have been much more difficult indeed.
The code itself is not very complex, but the knowledge of both project internals
was needed and Luke provided the knowledge I missed on the MIT kdb plugin side.&lt;/p&gt;

&lt;p&gt;I hope to have a hacky prototype able to add the PAC using Luke's code
next week. Once I can make Windows work with this code, I will actually start
working on trying to get a little bit cleaner interfaces within Samba so that I
can reduce the dependency on the Heimdal code hacks in the bridge code.&lt;/p&gt;

&lt;p&gt;PS: if you want to see the work you can pull the code from these 2
branches:
&lt;br /&gt;git://git.samba.org/idra/samba.git
&lt;br /&gt;git://git.samba.org/idra/krb5.git&lt;/p&gt;&lt;/p&gt;</description>
	<pubDate>Sat, 09 Jan 2010 00:59:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: mating samba and MIT Kerberos</title>
	<guid>tag:ssimo.org.blog:id_004</guid>
	<link>https://ssimo.org/blog/id_004.html</link>
	<description>&lt;p&gt;Just before the holidays I started working on a new project to mate Samba 4
and MIT Kerberos.&lt;/p&gt;

&lt;p&gt;Samba 4 embeds a copy of Heimdal Kerberos, and I want to use MIT instead as
that’s what is ditributed in RHEL and Fedora and it is the implementation of
Kerberos we use in FreeIPA.&lt;/p&gt;

&lt;p&gt;Samba 4 is basically one gigantic mess of spaghetti code (No it is not that
bad, but dependencies are intricate :-)&lt;/p&gt;

&lt;p&gt;Because it embeds the Heimdal KDC it also uses the Heimdal client library
and it conflicts with the MIT Kerberos one of course. So here I am building a
plugin that can act as separation layer that will, hopefully, keep the
namespaces separated (thanks RTLD_LOCAL).&lt;/p&gt;

&lt;p&gt;It is going to be an interested ride.&lt;/p&gt;

&lt;p&gt;(if you want to take a look feel free to check my personal samba git repo on
git.samba.org and soon I will also publish the krb5 repo with the other half
somewhere too …)&lt;/p&gt;</description>
	<pubDate>Tue, 05 Jan 2010 00:14:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Fun with Wiimotes</title>
	<guid>tag:ssimo.org.blog:id_003</guid>
	<link>https://ssimo.org/blog/id_003.html</link>
	<description>&lt;p&gt;Today I saw this &lt;a href=&quot;http://www.youtube.com/watch?v=5s5EvhHy7eQ&quot;&gt;YouTube
video&lt;/a&gt; and got intrigued again about playing with my Wii Remote.&lt;/p&gt;

&lt;p&gt; So I searched around and found 2 useful projects.&lt;/p&gt;

&lt;p&gt;The first is the &lt;a href=&quot;http://www.wiiuse.net/&quot;&gt;wiiuse
library&lt;/a&gt;, although a bit buggy and with horrible dosmode files (carriage
return at the end of each line) I quickly packaged and even submitted a &lt;a href=&quot;http://bugzilla.redhat.com/552113&quot;&gt;review bug&lt;/a&gt; to push it into Fedora.
&lt;/p&gt;

&lt;p&gt;The second is an even crueder program called &lt;a href=&quot;http://www.resplect.com/xwii/&quot;&gt;XWii&lt;/a&gt;. The code is a bit horrible, but
I was able to quickly hack it to do a few things including mapping multimedia
volume keys to minus/plus/home Wiimote buttons, and a bit finer control to be
able to use a wiimote as a real IR mouse. There is a lot of work to turn this
program in a state where I can consider proposing it as a Fedora package.&lt;/p&gt;

&lt;p&gt;If I can find time on weekends I plan to buy a few infrared leds and play a
bit with my wiimotes and my video projector. If all goes well I might rewrite
xwii in C as a real daemon and propose it as a package for Fedora. But no
promises, this new year looks like I am going to work hard on a few
work-related projects, so it may take quite some time or forever ...&lt;/p&gt;</description>
	<pubDate>Mon, 04 Jan 2010 04:51:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Holidays are awesome</title>
	<guid>tag:ssimo.org.blog:id_002</guid>
	<link>https://ssimo.org/blog/id_002.html</link>
	<description>&lt;p&gt;Spent awesome holidays with relatives.&lt;/p&gt;

&lt;p&gt;As usual the best is food. I love holidays food, especially Italian holidays
food&lt;/p&gt;

&lt;p&gt;Today Luana and her parents made something special: Home made gnocchetti
with beans. They brought home made sausages too, and this evening we are going
to have home made pizza.&lt;/p&gt;

&lt;p&gt;Total Bliss&lt;/p&gt;</description>
	<pubDate>Sun, 27 Dec 2009 19:39:00 +0000</pubDate>
</item>
<item>
	<title>Simo Sorce: Bye bye Evolution - welcome claws-mail</title>
	<guid>tag:ssimo.org.blog:id_001</guid>
	<link>https://ssimo.org/blog/id_001.html</link>
	<description>&lt;p&gt;After more than 8 years of service I finally abandoned evolution for my
work mail.&lt;/p&gt;

&lt;p&gt;I used evolution with great satisfaction for many years, but recently it
has got in the way.&lt;/p&gt;

&lt;p&gt;I am still using evolution for my personal email on my personal desktop
but not for work anymore.&lt;/p&gt;

&lt;p&gt;Many small things got worse in the last year. Calendaring with Zimbra
stopped working even half decently no less than 2 moths ago, changes in the
way messages are displayed or threaded I didn’t like a bit and got in my
way of managing email.&lt;/p&gt;

&lt;p&gt;As of late I kept using evolution mostly for the integrated calendar,
although it never worked perfectly it was still decent and the best
compromise I could find. But since calendaring stopped working
(appointments alarms do not fire, evolution prevents me changing stuff
etc…) the last reason to keep sticking to evo faded.&lt;/p&gt;

&lt;p&gt;So I looked out again and decided to give another try to claws-mail.
Last time I tried it was 3-4 years ago and compared to evolution it was
simply way to poor in features.&lt;/p&gt;

&lt;p&gt;But recent releases are just all evolution should be for me. The only
thing claws-mail lacks is the graphical polish evolution has. But I can
live with an ugly tool as long as it does the job.&lt;/p&gt;

&lt;p&gt;And claws-mail just does the job.&lt;/p&gt;

&lt;p&gt;It lets me configure just about every single behaviour and every single
item in the interface the way I like. I finally found again the joy of
configuring a tool so that it maximized my way of doing things instead of
having to bend my habits to a rigid tool like evolution is gradually
becoming.&lt;/p&gt;

&lt;p&gt;If I were to make the usual dreaded car analogy, evolution is more and
more looking like the typical cheap sports car that has a very nice line
and nice features, but is fragile.&lt;/p&gt;

&lt;p&gt;Claws is more like a Van or a Truck, it ain’t pretty, but when I have to
use it for my work it just is about perfect, it get’s the job done, without
fear of scratching the paint either.&lt;/p&gt;

&lt;p&gt;Claws-mail lacks a decent calendaring support and has no way to
integrate with Zimbra, and the optional calendaring plugin it has is pretty
poor, but given evolution is broken in that regard I can hardly say that’s
a show-stopper. For calendaring I am now also experimenting again with
sunbird.&lt;/p&gt;

&lt;p&gt;But for mail it supports all I need, GSSAPI auth works, IMAP works great
and looks like offline support works as well. Search does its job and so
on.&lt;/p&gt;

&lt;p&gt;But again the main feature is that I was able to configure just about
any aspect I wanted.&lt;/p&gt;

&lt;p&gt;I can tell it exactly how to behave when I change a folder (I prefer it
to select the last mail I’ve read)&lt;/p&gt;

&lt;p&gt;It doesn’t jump hectically when I get in a folder just because I like to
keep new mails at the bottom and not at the top like evolution does.&lt;/p&gt;

&lt;p&gt;It is generally faster at rendering messages.&lt;/p&gt;

&lt;p&gt;One difference with evolution is how it manages attachments, I think I
like how it does it though. Does not cause again all the view pane to
flicker like evolution does just because it has to recalculate the page
layout to show the attachment content when you select it.&lt;/p&gt;

&lt;p&gt;In short I got in love by how well it configures and although it lacks
calendaring and it is not much multithreaded (sometimes you have to wait
for another operation to finish) it looks solid and didn’t have a problem
with my multi-gigs IMAP repository.&lt;/p&gt;

&lt;p&gt;All in all, right now I feel it much power-user friendly, and is making
my use of email enjoyable again like it was with evolution up to 2-3 years
ago.&lt;/p&gt;

&lt;p&gt;Let’s see how long the honeymoon will last :-)&lt;/p&gt;</description>
	<pubDate>Fri, 18 Dec 2009 21:02:00 +0000</pubDate>
</item>

</channel>
</rss>
